#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šäº‹ä¸šéƒ¨æ—¥æŠ¥è‡ªåŠ¨åŒ–ä¸»æµç¨‹
- äº”å¤§äº‹ä¸šéƒ¨ã€äº”å¤§æ¸ é“ç‹¬ç«‹åˆ†ç»„
- æ•°æ®è¿‡æ»¤ï¼ˆåˆ·å•ã€è®¢å•çŠ¶æ€ã€çº¿ä¸Šåº—é“ºã€äº”å¤§æ¸ é“ï¼‰
- æŠ¥è¡¨ç”Ÿæˆã€webå‘å¸ƒã€å¾®ä¿¡æ¨é€
- æ¨é€å†…å®¹ç²¾ç®€ï¼Œwebé“¾æ¥å•ç‹¬ä¸€æ®µ
- ä¸¥æ ¼å¯¹é½æ•´ä½“æ—¥æŠ¥æ•°æ®.pyæœ€ä½³å®è·µ
"""

import os
import sys
import glob
import pandas as pd
import requests
from datetime import datetime, timedelta
import time
import traceback
import re
import unicodedata
import subprocess
import pymysql

# ========== é…ç½®åŒº ==========
# æ•°æ®åº“é…ç½®
DB_HOST = "212.64.57.87"
DB_PORT = 3306
DB_USER = "root"
DB_PASSWORD = "c973ee9b500cc638"
DB_NAME = "Date"
DB_CHARSET = "utf8mb4"

# SSHéš§é“é…ç½®ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
SSH_HOST = "212.64.57.87"
SSH_USER = "root"
SSH_PORT = 22
LOCAL_PORT = 13306  # æœ¬åœ°è½¬å‘ç«¯å£

WECHAT_API = "http://212.64.57.87:5001/send"
WECHAT_TOKEN = "wecomchan_token"
WECHAT_USER = "weicungang"
EDGEONE_PROJECT = "sales-report"  # EdgeOne Pages é¡¹ç›®å
EDGEONE_TOKEN = "YxsKLIORJJqehzWS0UlrPKr4qgMJjikkqdJwTQ/SOYc="  # EdgeOne Pages API Token
REPORTS_DIR = "reports"

# äº‹ä¸šéƒ¨åˆ†ç»„é…ç½®ï¼ˆæŒ‰è´§å“åç§°ä¸¥æ ¼ç­›é€‰ï¼‰
BUSINESS_GROUPS = {
    "ç©ºè°ƒäº‹ä¸šéƒ¨": ["å®¶ç”¨ç©ºè°ƒ", "å•†ç”¨ç©ºè°ƒ"],
    "åˆ¶å†·äº‹ä¸šéƒ¨": ["å†°ç®±", "å†·æŸœ"],
    "æ´—æŠ¤äº‹ä¸šéƒ¨": ["æ´—è¡£æœº", "æ™¾è¡£æœº", "å¹²è¡£æœº", "çƒ˜å¹²æœº"],
    "æ°´è”ç½‘äº‹ä¸šéƒ¨": ["çƒ­æ°´å™¨", "å‡€æ°´", "é‡‡æš–", "ç”µçƒ­æ°´å™¨", "ç‡ƒæ°”çƒ­æ°´å™¨", "å¤šèƒ½æºçƒ­æ°´å™¨"],
    "å¨ç”µæ´—ç¢—æœºäº‹ä¸šéƒ¨": ["å¨ç”µ", "æ´—ç¢—æœº"]
}

# æ¸ é“åˆ†ç»„é…ç½®ï¼ˆæŒ‰åº—é“ºåç§°ä¸¥æ ¼ç­›é€‰ï¼‰
CHANNEL_GROUPS = {
    "å¡è¨å¸æ¸ é“": ["å¡è¨å¸", "å°çº¢ä¹¦"],
    "å¤©çŒ«æ¸ é“": ["å¤©çŒ«", "æ·˜å®"],
    "äº¬ä¸œæ¸ é“": ["äº¬ä¸œ"],
    "æ‹¼å¤šå¤šæ¸ é“": ["æ‹¼å¤šå¤š"],
    "æŠ–éŸ³æ¸ é“": ["æŠ–éŸ³", "å¿«æ‰‹"]
}

# å›ºå®šåˆ—å
DATE_COL = 'äº¤æ˜“æ—¶é—´'
AMOUNT_COL = 'åˆ†æ‘Šåæ€»ä»·'
QTY_COL = 'å®å‘æ•°é‡'
SHOP_COL = 'åº—é“º'
CATEGORY_COL = 'è´§å“åç§°'
MODEL_COL = 'è§„æ ¼åç§°'

# ========== å·¥å…·å‡½æ•° ==========
def check_required_columns(df):
    required_cols = [DATE_COL, AMOUNT_COL, QTY_COL, SHOP_COL, CATEGORY_COL, MODEL_COL]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        print(f"âŒ ç¼ºå°‘å¿…è¦çš„åˆ—: {missing}")
        print(f"å½“å‰åˆ—: {list(df.columns)}")
        sys.exit(1)

def check_and_fix_column_names(df):
    """æ£€æŸ¥å’Œä¿®æ­£åˆ—å"""
    print(f"ğŸ” æ£€æŸ¥åˆ—åï¼Œå½“å‰åˆ—: {list(df.columns)}")
    
    # å®šä¹‰å¯èƒ½çš„åˆ—åæ˜ å°„ï¼ˆæ‰©å±•ç‰ˆï¼‰
    column_mappings = {
        'åˆ†æ‘Šåæ€»ä»·': ['åˆ†æ‘Šåæ€»ä»·', 'æ€»ä»·', 'é‡‘é¢', 'é”€å”®é‡‘é¢', 'è®¢å•é‡‘é¢', 'å®ä»˜é‡‘é¢', 'æ”¯ä»˜é‡‘é¢', 'é€€æ¬¾å‰æ”¯ä»˜é‡‘é¢', 'åˆ†æ‘Šé‡‘é¢', 'åˆ†æ‘Šæ€»ä»·'],
        'å®å‘æ•°é‡': ['å®å‘æ•°é‡', 'æ•°é‡', 'é”€å”®æ•°é‡', 'è®¢å•æ•°é‡', 'å•†å“æ•°é‡', 'å‘è´§æ•°é‡', 'å®é™…æ•°é‡'],
        'åº—é“º': ['åº—é“º', 'åº—é“ºåç§°', 'åº—é“ºå', 'é”€å”®åº—é“º', 'æ¸ é“åº—é“º', 'é—¨åº—', 'å•†åº—'],
        'è´§å“åç§°': ['è´§å“åç§°', 'å•†å“åç§°', 'äº§å“åç§°', 'å“ç±»', 'å•†å“å“ç±»', 'äº§å“å“ç±»', 'å•†å“', 'äº§å“'],
        'è§„æ ¼åç§°': ['è§„æ ¼åç§°', 'å‹å·', 'å•†å“å‹å·', 'äº§å“å‹å·', 'è§„æ ¼', 'äº§å“è§„æ ¼', 'å•†å“è§„æ ¼'],
        'äº¤æ˜“æ—¶é—´': ['äº¤æ˜“æ—¶é—´', 'ä¸‹å•æ—¶é—´', 'è®¢å•æ—¶é—´', 'åˆ›å»ºæ—¶é—´', 'æ—¶é—´', 'æ—¥æœŸ', 'äº¤æ˜“æ—¥æœŸ', 'è®¢å•æ—¥æœŸ']
    }
    
    # æ£€æŸ¥å¹¶ä¿®æ­£åˆ—å
    fixed_columns = {}
    for target_col, possible_names in column_mappings.items():
        if target_col not in df.columns:
            found = False
            for possible_name in possible_names:
                if possible_name in df.columns:
                    print(f"   âœ… æ‰¾åˆ°åˆ—åæ˜ å°„: {possible_name} -> {target_col}")
                    fixed_columns[possible_name] = target_col
                    found = True
                    break
            if not found:
                print(f"   âŒ æœªæ‰¾åˆ°åˆ—å: {target_col}")
                print(f"      å¯èƒ½çš„åˆ—å: {possible_names}")
                print(f"      å®é™…åˆ—å: {list(df.columns)}")
        else:
            print(f"   âœ… åˆ—åå·²å­˜åœ¨: {target_col}")
    
    # æ‰§è¡Œåˆ—åé‡å‘½å
    if fixed_columns:
        df = df.rename(columns=fixed_columns)
        print(f"   ğŸ”„ å·²é‡å‘½ååˆ—: {fixed_columns}")
    
    return df

def to_number(val):
    if pd.isnull(val):
        return 0
    val = str(val).replace('ï¼Œ', '').replace(',', '').replace(' ', '').replace('\u3000', '')
    try:
        return float(val)
    except:
        return 0

def is_online_shop(shop_name):
    if not isinstance(shop_name, str):
        return False
    online_keywords = ['äº¬ä¸œ','å¤©çŒ«','æ‹¼å¤šå¤š','æŠ–éŸ³','å¡è¨å¸','å°çº¢ä¹¦','æ·˜å®','è‹å®','å›½ç¾']
    return any(kw in shop_name for kw in online_keywords)

def _send_single_message(msg):
    data = {"msg": msg, "token": WECHAT_TOKEN, "to_user": WECHAT_USER}
    try:
        resp = requests.post(WECHAT_API, json=data, timeout=15)
        print(f"ğŸ“¤ å‘é€ç»“æœ: {resp.text[:100]}...")
        return True
    except Exception as e:
        print(f"âŒ å‘é€å¼‚å¸¸: {e}")
        return False

def send_wecomchan_segment(content):
    """åˆ†æ®µå‘é€ï¼Œç¡®ä¿é“¾æ¥ä¼˜å…ˆå‘é€"""
    max_chars = 1500  # ä¿®æ­£å­—ç¬¦é™åˆ¶ä¸º1500
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«é“¾æ¥
    link_pattern = r'ğŸŒ æŸ¥çœ‹å®Œæ•´Webé¡µé¢: (https://[^\s]+)'
    link_match = re.search(link_pattern, content)
    
    if link_match:
        link = link_match.group(1)
        link_text = f"ğŸŒ æŸ¥çœ‹å®Œæ•´Webé¡µé¢: {link}"
        content_without_link = content.replace(link_text, "").strip()
        
        # å¦‚æœå†…å®¹é•¿åº¦è¶…è¿‡é™åˆ¶ï¼Œä¼˜å…ˆä¿è¯é“¾æ¥å‘é€
        if len(content) > max_chars:
            print(f"âš ï¸ å†…å®¹è¿‡é•¿({len(content)}å­—ç¬¦)ï¼Œä¼˜å…ˆä¿è¯é“¾æ¥å‘é€")
            # æˆªæ–­å†…å®¹ä½†ä¿ç•™é“¾æ¥
            available_chars = max_chars - len(link_text) - 10  # é¢„ç•™ä¸€äº›ç©ºé—´
            if available_chars > 0:
                truncated_content = content_without_link[:available_chars] + "..."
                final_content = truncated_content + "\n" + link_text
            else:
                # å¦‚æœè¿é“¾æ¥éƒ½æ”¾ä¸ä¸‹ï¼Œåªå‘é€é“¾æ¥
                final_content = link_text
        else:
            final_content = content
        
        print(f"ğŸ“¤ å‘é€æ¶ˆæ¯ï¼Œé•¿åº¦: {len(final_content)}å­—ç¬¦")
        success = _send_single_message(final_content)
        if not success:
            print("âŒ æ¶ˆæ¯å‘é€å¤±è´¥")
    else:
        # æ²¡æœ‰é“¾æ¥çš„æƒ…å†µï¼Œæ­£å¸¸åˆ†æ®µå‘é€
        if len(content) <= max_chars:
            success = _send_single_message(content)
            if not success:
                print("âŒ æ¶ˆæ¯å‘é€å¤±è´¥")
        else:
            print(f"âš ï¸ å†…å®¹è¿‡é•¿({len(content)}å­—ç¬¦)ï¼Œè¿›è¡Œæ™ºèƒ½åˆ†æ®µ")
            segments = _smart_split_content(content, max_chars)
            for segment in segments:
                success = _send_single_message(segment)
                if not success:
                    print("âŒ æ¶ˆæ¯å‘é€å¤±è´¥")
                time.sleep(2)

def _smart_split_content(content, max_chars):
    """æ™ºèƒ½åˆ†å‰²å†…å®¹"""
    # æŒ‰ç…§è‡ªç„¶åˆ†æ®µç¬¦åˆ†å‰²
    natural_breaks = ['\n\n', '\nâ”â”â”', '\n===', '\n---', '\nğŸ“Š', '\nğŸ”¥', '\nğŸ’°']
    
    segments = []
    current_segment = ""
    
    lines = content.split('\n')
    for line in lines:
        if len(current_segment + line + '\n') > max_chars:
            if current_segment:
                segments.append(current_segment.strip())
                current_segment = line + '\n'
            else:
                # å•è¡Œå¤ªé•¿ï¼Œå¼ºåˆ¶æˆªæ–­
                segments.append(line[:max_chars])
                current_segment = ""
        else:
            current_segment += line + '\n'
    
    if current_segment.strip():
        segments.append(current_segment.strip())
    
    return segments

def calculate_ratio(current, previous):
    if previous == 0:
        return "ğŸ“ˆ 100%" if current > 0 else "0%"
    ratio = ((current - previous) / previous) * 100
    if ratio > 0:
        return f"ğŸ“ˆ {ratio:.1f}%"
    elif ratio < 0:
        return f"ğŸ“‰ {ratio:.1f}%"
    else:
        return "0%"

def to_pinyin(s):
    mapping = {
        'ç©ºè°ƒäº‹ä¸šéƒ¨': 'kongtiaoshiyebu',
        'åˆ¶å†·äº‹ä¸šéƒ¨': 'zhilingshiyebu',
        'æ´—æŠ¤äº‹ä¸šéƒ¨': 'xihushiyebu',
        'æ°´è”ç½‘äº‹ä¸šéƒ¨': 'shuilianwangshiyebu',
        'å¨ç”µæ´—ç¢—æœºäº‹ä¸šéƒ¨': 'chudianxiwangjishiyebu',
        'å¡è¨å¸æ¸ é“': 'kasadiqudao',
        'å¤©çŒ«æ¸ é“': 'tianmaoqudao',
        'äº¬ä¸œæ¸ é“': 'jingdongqudao',
        'æ‹¼å¤šå¤šæ¸ é“': 'pinduoduoqudao',
        'æŠ–éŸ³æ¸ é“': 'douyinqudao'
    }
    if s in mapping:
        return mapping[s]
    s_ascii = unicodedata.normalize('NFKD', s).encode('ascii', 'ignore').decode('ascii')
    s_ascii = re.sub(r'[^a-zA-Z0-9_]', '', s_ascii)
    return s_ascii.lower() or 'report'

def generate_html_content(title_cn, content_text):
    """ç»Ÿä¸€çš„HTMLç”Ÿæˆå‡½æ•°ï¼Œç¡®ä¿æ‰€æœ‰æŠ¥å‘Šä½¿ç”¨ç›¸åŒçš„æ ¼å¼"""
    html_content = f'''<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
    <title>{title_cn}</title>
    <style>
        body {{ font-family: 'Microsoft YaHei', 'å¾®è½¯é›…é»‘', Arial, sans-serif; background: #f8f9fa; color: #222; margin: 0; padding: 0.5em; max-width: 900px; margin-left:auto; margin-right:auto; text-align: left; font-size: 10.5pt; }}
        h1, h2, h3 {{ color: #0056b3; text-align: left; font-family: 'Microsoft YaHei', 'å¾®è½¯é›…é»‘', Arial, sans-serif; font-size: 14pt; font-weight: bold; margin: 0.3em 0; }}
        pre, code {{ background: #f3f3f3; padding: 0.5em; border-radius: 4px; white-space: pre-wrap; word-break: break-all; text-align: left; font-family: 'Microsoft YaHei', 'å¾®è½¯é›…é»‘', Arial, sans-serif; margin: 0.3em 0; }}
        .growth-positive {{ background-color: #e6f4ea !important; }}
        .growth-negative {{ background-color: #fbeaea !important; }}
        .section {{ margin-bottom: 2em; text-align: left; }}
        .highlight {{ color: #d63384; font-weight: bold; }}
        .emoji {{ font-size: 1.2em; }}
        @media (max-width: 600px) {{
            body {{ padding: 0.5em; font-size: 10.5pt; }}
            h1 {{ font-size: 14pt; }}
        }}
        .left-align {{ text-align: left !important; }}
    </style>
</head>
<body>
    <h1>{title_cn}</h1>
    <div class="section left-align">
        <pre>
{content_text}
        </pre>
    </div>
    <footer style="margin-top:2em;color:#888;font-size:0.9em;">è‡ªåŠ¨ç”Ÿæˆ | Powered by EdgeOne Pages & ä¼ä¸šå¾®ä¿¡æœºå™¨äºº</footer>
</body>
</html>'''
    return html_content

# ========== æ•°æ®è¯»å–ä¸é¢„å¤„ç† ==========
print("\nğŸš€ å¤šäº‹ä¸šéƒ¨æ—¥æŠ¥æ•°æ®åˆ†æç³»ç»Ÿå¯åŠ¨...")

# æ­¥éª¤2: è¯»å–ERPé”€å”®æ•°æ®
print("ğŸ“Š æ­£åœ¨ä»æ•°æ®åº“è¯»å–ERPè®¢å•æ˜ç»†æ•°æ®...")

# è·å–å‰ä¸€å¤©æ—¥æœŸä½œä¸ºæŠ¥å‘Šæ—¥æœŸ
yesterday = datetime.now() - timedelta(days=1)
yesterday_str = yesterday.strftime('%Y-%m-%d')

try:
    conn = pymysql.connect(
        host=DB_HOST, port=DB_PORT, user=DB_USER, 
        password=DB_PASSWORD, database=DB_NAME, charset=DB_CHARSET,
        connect_timeout=10
    )
    df_erp = pd.read_sql(f"SELECT * FROM Daysales WHERE äº¤æ˜“æ—¶é—´ LIKE '{yesterday_str}%'", conn)
    conn.close()
    print(f"ğŸ“Š ç›´æ¥è¿æ¥æˆåŠŸï¼Œå…±{len(df_erp)}è¡Œ")
except Exception as e:
    print(f"âŒ ç›´æ¥è¿æ¥æ•°æ®åº“å¤±è´¥: {e}")
    sys.exit(1)
    
# åç»­åˆ†æé€»è¾‘ä¿æŒä¸å˜ï¼Œdf_erpå³ä¸ºä¸»æ•°æ®æº

# ç«‹å³æ£€æŸ¥å’Œä¿®æ­£åˆ—å
df_erp = check_and_fix_column_names(df_erp)
check_required_columns(df_erp)

# 2. æ•°æ®æ¸…æ´—
for col in [AMOUNT_COL, QTY_COL]:
    df_erp[col] = df_erp[col].apply(to_number)
df_erp = df_erp[(df_erp[AMOUNT_COL] > 0) & (df_erp[QTY_COL] > 0)]

# å‰”é™¤åˆ·å• - ä¿®æ­£é€»è¾‘ï¼šåŒ…å«"æŠ½çº¸"æˆ–"çº¸å·¾"æˆ–ç­‰äº"ä¸å‘è´§"çš„éƒ½å‰”é™¤
if 'å®¢æœå¤‡æ³¨' in df_erp.columns:
    before = len(df_erp)
    df_erp = df_erp[~(df_erp['å®¢æœå¤‡æ³¨'].astype(str).str.contains('æŠ½çº¸|çº¸å·¾') | (df_erp['å®¢æœå¤‡æ³¨'] == 'ä¸å‘è´§'))]
    print(f"åˆ·å•è¿‡æ»¤: {before} -> {len(df_erp)}")

# å‰”é™¤æœªä»˜æ¬¾/å·²å–æ¶ˆ/å·²é€€æ¬¾è®¢å• - æ·»åŠ å·²é€€æ¬¾çŠ¶æ€
order_status_col = next((c for c in df_erp.columns if 'è®¢å•çŠ¶æ€' in c or 'çŠ¶æ€' in c), None)
if order_status_col:
    before = len(df_erp)
    df_erp = df_erp[~df_erp[order_status_col].astype(str).str.contains('æœªä»˜æ¬¾|å·²å–æ¶ˆ|å·²é€€æ¬¾')]
    print(f"è®¢å•çŠ¶æ€è¿‡æ»¤: {before} -> {len(df_erp)}")

# åªä¿ç•™çº¿ä¸Šåº—é“º
before = len(df_erp)
df_erp = df_erp[df_erp[SHOP_COL].apply(is_online_shop)]
print(f"çº¿ä¸Šåº—é“ºè¿‡æ»¤: {before} -> {len(df_erp)}")

# åªä¿ç•™äº”å¤§æ¸ é“åº—é“º
channel_keywords = sum(CHANNEL_GROUPS.values(), [])
def is_five_channel(shop):
    if not isinstance(shop, str):
        return False
    # å¡è¨å¸ä¼˜å…ˆ
    if any(kw in shop for kw in CHANNEL_GROUPS['å¡è¨å¸æ¸ é“']):
        return True
    if any(kw in shop for kw in CHANNEL_GROUPS['äº¬ä¸œæ¸ é“']):
        return True
    if any(kw in shop for kw in CHANNEL_GROUPS['å¤©çŒ«æ¸ é“']) and not any(kw in shop for kw in CHANNEL_GROUPS['å¡è¨å¸æ¸ é“']):
        return True
    if any(kw in shop for kw in CHANNEL_GROUPS['æ‹¼å¤šå¤šæ¸ é“']):
        return True
    if any(kw in shop for kw in CHANNEL_GROUPS['æŠ–éŸ³æ¸ é“']):
        return True
    return False

before = len(df_erp)
df_erp = df_erp[df_erp[SHOP_COL].apply(is_five_channel)]
print(f"äº”å¤§æ¸ é“è¿‡æ»¤: {before} -> {len(df_erp)}")

# è¿‡æ»¤å‰ä¸€å¤©çš„æ•°æ®
before = len(df_erp)
# å¤„ç†æ—¥æœŸæ ¼å¼é—®é¢˜
if df_erp[DATE_COL].dtype == 'timedelta64[ns]':
    print("ğŸ”„ æ£€æµ‹åˆ°timedeltaæ ¼å¼ï¼Œè½¬æ¢ä¸ºæ—¥æœŸ...")
    # ä½¿ç”¨åŸºå‡†æ—¥æœŸ2024-01-01
    base_date = pd.Timestamp('2024-01-01')
    df_erp[DATE_COL] = base_date + df_erp[DATE_COL]
elif df_erp[DATE_COL].dtype == 'object':
    print("ğŸ”„ æ£€æµ‹åˆ°objectæ ¼å¼ï¼Œè½¬æ¢ä¸ºdatetime...")
    df_erp[DATE_COL] = pd.to_datetime(df_erp[DATE_COL], errors='coerce')

# è¿‡æ»¤å‰ä¸€å¤©çš„æ•°æ®
target_date = (datetime.now() - timedelta(days=1)).date()
df_erp = df_erp[df_erp[DATE_COL].dt.date == target_date]
print(f"å‰ä¸€å¤©æ•°æ®è¿‡æ»¤: {before} -> {len(df_erp)}")

# 3. è¯»å–å‰å‰ä¸€å¤©æ•°æ®ç”¨äºç¯æ¯”
prev_date = (datetime.now() - timedelta(days=2)).strftime('%Y-%m-%d')
prev_sql = f"SELECT * FROM Daysales WHERE äº¤æ˜“æ—¶é—´ LIKE '{prev_date}%'"

df_prev = None
try:
    # å°è¯•ç›´æ¥è¿æ¥
    conn = pymysql.connect(
        host=DB_HOST, port=DB_PORT, user=DB_USER, 
        password=DB_PASSWORD, database=DB_NAME, charset=DB_CHARSET,
        connect_timeout=10
    )
    df_prev = pd.read_sql(prev_sql, conn)
    conn.close()
    print(f"ğŸ“Š å‰å‰ä¸€å¤©æ•°æ®è¯»å–æˆåŠŸï¼Œå…±{len(df_prev)}è¡Œ")
    
    # æ£€æŸ¥å’Œä¿®æ­£åˆ—å
    df_prev = check_and_fix_column_names(df_prev)
    check_required_columns(df_prev)
    
    # æ•°æ®æ¸…æ´—
    for col in [AMOUNT_COL, QTY_COL]:
        df_prev[col] = df_prev[col].apply(to_number)
    df_prev = df_prev[(df_prev[AMOUNT_COL] > 0) & (df_prev[QTY_COL] > 0)]
    
    # å‰”é™¤åˆ·å• - ä¸å½“å¤©æ•°æ®ä½¿ç”¨ç›¸åŒçš„ç­›é€‰æ¡ä»¶
    if 'å®¢æœå¤‡æ³¨' in df_prev.columns:
        before = len(df_prev)
        df_prev = df_prev[~(df_prev['å®¢æœå¤‡æ³¨'].astype(str).str.contains('æŠ½çº¸|çº¸å·¾') | (df_prev['å®¢æœå¤‡æ³¨'] == 'ä¸å‘è´§'))]
        print(f"å‰ä¸€å¤©åˆ·å•è¿‡æ»¤: {before} -> {len(df_prev)}")
    
    # å‰”é™¤æœªä»˜æ¬¾/å·²å–æ¶ˆ/å·²é€€æ¬¾è®¢å• - ä¸å½“å¤©æ•°æ®ä½¿ç”¨ç›¸åŒçš„ç­›é€‰æ¡ä»¶
    order_status_col_prev = next((c for c in df_prev.columns if 'è®¢å•çŠ¶æ€' in c or 'çŠ¶æ€' in c), None)
    if order_status_col_prev:
        before = len(df_prev)
        df_prev = df_prev[~df_prev[order_status_col_prev].astype(str).str.contains('æœªä»˜æ¬¾|å·²å–æ¶ˆ|å·²é€€æ¬¾')]
        print(f"å‰ä¸€å¤©è®¢å•çŠ¶æ€è¿‡æ»¤: {before} -> {len(df_prev)}")
    
    df_prev = df_prev[df_prev[SHOP_COL].apply(is_online_shop)]
    df_prev = df_prev[df_prev[SHOP_COL].apply(is_five_channel)]
    
    # è¿‡æ»¤å‰å‰ä¸€å¤©çš„æ•°æ®
    before = len(df_prev)
    # å¤„ç†æ—¥æœŸæ ¼å¼é—®é¢˜
    if df_prev[DATE_COL].dtype == 'timedelta64[ns]':
        print("ğŸ”„ å‰å‰ä¸€å¤©æ•°æ®æ£€æµ‹åˆ°timedeltaæ ¼å¼ï¼Œè½¬æ¢ä¸ºæ—¥æœŸ...")
        # ä½¿ç”¨åŸºå‡†æ—¥æœŸ2024-01-01
        base_date = pd.Timestamp('2024-01-01')
        df_prev[DATE_COL] = base_date + df_prev[DATE_COL]
    elif df_prev[DATE_COL].dtype == 'object':
        print("ğŸ”„ å‰å‰ä¸€å¤©æ•°æ®æ£€æµ‹åˆ°objectæ ¼å¼ï¼Œè½¬æ¢ä¸ºdatetime...")
        df_prev[DATE_COL] = pd.to_datetime(df_prev[DATE_COL], errors='coerce')
    
    # è¿‡æ»¤å‰å‰ä¸€å¤©çš„æ•°æ®
    target_date_prev = (datetime.now() - timedelta(days=2)).date()
    df_prev = df_prev[df_prev[DATE_COL].dt.date == target_date_prev]
    print(f"å‰å‰ä¸€å¤©æ•°æ®è¿‡æ»¤: {before} -> {len(df_prev)}")
    
except Exception as e:
    print(f"âš ï¸ å‰å‰ä¸€å¤©æ•°æ®è¯»å–å¤±è´¥: {e}")
    df_prev = None

# ========== æŠ¥è¡¨ç”Ÿæˆä¸æ¨é€ ==========
# æ¸ é“å½’ç±»å‡½æ•°
CHANNEL_NAME_MAP = {
    "å¡è¨å¸æ¸ é“": "å¡è¨å¸æ¸ é“",
    "å°çº¢ä¹¦": "å¡è¨å¸æ¸ é“",
    "å¤©çŒ«æ¸ é“": "å¤©çŒ«æ¸ é“",
    "æ·˜å®æ¸ é“": "å¤©çŒ«æ¸ é“",
    "äº¬ä¸œæ¸ é“": "äº¬ä¸œæ¸ é“",
    "æ‹¼å¤šå¤šæ¸ é“": "æ‹¼å¤šå¤šæ¸ é“",
    "æŠ–éŸ³æ¸ é“": "æŠ–éŸ³æ¸ é“",
    "å¿«æ‰‹æ¸ é“": "æŠ–éŸ³æ¸ é“"
}
def classify_channel(shop_name):
    if not isinstance(shop_name, str):
        return "å…¶ä»–"
    # å¡è¨å¸ä¼˜å…ˆ
    if any(kw in shop_name for kw in CHANNEL_GROUPS['å¡è¨å¸æ¸ é“']):
        return "å¡è¨å¸æ¸ é“"
    if any(kw in shop_name for kw in CHANNEL_GROUPS['äº¬ä¸œæ¸ é“']):
        return "äº¬ä¸œæ¸ é“"
    if any(kw in shop_name for kw in CHANNEL_GROUPS['å¤©çŒ«æ¸ é“']) and not any(kw in shop_name for kw in CHANNEL_GROUPS['å¡è¨å¸æ¸ é“']):
        return "å¤©çŒ«æ¸ é“"
    if any(kw in shop_name for kw in CHANNEL_GROUPS['æ‹¼å¤šå¤šæ¸ é“']):
        return "æ‹¼å¤šå¤šæ¸ é“"
    if any(kw in shop_name for kw in CHANNEL_GROUPS['æŠ–éŸ³æ¸ é“']):
        return "æŠ–éŸ³æ¸ é“"
    return "å…¶ä»–"

def generate_group_report(group_name, group_type, keywords, df, df_prev, report_date):
    if group_type == 'business':
        group_df = df[df[CATEGORY_COL].apply(lambda x: any(kw in str(x) for kw in keywords))]
        prev_group_df = df_prev[df_prev[CATEGORY_COL].apply(lambda x: any(kw in str(x) for kw in keywords))] if df_prev is not None else None
    else:
        # æ¸ é“åˆ†ç»„ï¼Œå¡è¨å¸ä¼˜å…ˆ
        if group_name == 'å¡è¨å¸æ¸ é“':
            group_df = df[df[SHOP_COL].apply(lambda x: any(kw in str(x) for kw in keywords))]
            prev_group_df = df_prev[df_prev[SHOP_COL].apply(lambda x: any(kw in str(x) for kw in keywords))] if df_prev is not None else None
        elif group_name == 'å¤©çŒ«æ¸ é“':
            group_df = df[df[SHOP_COL].apply(lambda x: (any(kw in str(x) for kw in keywords)) and not any(kw in str(x) for kw in CHANNEL_GROUPS['å¡è¨å¸æ¸ é“']))]
            prev_group_df = df_prev[df_prev[SHOP_COL].apply(lambda x: (any(kw in str(x) for kw in keywords)) and not any(kw in str(x) for kw in CHANNEL_GROUPS['å¡è¨å¸æ¸ é“']))] if df_prev is not None else None
        else:
            group_df = df[df[SHOP_COL].apply(lambda x: any(kw in str(x) for kw in keywords))]
            prev_group_df = df_prev[df_prev[SHOP_COL].apply(lambda x: any(kw in str(x) for kw in keywords))] if df_prev is not None else None
    
    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
    print(f"ğŸ” {group_name} åŒ¹é…æ•°æ®é‡: {len(group_df)} è¡Œ")
    if len(group_df) > 0:
        print(f"   ğŸ“‹ å…³é”®è¯: {keywords}")
        if group_type == 'business':
            print(f"   ğŸ·ï¸ åŒ¹é…çš„å“ç±»: {group_df[CATEGORY_COL].unique()[:5].tolist()}")
        else:
            print(f"   ğŸª åŒ¹é…çš„åº—é“º: {group_df[SHOP_COL].unique()[:5].tolist()}")
    
    if group_df.empty:
        # æ²¡æœ‰æ•°æ®æ—¶ç”Ÿæˆç©ºæ•°æ®é¡µé¢
        content = f"ğŸ¢ {group_name}æ—¥æŠ¥\nğŸ“… æ•°æ®æ—¥æœŸ: {report_date}\n\nâš ï¸ ä»Šæ—¥æš‚æ— é”€å”®æ•°æ®"
        title_cn = f"{group_name}æ—¥æŠ¥ï¼ˆ{report_date}ï¼‰"
        empty_content = f"""ğŸ¢ {group_name}æ—¥æŠ¥
ğŸ“… æ•°æ®æ—¥æœŸ: {report_date}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš ï¸ ä»Šæ—¥æš‚æ— é”€å”®æ•°æ®
è¯¥äº‹ä¸šéƒ¨/æ¸ é“ä»Šæ—¥æš‚æ— é”€å”®æ•°æ®ï¼Œè¯·æŸ¥çœ‹å…¶ä»–æ—¶é—´æ®µçš„æŠ¥å‘Šã€‚"""
        
        html_content = generate_html_content(title_cn, empty_content)
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ”§ {group_name} ç©ºæ•°æ®é¡µé¢HTMLç”Ÿæˆè°ƒè¯•ä¿¡æ¯:")
        print(f"   å†…å®¹é•¿åº¦: {len(html_content)} å­—ç¬¦")
        print(f"   ä½¿ç”¨ç»Ÿä¸€HTMLç”Ÿæˆå‡½æ•°: âœ…")
        
        file_prefix = to_pinyin(group_name)
        filename = f"{file_prefix}_{report_date}.html".replace('/', '-')
        script_dir = os.path.dirname(os.path.abspath(__file__))
        reports_dir = os.path.join(script_dir, "reports")
        os.makedirs(reports_dir, exist_ok=True)
        filepath = os.path.join(reports_dir, filename)
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(html_content)
        return content, filename
    
    # æœ‰æ•°æ®æ—¶çš„æ­£å¸¸å¤„ç†é€»è¾‘
    # æ•´ä½“æ•°æ®
    total_amount = int(group_df[AMOUNT_COL].sum())
    total_qty = int(group_df[QTY_COL].sum())
    avg_price = int(total_amount / total_qty) if total_qty else 0
    prev_amount = int(prev_group_df[AMOUNT_COL].sum()) if prev_group_df is not None and not prev_group_df.empty else 0
    prev_qty = int(prev_group_df[QTY_COL].sum()) if prev_group_df is not None and not prev_group_df.empty else 0
    prev_avg_price = int(prev_amount / prev_qty) if prev_qty else 0
    # å“ç±»æ˜ç»†
    category_data = group_df.groupby(CATEGORY_COL).agg({AMOUNT_COL: 'sum', QTY_COL: 'sum'}).reset_index()
    category_data = category_data.sort_values(AMOUNT_COL, ascending=False)
    prev_category_data = None
    if prev_group_df is not None:
        prev_category_data = prev_group_df.groupby(CATEGORY_COL).agg({AMOUNT_COL: 'sum', QTY_COL: 'sum'}).reset_index()
    
    # æ¸ é“æ•°æ®ï¼ˆä»…äº‹ä¸šéƒ¨ï¼ŒæŒ‰äº”å¤§æ¸ é“èšåˆï¼‰
    channel_data = None
    prev_channel_data = None
    if group_type == 'business':
        group_df = group_df.copy()
        group_df['æ¸ é“'] = group_df[SHOP_COL].apply(classify_channel)
        channel_data = group_df.groupby('æ¸ é“').agg({AMOUNT_COL: 'sum', QTY_COL: 'sum'}).reset_index()
        channel_data = channel_data[channel_data['æ¸ é“'].isin(CHANNEL_GROUPS.keys())]
        channel_data = channel_data.sort_values(AMOUNT_COL, ascending=False)
        if prev_group_df is not None:
            prev_group_df = prev_group_df.copy()
            prev_group_df['æ¸ é“'] = prev_group_df[SHOP_COL].apply(classify_channel)
            prev_channel_data = prev_group_df.groupby('æ¸ é“').agg({AMOUNT_COL: 'sum', QTY_COL: 'sum'}).reset_index()
    
    # åº—é“ºæ•°æ® - åœ¨group_dfè¢«ä¿®æ”¹ä¹‹å‰ç”Ÿæˆ
    shop_data = group_df.groupby(SHOP_COL).agg({AMOUNT_COL: 'sum', QTY_COL: 'sum'}).reset_index()
    shop_data = shop_data.sort_values(AMOUNT_COL, ascending=False)
    prev_shop_data = None
    if prev_group_df is not None:
        prev_shop_data = prev_group_df.groupby(SHOP_COL).agg({AMOUNT_COL: 'sum', QTY_COL: 'sum'}).reset_index()
    # TOPå•å“
    product_data = group_df.groupby(MODEL_COL).agg({AMOUNT_COL: 'sum', QTY_COL: 'sum'}).reset_index()
    product_data = product_data[product_data[AMOUNT_COL] > 1000]  # é˜ˆå€¼ä»5000é™åˆ°1000
    product_data = product_data.sort_values(AMOUNT_COL, ascending=False)
    
    # ---------- ç»Ÿä¸€åˆ†æ®µç‰ˆ ----------
    web_content = f"""ğŸ¢ {group_name}æ—¥æŠ¥
ğŸ“… æ•°æ®æ—¥æœŸ: {report_date}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š æ•´ä½“æ•°æ®
æ€»é”€å”®é¢: Â¥{total_amount:,}ï¼ˆç¯æ¯”:{calculate_ratio(total_amount, prev_amount)}ï¼‰
æ€»é”€é‡: {total_qty}ä»¶ï¼ˆç¯æ¯”:{calculate_ratio(total_qty, prev_qty)}ï¼‰
å¹³å‡å•ä»·: Â¥{avg_price:,}ï¼ˆç¯æ¯”:{calculate_ratio(avg_price, prev_avg_price)}ï¼‰

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ å“ç±»æ˜ç»†"""
    for _, row in category_data.iterrows():
        cat = row[CATEGORY_COL]
        amount = int(row[AMOUNT_COL])
        qty = int(row[QTY_COL])
        price = int(amount / qty) if qty else 0
        prev_amount_cat = int(prev_category_data.loc[prev_category_data[CATEGORY_COL] == cat, AMOUNT_COL].sum()) if prev_category_data is not None else 0
        web_content += f"\nâ€¢ {cat}: Â¥{amount:,} ({calculate_ratio(amount, prev_amount_cat)})ï¼Œ{qty}ä»¶ | å•ä»·: Â¥{price:,}"

    if group_type == 'business' and channel_data is not None and not channel_data.empty:
        web_content += "\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nğŸª æ¸ é“æ•°æ®"
        for _, row in channel_data.iterrows():
            channel = row['æ¸ é“']
            amount = int(row[AMOUNT_COL])
            qty = int(row[QTY_COL])
            price = int(amount / qty) if qty else 0
            prev_amount_channel = int(prev_channel_data.loc[prev_channel_data['æ¸ é“'] == channel, AMOUNT_COL].sum()) if prev_channel_data is not None else 0
            web_content += f"\nâ€¢ {channel}: Â¥{amount:,} ({calculate_ratio(amount, prev_amount_channel)})ï¼Œ{qty}ä»¶ | å•ä»·: Â¥{price:,}"

    if shop_data is not None and not shop_data.empty:
        web_content += "\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nğŸª åº—é“ºæ•°æ®"
        for _, row in shop_data.head(10).iterrows():
            shop = row[SHOP_COL]
            amount = int(row[AMOUNT_COL])
            qty = int(row[QTY_COL])
            prev_amount_shop = int(prev_shop_data.loc[prev_shop_data[SHOP_COL] == shop, AMOUNT_COL].sum()) if prev_shop_data is not None else 0
            web_content += f"\nâ€¢ {shop}: Â¥{amount:,} ({calculate_ratio(amount, prev_amount_shop)})ï¼Œ{qty}ä»¶"

    if product_data is not None and not product_data.empty:
        web_content += "\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nğŸ† TOP å•å“"
        for _, row in product_data.head(10).iterrows():
            model = row[MODEL_COL]
            amount = int(row[AMOUNT_COL])
            qty = int(row[QTY_COL])
            price = int(amount / qty) if qty else 0
            # è®¡ç®—ç¯æ¯”æ•°æ®
            prev_amount_product = 0
            if df_prev is not None:
                prev_product = df_prev[df_prev[MODEL_COL] == model]
                if not prev_product.empty:
                    prev_amount_product = int(prev_product[AMOUNT_COL].sum())
            ratio_str = f"ï¼Œå‰ä¸€å¤© Â¥{prev_amount_product:,}ï¼Œç¯æ¯” {calculate_ratio(amount, prev_amount_product)}"
            web_content += f"\nâ€¢ {model}: Â¥{amount:,}ï¼Œ{qty}ä»¶ | å•ä»·: Â¥{price:,}{ratio_str}"

    web_content += "\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nğŸ“‹ åº—é“ºå•å“æ˜ç»†"
    if shop_data is not None and not shop_data.empty:
        for _, shop_row in shop_data.head(10).iterrows():
            shop = shop_row[SHOP_COL]
            shop_products = df[df[SHOP_COL] == shop].groupby(MODEL_COL).agg({
                AMOUNT_COL: 'sum', QTY_COL: 'sum'
            }).reset_index()
            shop_products = shop_products[(shop_products[AMOUNT_COL] > 100) & ~shop_products[MODEL_COL].str.contains('è¿è´¹|èµ å“')]
            shop_products = shop_products.sort_values(AMOUNT_COL, ascending=False).head(5)
            web_content += f"\n\nğŸª ã€{shop}ã€‘æ ¸å¿ƒäº§å“"
            if not shop_products.empty:
                for _, p in shop_products.iterrows():
                    price = int(p[AMOUNT_COL] / p[QTY_COL]) if p[QTY_COL] else 0
                    # è®¡ç®—ç¯æ¯”æ•°æ®
                    prev_amount_product = 0
                    if df_prev is not None:
                        prev_product = df_prev[(df_prev[MODEL_COL] == p[MODEL_COL]) & (df_prev[SHOP_COL] == shop)]
                        if not prev_product.empty:
                            prev_amount_product = int(prev_product[AMOUNT_COL].sum())
                    ratio_str = f"ï¼Œå‰ä¸€å¤© Â¥{prev_amount_product:,}ï¼Œç¯æ¯” {calculate_ratio(int(p[AMOUNT_COL]), prev_amount_product)}"
                    web_content += f"\nâ”œâ”€ ğŸ”¸ {p[MODEL_COL]}"
                    web_content += f"\nâ”œâ”€ é”€å”®é¢: Â¥{int(p[AMOUNT_COL]):,} | é”€é‡: {int(p[QTY_COL])}ä»¶ | å•ä»·: Â¥{price:,}{ratio_str}"
    else:
        web_content += "\n  æš‚æ— åº—é“ºæ•°æ®"

    # ç”Ÿæˆçº¯æ–‡æœ¬ç‰ˆæœ¬ç”¨äºå¾®ä¿¡å‘é€ - ç®€åŒ–å†…å®¹ï¼Œç§»é™¤åº—é“ºå•å“æ˜ç»†ï¼Œä¿æŒåŸæœ‰æ ¼å¼
    content = f"ğŸ¢ {group_name}æ—¥æŠ¥\nğŸ“… æ•°æ®æ—¥æœŸ: {report_date}\n\n"
    content += f"ğŸ“Š æ•´ä½“æ•°æ®\næ€»é”€å”®é¢: Â¥{total_amount:,}ï¼ˆç¯æ¯”:{calculate_ratio(total_amount, prev_amount)}ï¼‰\næ€»é”€é‡: {total_qty}ä»¶ï¼ˆç¯æ¯”:{calculate_ratio(total_qty, prev_qty)}ï¼‰\nå¹³å‡å•ä»·: Â¥{avg_price:,}\n\n"
    
    # å“ç±»æ˜ç»† - åªæ˜¾ç¤ºå‰3ä¸ª
    content += "ğŸ“‹ å“ç±»æ˜ç»†\n"
    for i, (_, row) in enumerate(category_data.iterrows()):
        if i >= 3:  # åªæ˜¾ç¤ºå‰3ä¸ªå“ç±»
            break
        cat = row[CATEGORY_COL]
        amount = int(row[AMOUNT_COL])
        qty = int(row[QTY_COL])
        price = int(amount / qty) if qty else 0
        prev_amount_cat = 0
        if prev_category_data is not None:
            prev_row = prev_category_data[prev_category_data[CATEGORY_COL] == cat]
            if not prev_row.empty:
                prev_amount_cat = int(prev_row.iloc[0][AMOUNT_COL])
        content += f"â€¢ {cat}: Â¥{amount:,} ({calculate_ratio(amount, prev_amount_cat)})ï¼Œ{qty}ä»¶\n"
    
    # æ¸ é“æ•°æ®ï¼ˆä»…äº‹ä¸šéƒ¨ï¼Œäº”å¤§æ¸ é“èšåˆï¼‰- åªæ˜¾ç¤ºå‰3ä¸ª
    if group_type == 'business' and channel_data is not None and not channel_data.empty:
        content += "\nğŸª æ¸ é“æ•°æ®\n"
        for i, (_, row) in enumerate(channel_data.iterrows()):
            if i >= 3:  # åªæ˜¾ç¤ºå‰3ä¸ªæ¸ é“
                break
            channel = row['æ¸ é“']
            amount = int(row[AMOUNT_COL])
            qty = int(row[QTY_COL])
            price = int(amount / qty) if qty else 0
            prev_amount_channel = 0
            if prev_channel_data is not None:
                prev_row = prev_channel_data[prev_channel_data['æ¸ é“'] == channel]
                if not prev_row.empty:
                    prev_amount_channel = int(prev_row.iloc[0][AMOUNT_COL])
            content += f"â€¢ {channel}: Â¥{amount:,} ({calculate_ratio(amount, prev_amount_channel)})ï¼Œ{qty}ä»¶\n"
    
    # åº—é“ºæ•°æ® - ç§»åˆ°æœ€åä¸€ä¸ªéƒ¨åˆ†ï¼Œåªæ˜¾ç¤ºå‰3ä¸ª
    if shop_data is not None and not shop_data.empty:
        content += "\nğŸª åº—é“ºæ•°æ®\n"
        for i, (_, row) in enumerate(shop_data.iterrows()):
            if i >= 3:  # åªæ˜¾ç¤ºå‰3ä¸ªåº—é“º
                break
            shop = row[SHOP_COL]
            amount = int(row[AMOUNT_COL])
            qty = int(row[QTY_COL])
            prev_amount_shop = 0
            if prev_shop_data is not None:
                prev_row = prev_shop_data[prev_shop_data[SHOP_COL] == shop]
                if not prev_row.empty:
                    prev_amount_shop = int(prev_row.iloc[0][AMOUNT_COL])
            content += f"â€¢ {shop}: Â¥{amount:,} ({calculate_ratio(amount, prev_amount_shop)})ï¼Œ{qty}ä»¶\n"
    
    # TOPå•å“ - ç§»åˆ°åº—é“ºæ•°æ®åé¢ï¼Œåªæ˜¾ç¤ºå‰3ä¸ª
    if product_data is not None and not product_data.empty:
        content += "\nğŸ† TOPå•å“\n"
        for i, (_, row) in enumerate(product_data.iterrows()):
            if i >= 3:  # åªæ˜¾ç¤ºå‰3ä¸ªå•å“
                break
            model = row[MODEL_COL]
            amount = int(row[AMOUNT_COL])
            qty = int(row[QTY_COL])
            price = int(amount / qty) if qty else 0
            # è®¡ç®—ç¯æ¯”æ•°æ®
            prev_amount_product = 0
            if df_prev is not None:
                prev_product = df_prev[df_prev[MODEL_COL] == model]
                if not prev_product.empty:
                    prev_amount_product = int(prev_product[AMOUNT_COL].sum())
            ratio_str = f"ï¼Œå‰ä¸€å¤© Â¥{prev_amount_product:,}ï¼Œç¯æ¯” {calculate_ratio(amount, prev_amount_product)}"
            content += f"â€¢ {model}: Â¥{amount:,}ï¼Œ{qty}ä»¶ | å•ä»·: Â¥{price:,}{ratio_str}\n"
    
    # ä¸­æ–‡æ ‡é¢˜
    title_cn = f"{group_name}æ—¥æŠ¥ï¼ˆ{report_date}ï¼‰"
    
    # å¼ºåˆ¶æ ¼å¼éªŒè¯ - ç¡®ä¿æ¯æ¬¡Webç”Ÿæˆéƒ½ä½¿ç”¨æ­£ç¡®æ ¼å¼
    print(f"ğŸ”§ {group_name} å¼ºåˆ¶æ ¼å¼éªŒè¯:")
    print(f"   å†…å®¹é•¿åº¦: {len(web_content)} å­—ç¬¦")
    
    # éªŒè¯å†…å®¹é¡ºåº
    sections_found = []
    if 'æ•´ä½“æ•°æ®' in web_content:
        sections_found.append('æ•´ä½“æ•°æ®')
    if 'å“ç±»æ˜ç»†' in web_content:
        sections_found.append('å“ç±»æ˜ç»†')
    if 'æ¸ é“æ•°æ®' in web_content:
        sections_found.append('æ¸ é“æ•°æ®')
    if 'åº—é“ºæ•°æ®' in web_content:
        sections_found.append('åº—é“ºæ•°æ®')
    if 'TOPå•å“' in web_content:
        sections_found.append('TOPå•å“')
    if 'åº—é“ºå•å“æ˜ç»†' in web_content:
        sections_found.append('åº—é“ºå•å“æ˜ç»†')
    
    print(f"   æ£€æµ‹åˆ°çš„å†…å®¹é¡ºåº: {' â†’ '.join(sections_found)}")
    
    # éªŒè¯åº—é“ºæ•°æ®åœ¨TOPå•å“å‰é¢
    if 'åº—é“ºæ•°æ®' in sections_found and 'TOPå•å“' in sections_found:
        shop_index = sections_found.index('åº—é“ºæ•°æ®')
        top_index = sections_found.index('TOPå•å“')
        if shop_index < top_index:
            print(f"   âœ… åº—é“ºæ•°æ®åœ¨TOPå•å“å‰é¢: æ­£ç¡®")
    else:
        print(f"   âš ï¸ åº—é“ºæ•°æ®é¡ºåºé”™è¯¯ï¼Œéœ€è¦ä¿®æ­£")
    
    # éªŒè¯åº—é“ºå•å“æ˜ç»†æ˜¯å¦å­˜åœ¨
    if 'åº—é“ºå•å“æ˜ç»†' in sections_found:
        print(f"   âœ… åº—é“ºå•å“æ˜ç»†å·²æ·»åŠ ")
    else:
        print(f"   âš ï¸ åº—é“ºå•å“æ˜ç»†ç¼ºå¤±")
    
    # HTMLå†…å®¹ - å¼ºåˆ¶ä½¿ç”¨ç»Ÿä¸€æ ¼å¼
    html_content = generate_html_content(title_cn, web_content)
    
    # æ·»åŠ è°ƒè¯•ä¿¡æ¯
    print(f"ğŸ”§ {group_name} HTMLç”Ÿæˆè°ƒè¯•ä¿¡æ¯:")
    print(f"   å†…å®¹é•¿åº¦: {len(html_content)} å­—ç¬¦")
    print(f"   å†…å®¹é¡ºåº: æ•´ä½“æ•°æ® â†’ å“ç±»æ˜ç»† â†’ æ¸ é“æ•°æ® â†’ åº—é“ºæ•°æ® â†’ TOPå•å“ â†’ åº—é“ºå•å“æ˜ç»†")
    print(f"   ä½¿ç”¨ç»Ÿä¸€HTMLç”Ÿæˆå‡½æ•°: âœ…")
    print(f"   åº—é“ºå•å“æ˜ç»†å·²æ·»åŠ : âœ…")
    print(f"   âš ï¸ å¼ºåˆ¶é‡æ–°ç”ŸæˆHTMLæ–‡ä»¶ï¼Œç¡®ä¿æ ¼å¼ä¿®æ”¹ç”Ÿæ•ˆ")
    
    file_prefix = to_pinyin(group_name)
    filename = f"{file_prefix}_{report_date}.html".replace('/', '-')
    script_dir = os.path.dirname(os.path.abspath(__file__))
    reports_dir = os.path.join(script_dir, "reports")
    os.makedirs(reports_dir, exist_ok=True)
    filepath = os.path.join(reports_dir, filename)
    
    # å¼ºåˆ¶é‡æ–°ç”ŸæˆHTMLæ–‡ä»¶
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(html_content)
    print(f"   âœ… HTMLæ–‡ä»¶å·²é‡æ–°ç”Ÿæˆ: {filepath}")
    print(f"   æ–‡ä»¶å¤§å°: {os.path.getsize(filepath)} å­—èŠ‚")
    
    return content, filename

# ========== ä¸»æµç¨‹ ==========
all_group_links = []
all_group_files = []  # å­˜å‚¨æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶ä¿¡æ¯

try:
    # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆæ‰€æœ‰åˆ†ç»„çš„HTMLæ–‡ä»¶åˆ°reportsç›®å½•
    for dept, keywords in BUSINESS_GROUPS.items():
        try:
            print(f"\nğŸ”„ æ­£åœ¨å¤„ç† {dept}...")
            content, filename = generate_group_report(dept, 'business', keywords, df_erp, df_prev, yesterday_str)
            # æ— è®ºæ˜¯å¦æœ‰æ•°æ®éƒ½è¦å¤„ç†ï¼Œé¿å…è·³è¿‡
            if content and filename:
                all_group_files.append({
                    'name': dept,
                    'content': content,
                    'filename': filename,
                    'type': 'business'
                })
                print(f"âœ… {dept} HTMLæ–‡ä»¶ç”Ÿæˆå®Œæˆ: {filename}")
            else:
                print(f"âš ï¸ {dept} ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡")
        except Exception as e:
            print(f"âŒ {dept} å¤„ç†å¼‚å¸¸: {e}")
            continue
    
    for channel, keywords in CHANNEL_GROUPS.items():
        try:
            print(f"\nğŸ”„ æ­£åœ¨å¤„ç† {channel}...")
            content, filename = generate_group_report(channel, 'channel', keywords, df_erp, df_prev, yesterday_str)
            # æ— è®ºæ˜¯å¦æœ‰æ•°æ®éƒ½è¦å¤„ç†ï¼Œé¿å…è·³è¿‡
            if content and filename:
                all_group_files.append({
                    'name': channel,
                    'content': content,
                    'filename': filename,
                    'type': 'channel'
                })
                print(f"âœ… {channel} HTMLæ–‡ä»¶ç”Ÿæˆå®Œæˆ: {filename}")
            else:
                print(f"âš ï¸ {channel} ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡")
        except Exception as e:
            print(f"âŒ {channel} å¤„ç†å¼‚å¸¸: {e}")
            continue
    
    # ç¬¬äºŒæ­¥ï¼šç»Ÿä¸€éƒ¨ç½²æ•´ä¸ªreportsç›®å½•ï¼ˆåªè°ƒç”¨ä¸€æ¬¡ï¼‰
    if all_group_files:
        print(f"\nğŸŒ å¼€å§‹ç»Ÿä¸€éƒ¨ç½² {len(all_group_files)} ä¸ªHTMLæ–‡ä»¶...")
        
        # ç¡®ä¿æ‰€æœ‰æ–‡ä»¶éƒ½å·²ç”Ÿæˆåˆ°reportsç›®å½•
        script_dir = os.path.dirname(os.path.abspath(__file__))
        reports_dir = os.path.join(script_dir, "reports")
        
        # éªŒè¯æ‰€æœ‰æ–‡ä»¶éƒ½å·²æ­£ç¡®ç”Ÿæˆ
        print(f"ğŸ” éªŒè¯æ‰€æœ‰HTMLæ–‡ä»¶:")
        for group_info in all_group_files:
            filepath = os.path.join(reports_dir, group_info['filename'])
            if os.path.exists(filepath):
                file_size = os.path.getsize(filepath)
                print(f"   âœ… {group_info['filename']}: {file_size} å­—èŠ‚")
            else:
                print(f"   âŒ {group_info['filename']}: æ–‡ä»¶ä¸å­˜åœ¨")
        
        # ä½¿ç”¨EdgeOne CLIéƒ¨ç½²æ•´ä¸ªreportsç›®å½•
        edgeone_path = r"C:\Users\weicu\AppData\Roaming\npm\edgeone.cmd"
        cmd = [
            edgeone_path, "pages", "deploy", "./reports",
            "-n", EDGEONE_PROJECT,
            "-t", EDGEONE_TOKEN
        ]
        
        try:
            print(f"\nğŸŒ æ­£åœ¨é€šè¿‡ edgeone CLI éƒ¨ç½²æ•´ä¸ª reports ç›®å½•...")
            print(f"   éƒ¨ç½²å‘½ä»¤: {' '.join(cmd)}")
            print(f"   âš ï¸ å¼ºåˆ¶é‡æ–°éƒ¨ç½²ï¼Œç¡®ä¿æ ¼å¼ä¿®æ”¹ç”Ÿæ•ˆ")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            print(f"   éƒ¨ç½²è¾“å‡º: {result.stdout}")
            if result.stderr:
                print(f"   éƒ¨ç½²é”™è¯¯: {result.stderr}")
            if result.returncode == 0:
                print(f"âœ… ç»Ÿä¸€éƒ¨ç½²æˆåŠŸï¼Œæ‰€æœ‰ {len(all_group_files)} ä¸ªæ–‡ä»¶å·²ä¸Šä¼ ")
                print(f"   âš ï¸ è¯·æ¸…é™¤æµè§ˆå™¨ç¼“å­˜æˆ–å¼ºåˆ¶åˆ·æ–°é¡µé¢æŸ¥çœ‹æœ€æ–°æ ¼å¼")
            else:
                print(f"âŒ éƒ¨ç½²å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
        except Exception as e:
            print(f"âŒ EdgeOne Pages CLI éƒ¨ç½²å¼‚å¸¸: {e}")
            print(f"   å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
        
        # ç¬¬ä¸‰æ­¥ï¼šä¸ºæ¯ä¸ªåˆ†ç»„æ‹¼æ¥å…¬ç½‘é“¾æ¥å¹¶å‘é€æ¶ˆæ¯
        for group_info in all_group_files:
            try:
                group_name = group_info['name']
                content = group_info['content']
                filename = group_info['filename']
                
                print(f"\nğŸ”— å¤„ç† {group_name} çš„Webé“¾æ¥...")
                print(f"   æ–‡ä»¶å: {filename}")
                print(f"   å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                
                # æ‹¼æ¥å…¬ç½‘é“¾æ¥ - ä½¿ç”¨æ­£ç¡®çš„URLæ ¼å¼ï¼ˆå»æ‰/reports/å‰ç¼€ï¼‰
                public_url = f"https://edge.haierht.cn/{filename}"
                print(f"   æœ€ç»ˆURL: {public_url}")
                
                # å‘é€æ¶ˆæ¯ - ç¡®ä¿æ€»æ˜¯é™„ä¸Šwebé“¾æ¥ï¼Œæ— è®ºæ˜¯å¦æœ‰æ•°æ®
                msg = content + f"\nğŸŒ æŸ¥çœ‹å®Œæ•´Webé¡µé¢: {public_url}"
                print(f"ã€{group_name}ã€‘Webé“¾æ¥: {public_url}")
                print(f"   æ¶ˆæ¯é•¿åº¦: {len(msg)} å­—ç¬¦")
                print(f"   å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                print(f"   é“¾æ¥é•¿åº¦: {len(f'ğŸŒ æŸ¥çœ‹å®Œæ•´Webé¡µé¢: {public_url}')} å­—ç¬¦")
                send_wecomchan_segment(msg)
                time.sleep(2)
                all_group_links.append(f"{group_name}: {public_url}")
                print(f"âœ… {group_name} å‘é€å®Œæˆ")
            except Exception as e:
                print(f"âŒ {group_name} å‘é€å¼‚å¸¸: {e}")
                continue
    else:
        print("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•HTMLæ–‡ä»¶")
    
    print("âœ… å¤šäº‹ä¸šéƒ¨æ—¥æŠ¥å…¨éƒ¨ç”Ÿæˆã€ç»Ÿä¸€éƒ¨ç½²å¹¶æ¨é€å®Œæˆï¼")
    if all_group_links:
        print("\nğŸ“‹ æ‰€æœ‰é“¾æ¥æ±‡æ€»:")
        for link in all_group_links:
            print(f"  {link}")

except Exception as e:
    print(f"âŒ æ‰§è¡Œå¼‚å¸¸: {e}\n{traceback.format_exc()}")
