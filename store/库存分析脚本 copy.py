#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åº“å­˜åˆ†æè„šæœ¬
åŠŸèƒ½ï¼šä»å¤šä¸ªæ•°æ®åº“è¡¨æ ¼è·å–åº“å­˜æ•°æ®ï¼ŒæŒ‰ä»“åº“ç±»å‹èšåˆï¼Œç”ŸæˆæŠ¥å‘Šå¹¶æ¨é€åˆ°ä¼ä¸šå¾®ä¿¡
"""

import pymysql
import pandas as pd
import json
import requests
import logging
from datetime import datetime, timedelta
import os
from typing import Dict, List, Tuple
import numpy as np
import time
import subprocess
import sys
import re # Added for regex in deployment ID extraction

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('åº“å­˜åˆ†æ.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# æ•°æ®åº“é…ç½®
DB_CONFIG_WDT = {
    'host': '212.64.57.87',
    'user': 'root',
    'password': 'c973ee9b500cc638',
    'database': 'wdt',
    'charset': 'utf8mb4'
}

DB_CONFIG_DATE = {
    'host': '212.64.57.87',
    'user': 'root',
    'password': 'c973ee9b500cc638',
    'database': 'Date',
    'charset': 'utf8mb4'
}

# ä¼ä¸šå¾®ä¿¡é…ç½®
WECOM_CONFIG = {
    'corpid': os.getenv('WECOM_CID', ''),
    'corpsecret': os.getenv('WECOM_SECRET', ''),
    'agentid': os.getenv('WECOM_AID', ''),
    'touser': os.getenv('WECOM_TOUID', 'weicungang')
}

# ========== EdgeOne Pages é…ç½® ==========
EDGEONE_PROJECT = "sales-report-new"
EDGEONE_DOMAIN = "edge.haierht.cn"
EDGEONE_CLI_PATH = "edgeone"  # ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œæ›´é€šç”¨
EDGEONE_CLI_PATH_ALT = "edgeone"  # å¤‡ç”¨è·¯å¾„

class InventoryAnalyzer:
    """åº“å­˜åˆ†æå™¨"""
    
    def __init__(self):
        self.wdt_connection = None
        self.date_connection = None
        self.latest_deployment_id = None  # å­˜å‚¨æœ€æ–°çš„éƒ¨ç½²ID
        
    def connect_databases(self) -> bool:
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.wdt_connection = pymysql.connect(**DB_CONFIG_WDT)
            self.date_connection = pymysql.connect(**DB_CONFIG_DATE)
            logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False
    
    def close_databases(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.wdt_connection:
            self.wdt_connection.close()
        if self.date_connection:
            self.date_connection.close()
        logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    def get_wdt_stock_data(self, spec_mapping: Dict[str, Dict[str, str]]) -> pd.DataFrame:
        """è·å–wdtæ•°æ®åº“çš„stockè¡¨æ ¼æ•°æ®ï¼Œæ ¹æ®è§„æ ¼åç§°æ˜ å°„æŸ¥è¯¢ï¼ˆä½¿ç”¨å¯å‘åº“å­˜avaliable_numï¼‰"""
        if not self.wdt_connection:
            logger.error("wdtæ•°æ®åº“æœªè¿æ¥")
            return pd.DataFrame()
        
        if not spec_mapping:
            logger.warning("æ²¡æœ‰è§„æ ¼åç§°æ˜ å°„ï¼Œæ— æ³•æŸ¥è¯¢wdtæ•°æ®")
            return pd.DataFrame()
        
        try:
            # è·å–æ‰€æœ‰æœ‰æ•ˆçš„è§„æ ¼åç§°
            spec_names = list(spec_mapping.keys())
            
            if not spec_names:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„è§„æ ¼åç§°")
                return pd.DataFrame()
            
            # æ„å»ºæ‰¹é‡æŸ¥è¯¢ - ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æ¥è€Œä¸æ˜¯å‚æ•°åŒ–æŸ¥è¯¢
            spec_names_str = "','".join(spec_names)
            query = f"""
            SELECT 
                spec_name as è§„æ ¼åç§°,
                avaliable_num as æ•°é‡,
                CASE 
                    WHEN warehouse_name = 'å¸¸è§„ä»“' THEN 'å¸¸è§„ä»“'
                    WHEN warehouse_name LIKE '%é¡ºä¸°%' THEN 'é¡ºä¸°ä»“'
                    ELSE 'å¿½ç•¥'
                END as ä»“åº“ç±»å‹
            FROM stock 
            WHERE spec_name IN ('{spec_names_str}')
            AND (
                warehouse_name = 'å¸¸è§„ä»“' 
                OR warehouse_name LIKE '%é¡ºä¸°%'
            )
            AND avaliable_num > 0
            """
            
            df = pd.read_sql(query, self.wdt_connection)
            
            if not df.empty:
                logger.info(f"ä»wdt.stockè·å–æ•°æ®æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•")
                return df
            else:
                logger.warning("æœªä»wdt.stockè·å–åˆ°ä»»ä½•æ•°æ®")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"è·å–wdtæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_jinrongstore_data(self, spec_mapping: Dict[str, Dict[str, str]]) -> pd.DataFrame:
        """è·å–jinrongstoreæ•°æ®ï¼šæ ¹æ®è§„æ ¼åç§°æ˜ å°„æŸ¥è¯¢"""
        if not self.date_connection:
            logger.error("dateæ•°æ®åº“æœªè¿æ¥")
            return pd.DataFrame()
        
        if not spec_mapping:
            logger.warning("æ²¡æœ‰è§„æ ¼åç§°æ˜ å°„ï¼Œæ— æ³•æŸ¥è¯¢jinrongstoreæ•°æ®")
            return pd.DataFrame()
        
        try:
            # è·å–æ‰€æœ‰è¡¨æ ¼
            cursor = self.date_connection.cursor()
            cursor.execute("SHOW TABLES LIKE '%jinrongstore%'")
            tables = cursor.fetchall()
            
            if not tables:
                logger.warning("æœªæ‰¾åˆ°jinrongstoreç›¸å…³è¡¨æ ¼")
                return pd.DataFrame()
            
            table_name = tables[0][0]
            logger.info(f"æ‰¾åˆ°jinrongstoreè¡¨æ ¼: {table_name}")
            
            # è·å–è¡¨ç»“æ„
            cursor.execute(f"DESCRIBE `{table_name}`")
            columns = [col[0] for col in cursor.fetchall()]
            logger.info(f"jinrongstoreè¡¨æ ¼åˆ—: {columns}")
            
            # ç²¾ç¡®æŸ¥æ‰¾åˆ—å
            model_col = 'å‹å·'
            quantity_col = 'æ•°é‡'
            redeemed_col = 'å·²èµè´§'
            
            # éªŒè¯åˆ—æ˜¯å¦å­˜åœ¨
            if model_col not in columns or quantity_col not in columns or redeemed_col not in columns:
                logger.warning("jinrongstoreè¡¨æ ¼ä¸­ç¼ºå°‘å¿…è¦åˆ—")
                return pd.DataFrame()
            
            # è·å–æ‰€æœ‰jinrongstoreå¯¹åº”çš„åç§°
            jinrong_names = []
            spec_name_mapping = {}
            
            for spec_name, warehouse_names in spec_mapping.items():
                if 'jinrongstore' in warehouse_names:
                    jinrong_name = warehouse_names['jinrongstore']
                    jinrong_names.append(jinrong_name)
                    spec_name_mapping[jinrong_name] = spec_name
            
            if not jinrong_names:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°jinrongstoreå¯¹åº”çš„åç§°")
                return pd.DataFrame()
            
            # æ„å»ºæ‰¹é‡æŸ¥è¯¢
            jinrong_names_str = "','".join(jinrong_names)
            query = f"""
            SELECT 
                `{model_col}` as å¯¹åº”åç§°,
                (`{quantity_col}` - `{redeemed_col}`) as æ•°é‡
            FROM `{table_name}`
            WHERE `{model_col}` IN ('{jinrong_names_str}')
            AND (`{quantity_col}` - `{redeemed_col}`) > 0
            """
            
            df = pd.read_sql(query, self.date_connection)
            
            if not df.empty:
                # æ·»åŠ è§„æ ¼åç§°å’Œä»“åº“ç±»å‹
                df['è§„æ ¼åç§°'] = df['å¯¹åº”åç§°'].map(spec_name_mapping)
                df['ä»“åº“ç±»å‹'] = 'é‡‘èä»“'
                df = df.drop('å¯¹åº”åç§°', axis=1)
                
                logger.info(f"ä»{table_name}è·å–æ•°æ®æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•")
                return df
            else:
                logger.warning("æœªä»jinrongstoreè·å–åˆ°ä»»ä½•æ•°æ®")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"è·å–jinrongstoreæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_rrsstore_data(self, spec_mapping: Dict[str, Dict[str, str]]) -> pd.DataFrame:
        """è·å–rrsstoreæ•°æ®ï¼šæ ¹æ®è§„æ ¼åç§°æ˜ å°„æŸ¥è¯¢"""
        if not self.date_connection:
            logger.error("dateæ•°æ®åº“æœªè¿æ¥")
            return pd.DataFrame()
        
        if not spec_mapping:
            logger.warning("æ²¡æœ‰è§„æ ¼åç§°æ˜ å°„ï¼Œæ— æ³•æŸ¥è¯¢rrsstoreæ•°æ®")
            return pd.DataFrame()
        
        try:
            # è·å–æ‰€æœ‰è¡¨æ ¼
            cursor = self.date_connection.cursor()
            cursor.execute("SHOW TABLES LIKE '%rrsstore%'")
            tables = cursor.fetchall()
            
            if not tables:
                logger.warning("æœªæ‰¾åˆ°rrsstoreç›¸å…³è¡¨æ ¼")
                return pd.DataFrame()
            
            table_name = tables[0][0]
            logger.info(f"æ‰¾åˆ°rrsstoreè¡¨æ ¼: {table_name}")
            
            # ç²¾ç¡®ä½¿ç”¨æŒ‡å®šçš„åˆ—å
            model_col = 'å•†å“ç¼–ç '
            quantity_col = 'å¯ç”¨åº“å­˜æ•°é‡'
            
            # è·å–è¡¨ç»“æ„éªŒè¯
            cursor.execute(f"DESCRIBE `{table_name}`")
            columns = [col[0] for col in cursor.fetchall()]
            logger.info(f"rrsstoreè¡¨æ ¼åˆ—: {columns}")
            
            # å¦‚æœæŒ‡å®šåˆ—ä¸å­˜åœ¨ï¼Œä½¿ç”¨å®é™…å­˜åœ¨çš„åˆ—
            if model_col not in columns:
                model_col = 'ç¤¾ä¼šåŒ–ç‰©æ–™ç¼–ç '  # å¤‡é€‰
            if quantity_col not in columns:
                quantity_col = 'å¯ç”¨åº“å­˜'  # å¤‡é€‰
            
            if model_col not in columns or quantity_col not in columns:
                logger.warning("rrsstoreè¡¨æ ¼ä¸­ç¼ºå°‘å¿…è¦åˆ—")
                return pd.DataFrame()
            
            # è·å–æ‰€æœ‰rrsstoreå¯¹åº”çš„åç§°
            rrs_names = []
            spec_name_mapping = {}
            
            for spec_name, warehouse_names in spec_mapping.items():
                if 'rrsstore' in warehouse_names:
                    rrs_name = warehouse_names['rrsstore']
                    rrs_names.append(rrs_name)
                    spec_name_mapping[rrs_name] = spec_name
            
            if not rrs_names:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°rrsstoreå¯¹åº”çš„åç§°")
                return pd.DataFrame()
            
            # æ„å»ºæ‰¹é‡æŸ¥è¯¢
            rrs_names_str = "','".join(rrs_names)
            query = f"""
            SELECT 
                `{model_col}` as å¯¹åº”åç§°,
                CAST(`{quantity_col}` AS SIGNED) as æ•°é‡
            FROM `{table_name}`
            WHERE `{model_col}` IN ('{rrs_names_str}')
            AND CAST(`{quantity_col}` AS SIGNED) > 0
            """
            
            df = pd.read_sql(query, self.date_connection)
            
            if not df.empty:
                # æ·»åŠ è§„æ ¼åç§°å’Œä»“åº“ç±»å‹
                df['è§„æ ¼åç§°'] = df['å¯¹åº”åç§°'].map(spec_name_mapping)
                df['ä»“åº“ç±»å‹'] = 'äº‘ä»“'
                df = df.drop('å¯¹åº”åç§°', axis=1)
                
                logger.info(f"ä»{table_name}è·å–æ•°æ®æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•")
                return df
            else:
                logger.warning("æœªä»rrsstoreè·å–åˆ°ä»»ä½•æ•°æ®")
                return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"è·å–rrsstoreæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_tongstore_data(self, spec_mapping: Dict[str, Dict[str, str]]) -> pd.DataFrame:
        """è·å–tongstoreæ•°æ®ï¼šæ ¹æ®è§„æ ¼åç§°æ˜ å°„æŸ¥è¯¢"""
        if not self.date_connection:
            logger.error("dateæ•°æ®åº“æœªè¿æ¥")
            return pd.DataFrame()
        
        if not spec_mapping:
            logger.warning("æ²¡æœ‰è§„æ ¼åç§°æ˜ å°„ï¼Œæ— æ³•æŸ¥è¯¢tongstoreæ•°æ®")
            return pd.DataFrame()
        
        try:
            # è·å–æ‰€æœ‰è¡¨æ ¼
            cursor = self.date_connection.cursor()
            cursor.execute("SHOW TABLES LIKE '%tongstore%'")
            tables = cursor.fetchall()
            
            if not tables:
                logger.warning("æœªæ‰¾åˆ°tongstoreç›¸å…³è¡¨æ ¼")
                return pd.DataFrame()
            
            table_name = tables[0][0]
            logger.info(f"æ‰¾åˆ°tongstoreè¡¨æ ¼: {table_name}")
            
            # è·å–è¡¨ç»“æ„
            cursor.execute(f"DESCRIBE `{table_name}`")
            columns = [col[0] for col in cursor.fetchall()]
            logger.info(f"tongstoreè¡¨æ ¼åˆ—: {columns}")
            
            # ä½¿ç”¨æ­£ç¡®çš„åˆ—å
            stock_col = '__EMPTY_2'  # æ€»åº“å­˜åˆ—
            available_col = '__EMPTY_3'  # æ€»å¯ç”¨åº“å­˜åˆ—
            model_col = '__EMPTY_8'  # å•†å“å‹å·åˆ—
            brand_col = '__EMPTY'  # å“ç‰Œåˆ—
            product_group_col = '__EMPTY_1'  # äº§å“ç»„åˆ—
            
            # éªŒè¯åˆ—æ˜¯å¦å­˜åœ¨
            required_columns = [stock_col, available_col, model_col]
            missing_columns = [col for col in required_columns if col not in columns]
            if missing_columns:
                logger.warning(f"tongstoreè¡¨æ ¼ä¸­ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
                return pd.DataFrame()
            
            # è·å–æ‰€æœ‰tongstoreå¯¹åº”çš„åç§°
            tong_names = []
            spec_name_mapping = {}
            
            for spec_name, warehouse_names in spec_mapping.items():
                if 'tongstore' in warehouse_names:
                    tong_name = warehouse_names['tongstore']
                    if tong_name and tong_name.strip():  # ç¡®ä¿åç§°ä¸ä¸ºç©º
                        tong_names.append(tong_name.strip())
                        spec_name_mapping[tong_name.strip()] = spec_name
            
            if not tong_names:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°tongstoreå¯¹åº”çš„åç§°")
                return pd.DataFrame()
            
            logger.info(f"tongstoreæ˜ å°„åç§°æ•°é‡: {len(tong_names)}")
            logger.info(f"tongstoreæ˜ å°„åç§°ç¤ºä¾‹: {tong_names[:5]}...")  # æ˜¾ç¤ºå‰5ä¸ª
            
            # åˆ†æ‰¹æŸ¥è¯¢ï¼Œé¿å…SQLè¿‡é•¿
            batch_size = 30
            all_results = []
            
            for i in range(0, len(tong_names), batch_size):
                batch_names = tong_names[i:i + batch_size]
                
                # æ„å»ºæ‰¹é‡æŸ¥è¯¢ - ä½¿ç”¨ç²¾ç¡®åŒ¹é…å’Œæ¨¡ç³ŠåŒ¹é…ç»“åˆ
                batch_conditions = []
                for name in batch_names:
                    # è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
                    escaped_name = name.replace("'", "''").replace("%", "\\%").replace("_", "\\_")
                    # ä½¿ç”¨ç²¾ç¡®åŒ¹é…å’Œæ¨¡ç³ŠåŒ¹é…
                    batch_conditions.append(f"(`{model_col}` = '{escaped_name}' OR `{model_col}` LIKE '%{escaped_name}%')")
                
                conditions_str = " OR ".join(batch_conditions)
                query = f"""
                SELECT 
                    `{model_col}` as å¯¹åº”åç§°,
                    `{brand_col}` as å“ç‰Œ,
                    `{product_group_col}` as äº§å“ç»„,
                    CAST(`{available_col}` AS SIGNED) as å¯ç”¨åº“å­˜,
                    CAST(`{stock_col}` AS SIGNED) as æ€»åº“å­˜
                FROM `{table_name}`
                WHERE ({conditions_str})
                AND `{model_col}` IS NOT NULL 
                AND `{model_col}` != ''
                AND `{model_col}` != 'å•†å“å‹å·'
                AND `{available_col}` IS NOT NULL
                AND CAST(`{available_col}` AS SIGNED) > 0
                AND `{model_col}` NOT LIKE '%å•†å“å‹å·%'
                ORDER BY `{model_col}`
                """
                
                try:
                    logger.info(f"æŸ¥è¯¢tongstoreæ‰¹æ¬¡ {i//batch_size + 1}ï¼ŒåŒ…å« {len(batch_names)} ä¸ªå•†å“å‹å·")
                    df_batch = pd.read_sql(query, self.date_connection)
                    
                    if not df_batch.empty:
                        logger.info(f"tongstoreæ‰¹æ¬¡ {i//batch_size + 1} æŸ¥è¯¢æˆåŠŸï¼Œè·å– {len(df_batch)} æ¡è®°å½•")
                        all_results.append(df_batch)
                    else:
                        logger.info(f"tongstoreæ‰¹æ¬¡ {i//batch_size + 1} æœªæ‰¾åˆ°åŒ¹é…æ•°æ®")
                        
                except Exception as e:
                    logger.error(f"tongstoreæ‰¹æ¬¡ {i//batch_size + 1} æŸ¥è¯¢å¤±è´¥: {e}")
                    continue
            
            if not all_results:
                logger.warning("æœªä»tongstoreè·å–åˆ°ä»»ä½•æ•°æ®")
                return pd.DataFrame()
            
            # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡ç»“æœ
            df = pd.concat(all_results, ignore_index=True)
            
            if not df.empty:
                # æ¸…ç†æ•°æ®ï¼šç§»é™¤é‡å¤å’Œæ— æ•ˆæ•°æ®
                df = df.drop_duplicates()
                logger.info(f"tongstoreåŸå§‹æ•°æ®: {len(df)} æ¡è®°å½•")
                
                # æ·»åŠ è§„æ ¼åç§°å’Œä»“åº“ç±»å‹
                # ä½¿ç”¨ç²¾ç¡®åŒ¹é…å’Œæ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°å¯¹åº”çš„è§„æ ¼åç§°
                matched_data = []
                unmatched_count = 0
                
                for _, row in df.iterrows():
                    model_name = str(row['å¯¹åº”åç§°']).strip()
                    available_quantity = row['å¯ç”¨åº“å­˜']
                    total_quantity = row['æ€»åº“å­˜']
                    brand = str(row['å“ç‰Œ']).strip() if pd.notna(row['å“ç‰Œ']) else ''
                    product_group = str(row['äº§å“ç»„']).strip() if pd.notna(row['äº§å“ç»„']) else ''
                    
                    # æŸ¥æ‰¾åŒ¹é…çš„è§„æ ¼åç§° - ä¼˜å…ˆç²¾ç¡®åŒ¹é…ï¼Œç„¶åæ¨¡ç³ŠåŒ¹é…
                    matched_spec = None
                    match_type = None
                    
                    # 1. ç²¾ç¡®åŒ¹é…
                    for spec_name, warehouse_names in spec_mapping.items():
                        if 'tongstore' in warehouse_names:
                            tong_name = warehouse_names['tongstore']
                            if tong_name and tong_name.strip() == model_name:
                                matched_spec = spec_name
                                match_type = 'ç²¾ç¡®åŒ¹é…'
                                break
                    
                    # 2. æ¨¡ç³ŠåŒ¹é…ï¼ˆå¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼‰
                    if not matched_spec:
                        for spec_name, warehouse_names in spec_mapping.items():
                            if 'tongstore' in warehouse_names:
                                tong_name = warehouse_names['tongstore']
                                if tong_name and tong_name.strip() in model_name:
                                    matched_spec = spec_name
                                    match_type = 'æ¨¡ç³ŠåŒ¹é…'
                                    break
                    
                    if matched_spec:
                        matched_data.append({
                            'è§„æ ¼åç§°': matched_spec,
                            'æ•°é‡': available_quantity,  # ä½¿ç”¨å¯ç”¨åº“å­˜
                            'ä»“åº“ç±»å‹': 'ç»Ÿä»“',
                            'åŒ¹é…ç±»å‹': match_type,
                            'åŸå§‹å‹å·': model_name,
                            'å“ç‰Œ': brand,
                            'äº§å“ç»„': product_group,
                            'æ€»åº“å­˜': total_quantity
                        })
                    else:
                        unmatched_count += 1
                        logger.debug(f"æœªåŒ¹é…çš„tongstoreè®°å½•: {model_name} (å“ç‰Œ: {brand}, äº§å“ç»„: {product_group})")
                
                if matched_data:
                    result_df = pd.DataFrame(matched_data)
                    logger.info(f"ä»{table_name}è·å–æ•°æ®æˆåŠŸï¼Œå…± {len(result_df)} æ¡è®°å½•")
                    logger.info(f"åŒ¹é…ç»Ÿè®¡: ç²¾ç¡®åŒ¹é… {len([d for d in matched_data if d['åŒ¹é…ç±»å‹'] == 'ç²¾ç¡®åŒ¹é…'])} æ¡, æ¨¡ç³ŠåŒ¹é… {len([d for d in matched_data if d['åŒ¹é…ç±»å‹'] == 'æ¨¡ç³ŠåŒ¹é…'])} æ¡")
                    logger.info(f"æœªåŒ¹é…è®°å½•: {unmatched_count} æ¡")
                    
                    # ç§»é™¤è°ƒè¯•åˆ—ï¼Œåªä¿ç•™å¿…è¦åˆ—
                    result_df = result_df[['è§„æ ¼åç§°', 'æ•°é‡', 'ä»“åº“ç±»å‹']]
                    return result_df
                else:
                    logger.warning("tongstoreæ•°æ®åŒ¹é…å¤±è´¥ï¼Œæœªæ‰¾åˆ°å¯¹åº”çš„è§„æ ¼åç§°")
                    return pd.DataFrame()
            else:
                logger.warning("æœªä»tongstoreè·å–åˆ°ä»»ä½•æ•°æ®")
                return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"è·å–tongstoreæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_jdstore_data(self, spec_mapping: Dict[str, Dict[str, str]]) -> pd.DataFrame:
        """è·å–jdstoreæ•°æ®ï¼šæ ¹æ®è§„æ ¼åç§°æ˜ å°„æŸ¥è¯¢"""
        if not self.date_connection:
            logger.error("dateæ•°æ®åº“æœªè¿æ¥")
            return pd.DataFrame()
        
        if not spec_mapping:
            logger.warning("æ²¡æœ‰è§„æ ¼åç§°æ˜ å°„ï¼Œæ— æ³•æŸ¥è¯¢jdstoreæ•°æ®")
            return pd.DataFrame()
        
        try:
            # è·å–æ‰€æœ‰è¡¨æ ¼
            cursor = self.date_connection.cursor()
            cursor.execute("SHOW TABLES LIKE '%jdstore%'")
            tables = cursor.fetchall()
            
            if not tables:
                logger.warning("æœªæ‰¾åˆ°jdstoreç›¸å…³è¡¨æ ¼")
                return pd.DataFrame()
            
            table_name = tables[0][0]
            logger.info(f"æ‰¾åˆ°jdstoreè¡¨æ ¼: {table_name}")
            
            # ç²¾ç¡®ä½¿ç”¨æŒ‡å®šçš„åˆ—å
            model_col = 'äº‹ä¸šéƒ¨å•†å“ç¼–ç '
            quantity_col = 'å¯ç”¨åº“å­˜'
            
            # è·å–è¡¨ç»“æ„éªŒè¯
            cursor.execute(f"DESCRIBE `{table_name}`")
            columns = [col[0] for col in cursor.fetchall()]
            logger.info(f"jdstoreè¡¨æ ¼åˆ—: {columns}")
            
            # éªŒè¯åˆ—æ˜¯å¦å­˜åœ¨
            if model_col not in columns or quantity_col not in columns:
                logger.warning("jdstoreè¡¨æ ¼ä¸­ç¼ºå°‘å¿…è¦åˆ—")
                return pd.DataFrame()
            
            # è·å–æ‰€æœ‰jdstoreå¯¹åº”çš„åç§°
            jd_names = []
            spec_name_mapping = {}
            
            for spec_name, warehouse_names in spec_mapping.items():
                if 'jdstore' in warehouse_names:
                    jd_name = warehouse_names['jdstore']
                    jd_names.append(jd_name)
                    spec_name_mapping[jd_name] = spec_name
            
            if not jd_names:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°jdstoreå¯¹åº”çš„åç§°")
                return pd.DataFrame()
            
            # åˆ†æ‰¹æŸ¥è¯¢ï¼Œé¿å…æ•°æ®åº“æ­»é”
            batch_size = 50
            all_results = []
            
            for i in range(0, len(jd_names), batch_size):
                batch_names = jd_names[i:i + batch_size]
                
                # æ„å»ºæ‰¹é‡æŸ¥è¯¢
                jd_names_str = "','".join(batch_names)
                query = f"""
                SELECT 
                    `{model_col}` as å¯¹åº”åç§°,
                    CAST(`{quantity_col}` AS SIGNED) as æ•°é‡
                FROM `{table_name}`
                WHERE `{model_col}` IN ('{jd_names_str}')
                AND CAST(`{quantity_col}` AS SIGNED) > 0
                """
                
                # æ·»åŠ é‡è¯•æœºåˆ¶
                max_retries = 3
                for attempt in range(max_retries):
                    try:
                        logger.info(f"æŸ¥è¯¢jdstoreæ‰¹æ¬¡ {i//batch_size + 1}ï¼Œå°è¯• {attempt + 1}/{max_retries}")
                        df_batch = pd.read_sql(query, self.date_connection)
                        all_results.append(df_batch)
                        logger.info(f"jdstoreæ‰¹æ¬¡ {i//batch_size + 1} æŸ¥è¯¢æˆåŠŸï¼Œè·å– {len(df_batch)} æ¡è®°å½•")
                        break
                    except Exception as e:
                        if "Deadlock" in str(e) and attempt < max_retries - 1:
                            logger.warning(f"jdstoreæ‰¹æ¬¡ {i//batch_size + 1} æ•°æ®åº“æ­»é”ï¼Œç­‰å¾…åé‡è¯•: {e}")
                            import time
                            time.sleep(2 * (attempt + 1))  # é€’å¢ç­‰å¾…æ—¶é—´
                            continue
                        else:
                            logger.error(f"jdstoreæ‰¹æ¬¡ {i//batch_size + 1} æŸ¥è¯¢å¤±è´¥: {e}")
                            break
            
            if not all_results:
                logger.warning("æœªä»jdstoreè·å–åˆ°ä»»ä½•æ•°æ®")
                return pd.DataFrame()
            
            # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡ç»“æœ
            df = pd.concat(all_results, ignore_index=True)
            
            if not df.empty:
                # æ·»åŠ è§„æ ¼åç§°å’Œä»“åº“ç±»å‹
                df['è§„æ ¼åç§°'] = df['å¯¹åº”åç§°'].map(spec_name_mapping)
                df['ä»“åº“ç±»å‹'] = 'äº¬ä»“'
                df = df.drop('å¯¹åº”åç§°', axis=1)
                
                logger.info(f"ä»{table_name}è·å–æ•°æ®æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•")
                return df
            else:
                logger.warning("æœªä»jdstoreè·å–åˆ°ä»»ä½•æ•°æ®")
                return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"è·å–jdstoreæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_matchstore_mapping(self) -> Dict[str, Dict[str, str]]:
        """è·å–matchstoreæ˜ å°„å…³ç³»ï¼šè§„æ ¼åç§°ä½œä¸ºæœ€ç»ˆäº§å“åï¼Œè¿”å›æ¯ä¸ªè§„æ ¼åç§°åœ¨å„ä¸ªåº“ä½çš„å¯¹åº”åç§°"""
        if not self.date_connection:
            logger.error("dateæ•°æ®åº“æœªè¿æ¥")
            return {}
        
        try:
            # è·å–æ‰€æœ‰è¡¨æ ¼
            cursor = self.date_connection.cursor()
            cursor.execute("SHOW TABLES LIKE '%matchstore%'")
            tables = cursor.fetchall()
            
            if not tables:
                logger.warning("æœªæ‰¾åˆ°matchstoreç›¸å…³è¡¨æ ¼")
                return {}
            
            table_name = tables[0][0]
            logger.info(f"æ‰¾åˆ°matchstoreè¡¨æ ¼: {table_name}")
            
            # è·å–è¡¨ç»“æ„
            cursor.execute(f"DESCRIBE `{table_name}`")
            columns = [col[0] for col in cursor.fetchall()]
            logger.info(f"matchstoreè¡¨æ ¼åˆ—: {columns}")
            
            # ä½¿ç”¨è§„æ ¼åç§°ä½œä¸ºæœ€ç»ˆäº§å“åï¼Œå¹¶å»ºç«‹æ˜ å°„å…³ç³»
            mapping = {}
            
            # ç²¾ç¡®æŸ¥æ‰¾åˆ—å
            spec_col = 'è§„æ ¼åç§°'
            
            # éœ€è¦æ˜ å°„çš„åˆ— - ä½¿ç”¨å®é™…çš„åˆ—å
            mapping_columns = {
                'jinrongstore': 'jinrongstore',
                'tongstore': 'tongstore', 
                'jdstore': 'jdstore',
                'rrsstore': 'rrsstore'
            }
            
            # éªŒè¯åˆ—æ˜¯å¦å­˜åœ¨
            available_columns = [col for col in mapping_columns.keys() if col in columns]
            if spec_col not in columns or not available_columns:
                logger.warning("matchstoreè¡¨æ ¼ä¸­ç¼ºå°‘å¿…è¦åˆ—")
                return {}
            
            # æ„å»ºæŸ¥è¯¢ - åªè·å–æœ‰è§„æ ¼åç§°çš„è®°å½•
            select_cols = ', '.join([f'`{col}`' for col in available_columns])
            query = f"""
            SELECT `{spec_col}`, {select_cols}
            FROM `{table_name}`
            WHERE `{spec_col}` IS NOT NULL AND `{spec_col}` != '' AND `{spec_col}` != 'nan'
            AND `{spec_col}` != 'None' AND `{spec_col}` != 'è§„æ ¼åç§°'
            """
            
            df = pd.read_sql(query, self.date_connection)
            
            # å»ºç«‹æ˜ å°„ï¼šå¯¹äºæ¯ä¸ªè§„æ ¼åç§°ï¼Œè®°å½•å®ƒåœ¨å„ä¸ªåº“ä½çš„å¯¹åº”åç§°
            for _, row in df.iterrows():
                spec_name = str(row[spec_col]).strip()
                
                # åªæœ‰å½“è§„æ ¼åç§°æœ‰æ•ˆæ—¶æ‰å»ºç«‹æ˜ å°„
                if spec_name and spec_name != 'nan' and spec_name != 'None' and spec_name != 'è§„æ ¼åç§°':
                    # ä¸ºæ¯ä¸ªè§„æ ¼åç§°åˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œè®°å½•å®ƒåœ¨å„ä¸ªåº“ä½çš„å¯¹åº”åç§°
                    spec_mapping = {}
                    
                    for col in available_columns:
                        value = str(row[col]).strip() if pd.notna(row[col]) and str(row[col]).strip() != '' else None
                        if value and value != 'nan' and value != 'None' and value != col:
                            spec_mapping[col] = value
                    
                    # åªæœ‰å½“è‡³å°‘æœ‰ä¸€ä¸ªåº“ä½æœ‰å¯¹åº”åç§°æ—¶ï¼Œæ‰æ·»åŠ åˆ°æ˜ å°„ä¸­
                    if spec_mapping:
                        mapping[spec_name] = spec_mapping
            
            logger.info(f"è·å–matchstoreæ˜ å°„æˆåŠŸï¼Œå…± {len(mapping)} ä¸ªè§„æ ¼åç§°çš„æ˜ å°„å…³ç³»")
            return mapping
            
        except Exception as e:
            logger.error(f"è·å–matchstoreæ•°æ®å¤±è´¥: {e}")
            return {}
    
    def unify_product_names(self, df: pd.DataFrame, mapping: Dict[str, str]) -> pd.DataFrame:
        """ç»Ÿä¸€äº§å“åç§°ï¼šä½¿ç”¨è§„æ ¼åç§°ä½œä¸ºæœ€ç»ˆäº§å“åï¼Œåªä¿ç•™æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®"""
        if df.empty:
            return df
        
        # åªä¿ç•™æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®
        if mapping:
            # åˆ›å»ºæ˜ å°„åçš„æ•°æ®æ¡†
            mapped_data = []
            for _, row in df.iterrows():
                product_name = str(row['äº§å“åç§°']).strip()
                # ä¸¥æ ¼åŒ¹é…ï¼šåªæœ‰å®Œå…¨åŒ¹é…çš„æ•°æ®æ‰ä¿ç•™
                if product_name in mapping:
                    # åªä¿ç•™æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®
                    new_row = row.copy()
                    new_row['è§„æ ¼åç§°'] = mapping[product_name]
                    mapped_data.append(new_row)
            
            if mapped_data:
                result_df = pd.DataFrame(mapped_data)
                logger.info(f"ç»Ÿä¸€äº§å“åç§°å®Œæˆï¼Œä¿ç•™ {len(result_df)} æ¡æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®")
                return result_df
            else:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®")
                return pd.DataFrame()
        else:
            # å¦‚æœæ²¡æœ‰æ˜ å°„å…³ç³»ï¼Œè¿”å›ç©ºæ•°æ®æ¡†
            logger.warning("æ²¡æœ‰æ˜ å°„å…³ç³»ï¼Œè¿”å›ç©ºæ•°æ®")
            return pd.DataFrame()
    
    def aggregate_inventory_data(self) -> pd.DataFrame:
        """èšåˆæ‰€æœ‰åº“å­˜æ•°æ®ï¼šåªç»Ÿè®¡æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®"""
        logger.info("å¼€å§‹èšåˆåº“å­˜æ•°æ®")
        
        # è·å–æ˜ å°„å…³ç³»
        mapping = self.get_matchstore_mapping()
        
        if not mapping:
            logger.warning("æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆçš„æ˜ å°„å…³ç³»ï¼Œæ— æ³•è¿›è¡Œæ•°æ®èšåˆ")
            return pd.DataFrame()
        
        # è·å–å„ä»“åº“æ•°æ®
        all_data = []
        
        # wdtæ•°æ®
        wdt_data = self.get_wdt_stock_data(mapping)
        if not wdt_data.empty:
            all_data.append(wdt_data)
        
        # jinrongstoreæ•°æ®
        jinrong_data = self.get_jinrongstore_data(mapping)
        if not jinrong_data.empty:
            all_data.append(jinrong_data)
        
        # rrsstoreæ•°æ®
        rrs_data = self.get_rrsstore_data(mapping)
        if not rrs_data.empty:
            all_data.append(rrs_data)
        
        # tongstoreæ•°æ®
        tong_data = self.get_tongstore_data(mapping)
        if not tong_data.empty:
            all_data.append(tong_data)
        
        # jdstoreæ•°æ®
        jd_data = self.get_jdstore_data(mapping)
        if not jd_data.empty:
            all_data.append(jd_data)
        
        if not all_data:
            logger.warning("æœªè·å–åˆ°ä»»ä½•æœ‰æ•ˆçš„åº“å­˜æ•°æ®")
            return pd.DataFrame()
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        combined_df = pd.concat(all_data, ignore_index=True)
        
        # ç¡®ä¿æ•°é‡åˆ—æ˜¯æ•°å€¼ç±»å‹
        combined_df['æ•°é‡'] = pd.to_numeric(combined_df['æ•°é‡'], errors='coerce').fillna(0)
        
        # æŒ‰è§„æ ¼åç§°ã€ä»“åº“ç±»å‹èšåˆ
        result_df = combined_df.groupby(['è§„æ ¼åç§°', 'ä»“åº“ç±»å‹']).agg({
            'æ•°é‡': 'sum'
        }).reset_index()
        
        # è®¡ç®—åˆè®¡æ•°é‡ï¼ˆåªç»Ÿè®¡æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®ï¼‰
        total_df = result_df.groupby(['è§„æ ¼åç§°']).agg({
            'æ•°é‡': 'sum'
        }).reset_index()
        total_df = total_df.rename(columns={'æ•°é‡': 'åˆè®¡æ•°é‡'})
        
        # åˆå¹¶æ•°æ®
        final_df = result_df.merge(total_df, on=['è§„æ ¼åç§°'], how='left')
        
        # é‡å‘½åæ•°é‡åˆ—ä¸ºåˆ°ä»“ä½æ•°é‡
        final_df = final_df.rename(columns={'æ•°é‡': 'åˆ°ä»“ä½æ•°é‡'})
        
        # é‡æ–°æ’åºåˆ—
        final_df = final_df[['è§„æ ¼åç§°', 'ä»“åº“ç±»å‹', 'åˆè®¡æ•°é‡', 'åˆ°ä»“ä½æ•°é‡']]
        
        # ç¡®ä¿æ•°å€¼åˆ—æ˜¯æ•°å€¼ç±»å‹
        final_df['åˆè®¡æ•°é‡'] = pd.to_numeric(final_df['åˆè®¡æ•°é‡'], errors='coerce').fillna(0)
        final_df['åˆ°ä»“ä½æ•°é‡'] = pd.to_numeric(final_df['åˆ°ä»“ä½æ•°é‡'], errors='coerce').fillna(0)
        
        logger.info(f"èšåˆå®Œæˆï¼Œå…± {len(final_df)} æ¡è®°å½•ï¼ˆåªåŒ…å«æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®ï¼‰")
        return final_df
    
    def get_category_mapping(self) -> Dict[str, str]:
        """è·å–å“ç±»æ˜ å°„å…³ç³»"""
        if not self.date_connection:
            logger.error("dateæ•°æ®åº“æœªè¿æ¥")
            return {}
        
        try:
            # è·å–matchstoreè¡¨æ ¼
            cursor = self.date_connection.cursor()
            cursor.execute("SHOW TABLES LIKE '%matchstore%'")
            tables = cursor.fetchall()
            
            if not tables:
                logger.warning("æœªæ‰¾åˆ°matchstoreç›¸å…³è¡¨æ ¼")
                return {}
            
            table_name = tables[0][0]
            
            # è·å–å“ç±»æ˜ å°„
            query = f"""
            SELECT è§„æ ¼åç§°, å“ç±»
            FROM `{table_name}`
            WHERE è§„æ ¼åç§° IS NOT NULL AND è§„æ ¼åç§° != ''
            AND å“ç±» IS NOT NULL AND å“ç±» != ''
            """
            
            df = pd.read_sql(query, self.date_connection)
            
            # å»ºç«‹æ˜ å°„
            category_mapping = {}
            for _, row in df.iterrows():
                spec_name = str(row['è§„æ ¼åç§°']).strip()
                category = str(row['å“ç±»']).strip()
                if spec_name and category and category != 'nan':
                    category_mapping[spec_name] = category
            
            logger.info(f"è·å–å“ç±»æ˜ å°„æˆåŠŸï¼Œå…± {len(category_mapping)} æ¡æ˜ å°„å…³ç³»")
            return category_mapping
            
        except Exception as e:
            logger.error(f"è·å–å“ç±»æ˜ å°„å¤±è´¥: {e}")
            return {}
    
    def create_summary_table(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºæ±‡æ€»è¡¨æ ¼ï¼šæŒ‰å“ç±»å’Œå‹å·æ±‡æ€»ï¼Œä»“åº“ç±»å‹ä½œä¸ºåˆ—"""
        if df.empty:
            return pd.DataFrame()
        
        # è·å–å“ç±»æ˜ å°„
        category_mapping = self.get_category_mapping()
        
        # æ·»åŠ å“ç±»ä¿¡æ¯
        df['å“ç±»'] = df['è§„æ ¼åç§°'].apply(lambda x: category_mapping.get(str(x).strip(), 'å…¶ä»–'))
        
        # å°†ä»“åº“ç±»å‹è½¬æ¢ä¸ºåˆ—
        pivot_df = df.pivot_table(
            index=['å“ç±»', 'è§„æ ¼åç§°'],
            columns='ä»“åº“ç±»å‹',
            values='åˆ°ä»“ä½æ•°é‡',
            aggfunc='sum',
            fill_value=0
        ).reset_index()
        
        # è®¡ç®—åˆè®¡åº“å­˜
        warehouse_columns = ['å¸¸è§„ä»“', 'é¡ºä¸°ä»“', 'äº¬ä»“', 'äº‘ä»“', 'ç»Ÿä»“', 'é‡‘èä»“']
        for col in warehouse_columns:
            if col not in pivot_df.columns:
                pivot_df[col] = 0
        
        pivot_df['åˆè®¡åº“å­˜'] = pivot_df[warehouse_columns].sum(axis=1)
        
        # é‡æ–°æ’åºåˆ—
        columns = ['å“ç±»', 'è§„æ ¼åç§°', 'åˆè®¡åº“å­˜'] + warehouse_columns
        pivot_df = pivot_df[columns]
        
        # é‡å‘½ååˆ— - ç»Ÿä¸€ä½¿ç”¨è§„æ ¼åç§°
        pivot_df = pivot_df.rename(columns={'è§„æ ¼åç§°': 'è§„æ ¼åç§°'})
        
        # æŒ‰åˆè®¡æ•°é‡æ’åºï¼šå…ˆæŒ‰å“ç±»åˆè®¡æ•°é‡æ’åºï¼Œå†æŒ‰å•å“åˆè®¡æ•°é‡æ’åº
        # è®¡ç®—æ¯ä¸ªå“ç±»çš„åˆè®¡æ•°é‡
        category_totals = pivot_df.groupby('å“ç±»')['åˆè®¡åº“å­˜'].sum().sort_values(ascending=False)
        
        # æŒ‰å“ç±»åˆè®¡æ•°é‡æ’åºï¼Œç„¶åæŒ‰å•å“åˆè®¡æ•°é‡æ’åº
        pivot_df['å“ç±»æ’åº'] = pivot_df['å“ç±»'].map(category_totals)
        pivot_df = pivot_df.sort_values(['å“ç±»æ’åº', 'åˆè®¡åº“å­˜'], ascending=[False, False])
        pivot_df = pivot_df.drop('å“ç±»æ’åº', axis=1)
        
        logger.info(f"æ±‡æ€»è¡¨æ ¼åˆ›å»ºå®Œæˆï¼Œå…± {len(pivot_df)} æ¡è®°å½•")
        return pivot_df
    
    def generate_report(self, df: pd.DataFrame) -> str:
        """ç”ŸæˆæŠ¥å‘Š"""
        if df.empty:
            return "æš‚æ— åº“å­˜æ•°æ®"
        
        # åˆ›å»ºæ±‡æ€»è¡¨æ ¼
        summary_df = self.create_summary_table(df)
        
        # è·å–æ‰€æœ‰å“ç±»
        categories = summary_df['å“ç±»'].unique().tolist()
        
        # ç”Ÿæˆç®€åŒ–çš„HTMLè¡¨æ ¼
        html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>åº“å­˜åˆ†ææŠ¥å‘Š</title>
    <style>
        body {{ 
            font-family: "Microsoft YaHei", "å¾®è½¯é›…é»‘", Arial, sans-serif; 
            margin: 0; 
            padding: 20px; 
            background-color: #f5f5f5; 
        }}
        .container {{ 
            max-width: 1600px; 
            margin: 0 auto; 
            background-color: white; 
            padding: 20px; 
            border-radius: 8px; 
            box-shadow: 0 2px 4px rgba(0,0,0,0.1); 
        }}
        h1 {{ 
            color: #333; 
            text-align: center; 
            font-size: 14pt; 
            font-weight: bold; 
            margin-bottom: 20px;
        }}
        
        /* ç­›é€‰åŒºåŸŸ */
        .filter-area {{
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 6px;
            margin-bottom: 20px;
            border: 1px solid #e9ecef;
        }}
        .filter-row {{
            display: flex;
            align-items: center;
            gap: 15px;
            margin-bottom: 10px;
        }}
        .filter-label {{
            font-size: 12pt;
            font-weight: bold;
            min-width: 80px;
        }}
        .filter-select, .filter-input {{
            padding: 6px 12px;
            border: 1px solid #ddd;
            border-radius: 4px;
            font-size: 12pt;
            font-family: "Microsoft YaHei", "å¾®è½¯é›…é»‘", Arial, sans-serif;
        }}
        .filter-button {{
            padding: 6px 15px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 12pt;
            font-family: "Microsoft YaHei", "å¾®è½¯é›…é»‘", Arial, sans-serif;
        }}
        .filter-button:hover {{
            background-color: #0056b3;
        }}
        .clear-button {{
            background-color: #6c757d;
        }}
        .clear-button:hover {{
            background-color: #545b62;
        }}
        
        /* è¡¨æ ¼å®¹å™¨ */
        .table-container {{
            position: relative;
            max-height: 70vh;
            overflow: auto;
            border: 1px solid #ddd;
            border-radius: 6px;
        }}
        
        /* è¡¨æ ¼æ ·å¼ */
        table {{ 
            width: 100%; 
            border-collapse: collapse; 
            margin: 0;
        }}
        
        /* å›ºå®šæ ‡é¢˜è¡Œ */
        thead {{
            position: sticky;
            top: 0;
            z-index: 10;
            background-color: #f2f2f2;
        }}
        
        th, td {{ 
            border: 1px solid #ddd; 
            padding: 8px 12px; 
            text-align: left; 
            font-size: 10.5pt;
        }}
        
        th {{ 
            background-color: #f2f2f2; 
            font-weight: bold;
            font-size: 14pt;
            position: sticky;
            top: 0;
        }}
        
        tr:nth-child(even) {{ 
            background-color: #f9f9f9; 
        }}
        
        .number {{ 
            text-align: right; 
            font-family: "Microsoft YaHei", "å¾®è½¯é›…é»‘", Arial, monospace; 
        }}
        
        .timestamp {{ 
            text-align: center; 
            color: #666; 
            margin-top: 20px; 
            font-style: italic; 
            font-size: 10.5pt;
        }}
        
        .category-row {{ 
            background-color: #e3f2fd !important; 
            font-weight: bold;
            font-size: 14pt;
        }}
        
        .total-row {{
            background-color: #ffeb3b !important; 
            font-weight: bold;
            font-size: 14pt;
        }}
        
        /* ç»Ÿè®¡ä¿¡æ¯ */
        .stats-info {{
            background-color: #e8f5e8;
            padding: 10px;
            border-radius: 4px;
            margin-bottom: 10px;
            font-size: 10.5pt;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“¦ åº“å­˜åˆ†ææŠ¥å‘Š</h1>
        
        <!-- ç­›é€‰åŒºåŸŸ -->
        <div class="filter-area">
            <div class="filter-row">
                <span class="filter-label">å“ç±»ç­›é€‰:</span>
                <select id="categoryFilter" class="filter-select" onchange="onCategoryChange()">
                    <option value="">å…¨éƒ¨å“ç±»</option>
                </select>
                
                <span class="filter-label">äº§å“æœç´¢:</span>
                <select id="productFilter" class="filter-select">
                    <option value="">å…¨éƒ¨äº§å“</option>
                </select>
                
                <button onclick="applyFilter()" class="filter-button">ç­›é€‰</button>
                <button onclick="clearFilter()" class="filter-button clear-button">æ¸…é™¤</button>
            </div>
            <div class="stats-info" id="statsInfo">
                æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            </div>
        </div>
        
        <!-- è¡¨æ ¼å®¹å™¨ -->
        <div class="table-container">
            <table id="inventoryTable">
                <thead>
                    <tr>
                        <th>å“ç±»</th>
                        <th>è§„æ ¼åç§°</th>
                        <th>åˆè®¡åº“å­˜</th>
                        <th>å¸¸è§„ä»“</th>
                        <th>é¡ºä¸°ä»“</th>
                        <th>äº¬ä»“</th>
                        <th>äº‘ä»“</th>
                        <th>ç»Ÿä»“</th>
                        <th>é‡‘èä»“</th>
                    </tr>
                </thead>
                <tbody id="inventoryBody">
"""
        
        # æŒ‰å“ç±»åˆ†ç»„æ˜¾ç¤º
        for category in categories:
            category_data = summary_df[summary_df['å“ç±»'] == category]
            
            # æ·»åŠ å“ç±»å°è®¡è¡Œ
            category_total = category_data['åˆè®¡åº“å­˜'].sum()
            category_warehouse_totals = category_data[['å¸¸è§„ä»“', 'é¡ºä¸°ä»“', 'äº¬ä»“', 'äº‘ä»“', 'ç»Ÿä»“', 'é‡‘èä»“']].sum()
            
            html_content += f"""
                <tr class="category-row">
                    <td>{category} (å°è®¡)</td>
                    <td></td>
                    <td class="number">{category_total:,.0f}</td>
                    <td class="number">{category_warehouse_totals['å¸¸è§„ä»“']:,.0f}</td>
                    <td class="number">{category_warehouse_totals['é¡ºä¸°ä»“']:,.0f}</td>
                    <td class="number">{category_warehouse_totals['äº¬ä»“']:,.0f}</td>
                    <td class="number">{category_warehouse_totals['äº‘ä»“']:,.0f}</td>
                    <td class="number">{category_warehouse_totals['ç»Ÿä»“']:,.0f}</td>
                    <td class="number">{category_warehouse_totals['é‡‘èä»“']:,.0f}</td>
                </tr>
            """
            
            # æ·»åŠ è¯¥å“ç±»çš„æ‰€æœ‰è§„æ ¼åç§°
            for _, row in category_data.iterrows():
                html_content += f"""
                <tr>
                    <td>{category}</td>
                    <td>{row['è§„æ ¼åç§°']}</td>
                    <td class="number">{row['åˆè®¡åº“å­˜']:,.0f}</td>
                    <td class="number">{row['å¸¸è§„ä»“']:,.0f}</td>
                    <td class="number">{row['é¡ºä¸°ä»“']:,.0f}</td>
                    <td class="number">{row['äº¬ä»“']:,.0f}</td>
                    <td class="number">{row['äº‘ä»“']:,.0f}</td>
                    <td class="number">{row['ç»Ÿä»“']:,.0f}</td>
                    <td class="number">{row['é‡‘èä»“']:,.0f}</td>
                </tr>
                """
        
        # æ·»åŠ æ€»è®¡è¡Œ
        total_row = summary_df.sum(numeric_only=True)
        html_content += f"""
                <tr class="total-row">
                    <td colspan="2">æ€»è®¡</td>
                    <td class="number">{total_row['åˆè®¡åº“å­˜']:,.0f}</td>
                    <td class="number">{total_row['å¸¸è§„ä»“']:,.0f}</td>
                    <td class="number">{total_row['é¡ºä¸°ä»“']:,.0f}</td>
                    <td class="number">{total_row['äº¬ä»“']:,.0f}</td>
                    <td class="number">{total_row['äº‘ä»“']:,.0f}</td>
                    <td class="number">{total_row['ç»Ÿä»“']:,.0f}</td>
                    <td class="number">{total_row['é‡‘èä»“']:,.0f}</td>
                </tr>
            </tbody>
        </table>
        </div>
        
        <div class="timestamp">
            ğŸ“… æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        </div>
    </div>
    
    <script>
        // å…¨å±€æ•°æ®å­˜å‚¨
        let originalData = [];
        let currentData = [];
        
        // é¡µé¢åŠ è½½æ—¶åˆå§‹åŒ–
        document.addEventListener('DOMContentLoaded', function() {{
            initializeData();
            populateCategoryFilter();
            populateProductFilter();
            updateStats();
        }});
        
        // åˆå§‹åŒ–æ•°æ®
        function initializeData() {{
            const tbody = document.getElementById('inventoryBody');
            const rows = tbody.querySelectorAll('tr');
            
            originalData = [];
            rows.forEach(row => {{
                const cells = row.querySelectorAll('td');
                if (cells.length >= 9 && !row.classList.contains('total-row')) {{
                    originalData.push({{
                        element: row.cloneNode(true),
                        category: cells[0].textContent.trim(),
                        product: cells[1].textContent.trim(),
                        totalStock: parseInt(cells[2].textContent.replace(/,/g, '')) || 0,
                        isCategory: row.classList.contains('category-row')
                    }});
                }}
            }});
            currentData = [...originalData];
        }}
        
        // å¡«å……å“ç±»ç­›é€‰ä¸‹æ‹‰æ¡†
        function populateCategoryFilter() {{
            const categoryFilter = document.getElementById('categoryFilter');
            
            // è®¡ç®—æ¯ä¸ªå“ç±»çš„æ€»æ•°é‡
            const categoryTotals = {{}};
            originalData.filter(item => !item.isCategory).forEach(item => {{
                if (!categoryTotals[item.category]) {{
                    categoryTotals[item.category] = 0;
                }}
                categoryTotals[item.category] += item.totalStock;
            }});
            
            // æŒ‰æ€»æ•°é‡æ’åºå“ç±»
            const sortedCategories = Object.keys(categoryTotals).sort((a, b) => {{
                return categoryTotals[b] - categoryTotals[a]; // é™åºæ’åˆ—
            }});
            
            // æ¸…ç©ºå¹¶é‡æ–°å¡«å……
            categoryFilter.innerHTML = '<option value="">å…¨éƒ¨å“ç±»</option>';
            sortedCategories.forEach(category => {{
                const option = document.createElement('option');
                option.value = category;
                option.textContent = `${{category}} (åº“å­˜: ${{categoryTotals[category].toLocaleString()}})`;
                categoryFilter.appendChild(option);
            }});
        }}
        
        // å¡«å……äº§å“æœç´¢ä¸‹æ‹‰æ¡†
        function populateProductFilter() {{
            const productFilter = document.getElementById('productFilter');
            const selectedCategory = document.getElementById('categoryFilter').value;
            
            // æ ¹æ®é€‰ä¸­çš„å“ç±»ç­›é€‰äº§å“
            let filteredProducts = originalData.filter(item => !item.isCategory);
            if (selectedCategory) {{
                filteredProducts = filteredProducts.filter(item => item.category === selectedCategory);
            }}
            
            // æŒ‰æ•°é‡æ’åºäº§å“
            const sortedProducts = filteredProducts
                .sort((a, b) => b.totalStock - a.totalStock) // é™åºæ’åˆ—
                .map(item => item.product);
            
            // æ¸…ç©ºå¹¶é‡æ–°å¡«å……
            productFilter.innerHTML = '<option value="">å…¨éƒ¨äº§å“</option>';
            sortedProducts.forEach(product => {{
                const option = document.createElement('option');
                option.value = product;
                option.textContent = product;
                productFilter.appendChild(option);
            }});
        }}
        
        // å“ç±»ç­›é€‰å˜åŒ–æ—¶è§¦å‘äº§å“æœç´¢ä¸‹æ‹‰æ¡†æ›´æ–°
        function onCategoryChange() {{
            populateProductFilter();
            applyFilter();
        }}
        
        // åº”ç”¨ç­›é€‰
        function applyFilter() {{
            const categoryFilter = document.getElementById('categoryFilter').value;
            const productFilter = document.getElementById('productFilter').value;
            
            currentData = originalData.filter(item => {{
                // å“ç±»ç­›é€‰
                if (categoryFilter && item.category !== categoryFilter) {{
                    return false;
                }}
                
                // äº§å“ç­›é€‰
                if (productFilter && item.product !== productFilter) {{
                    return false;
                }}
                
                return true;
            }});
            
            renderTable();
            updateStats();
        }}
        
        // æ¸…é™¤ç­›é€‰
        function clearFilter() {{
            document.getElementById('categoryFilter').value = '';
            document.getElementById('productFilter').value = '';
            currentData = [...originalData];
            populateProductFilter(); // é‡æ–°å¡«å……äº§å“ç­›é€‰
            renderTable();
            updateStats();
        }}
        
        // æ¸²æŸ“è¡¨æ ¼
        function renderTable() {{
            const tbody = document.getElementById('inventoryBody');
            const totalRow = tbody.querySelector('.total-row');
            
            // æ¸…ç©ºè¡¨æ ¼
            tbody.innerHTML = '';
            
            // æŒ‰å“ç±»åˆ†ç»„
            const groupedData = {{}};
            currentData.filter(item => !item.isCategory).forEach(item => {{
                if (!groupedData[item.category]) {{
                    groupedData[item.category] = [];
                }}
                groupedData[item.category].push(item);
            }});
            
            // è®¡ç®—å“ç±»å°è®¡
            Object.keys(groupedData).sort().forEach(category => {{
                const categoryItems = groupedData[category];
                
                // è®¡ç®—å°è®¡
                const categoryTotal = categoryItems.reduce((sum, item) => sum + item.totalStock, 0);
                const categoryRow = document.createElement('tr');
                categoryRow.className = 'category-row';
                categoryRow.innerHTML = `
                    <td>${{category}} (å°è®¡)</td>
                    <td></td>
                    <td class="number">${{categoryTotal.toLocaleString()}}</td>
                    <td class="number">-</td>
                    <td class="number">-</td>
                    <td class="number">-</td>
                    <td class="number">-</td>
                    <td class="number">-</td>
                    <td class="number">-</td>
                `;
                tbody.appendChild(categoryRow);
                
                // æ·»åŠ è¯¥å“ç±»çš„äº§å“
                categoryItems.forEach(item => {{
                    tbody.appendChild(item.element.cloneNode(true));
                }});
            }});
            
            // é‡æ–°æ·»åŠ æ€»è®¡è¡Œ
            if (totalRow) {{
                tbody.appendChild(totalRow.cloneNode(true));
            }}
        }}
        
        // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        function updateStats() {{
            const filteredProducts = currentData.filter(item => !item.isCategory);
            const totalProducts = filteredProducts.length;
            const totalStock = filteredProducts.reduce((sum, item) => sum + item.totalStock, 0);
            const categories = [...new Set(filteredProducts.map(item => item.category))].length;
            
            document.getElementById('statsInfo').innerHTML = `
                ğŸ“Š å½“å‰æ˜¾ç¤º: äº§å“ ${{totalProducts}} ç§ | å“ç±» ${{categories}} ä¸ª | æ€»åº“å­˜ ${{totalStock.toLocaleString()}} å°
            `;
        }}
    </script>
</body>
</html>"""
        
        return html_content
    
    def save_to_csv(self, df: pd.DataFrame) -> str:
        """ä¿å­˜ä¸ºCSVæ–‡ä»¶"""
        filename = f"inventory_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        logger.info(f"æ•°æ®å·²ä¿å­˜åˆ° {filename}")
        return filename
    
    def deploy_to_edgeone(self, html_content: str, filename: str) -> str:
        """ä½¿ç”¨EdgeOne CLIéƒ¨ç½²åˆ°EdgeOne Pages - å½»åº•ä¿®å¤ç‰ˆæœ¬"""
        try:
            logger.info("ğŸš€ å¼€å§‹éƒ¨ç½²åˆ°EdgeOne Pages...")
            
            # è·å–ä¸»é¡¹ç›®çš„reportsç›®å½•è·¯å¾„
            script_dir = os.path.dirname(os.path.abspath(__file__))  # å½“å‰è„šæœ¬ç›®å½•ï¼ˆstoreï¼‰
            main_project_dir = os.path.dirname(script_dir)  # ä¸»é¡¹ç›®ç›®å½•ï¼ˆwecomchanï¼‰
            reports_dir = os.path.join(main_project_dir, "reports")  # ä¸»é¡¹ç›®çš„reportsç›®å½•
            
            # ç¡®ä¿reportsç›®å½•å­˜åœ¨
            os.makedirs(reports_dir, exist_ok=True)
            logger.info(f"ğŸ“ ç¡®ä¿reportsç›®å½•å­˜åœ¨: {reports_dir}")
            
            # ä¿å­˜HTMLæ–‡ä»¶åˆ°ä¸»é¡¹ç›®çš„reportsç›®å½•
            file_path = os.path.join(reports_dir, filename)
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            logger.info(f"ğŸ“„ å·²ä¿å­˜HTMLæ–‡ä»¶: {file_path}")
            
            # æ£€æµ‹æ“ä½œç³»ç»Ÿ
            import platform
            is_windows = platform.system() == "Windows"
            
            # æ ¹æ®æ“ä½œç³»ç»Ÿç¡®å®šEdgeOne CLIè·¯å¾„
            if is_windows:
                edgeone_cmd = EDGEONE_CLI_PATH
                edgeone_cmd_alt = EDGEONE_CLI_PATH_ALT
            else:
                edgeone_cmd = EDGEONE_CLI_PATH
                edgeone_cmd_alt = EDGEONE_CLI_PATH_ALT
            
            # æ£€æŸ¥EdgeOne CLIæ˜¯å¦å¯ç”¨
            def check_edgeone_cli():
                try:
                    import subprocess
                    # å°è¯•ä¸»è·¯å¾„
                    try:
                        result = subprocess.run([edgeone_cmd, "--version"], 
                                          capture_output=True, text=True, check=True, timeout=10)
                        logger.info(f"âœ… EdgeOne CLI å·²å®‰è£…: {edgeone_cmd}")
                        return edgeone_cmd
                    except:
                        # å°è¯•å¤‡ç”¨è·¯å¾„
                        try:
                            result = subprocess.run([edgeone_cmd_alt, "--version"], 
                                              capture_output=True, text=True, check=True, timeout=10)
                            logger.info(f"âœ… EdgeOne CLI å·²å®‰è£… (å¤‡ç”¨è·¯å¾„): {edgeone_cmd_alt}")
                            return edgeone_cmd_alt
                        except:
                            pass
                    
                    logger.error("âŒ EdgeOne CLI ä¸å¯ç”¨")
                    return None
                except Exception as e:
                    logger.error(f"âŒ EdgeOne CLI æ£€æŸ¥å¤±è´¥: {e}")
                    return None
            
            # æ£€æŸ¥ç™»å½•çŠ¶æ€
            def check_edgeone_login(edgeone_path):
                try:
                    import subprocess
                    result = subprocess.run([edgeone_path, "whoami"], 
                                      capture_output=True, text=True, check=True, timeout=10)
                    logger.info("âœ… EdgeOne CLI å·²ç™»å½•")
                    return True
                except Exception as e:
                    logger.error(f"âŒ EdgeOne CLI æœªç™»å½•: {e}")
                    return False
            
            # æ‰§è¡ŒCLIéƒ¨ç½² - ä¿®å¤ç‰ˆæœ¬
            def execute_cli_deploy(edgeone_path):
                try:
                    import subprocess
                    import os
                    
                    # ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œåœ¨ä¸»é¡¹ç›®ç›®å½•ä¸‹æ‰§è¡Œ
                    cmd = [
                        edgeone_path, "pages", "deploy", 
                        reports_dir,  # ä½¿ç”¨ç»å¯¹è·¯å¾„
                        "-n", EDGEONE_PROJECT
                    ]
                    
                    logger.info(f"ğŸ“¤ æ‰§è¡ŒCLIéƒ¨ç½²å‘½ä»¤: {' '.join(cmd)}")
                    logger.info(f"ğŸ“ å·¥ä½œç›®å½•: {main_project_dir}")
                    
                    # åœ¨ä¸»é¡¹ç›®ç›®å½•ä¸‹æ‰§è¡Œéƒ¨ç½²å‘½ä»¤
                    result = subprocess.run(
                        cmd, 
                        check=True, 
                        capture_output=True, 
                        text=True, 
                        timeout=300,
                        cwd=main_project_dir  # ç¡®ä¿åœ¨æ­£ç¡®çš„å·¥ä½œç›®å½•ä¸‹æ‰§è¡Œ
                    )
                    
                    logger.info("âœ… EdgeOne CLI éƒ¨ç½²æˆåŠŸï¼")
                    logger.info(f"ğŸ“¤ éƒ¨ç½²è¾“å‡º: {result.stdout}")
                    
                    # ä»éƒ¨ç½²è¾“å‡ºä¸­æå–éƒ¨ç½²ID
                    deployment_id_match = re.search(r"Created deployment with ID: (\w+)", result.stdout)
                    if deployment_id_match:
                        self.latest_deployment_id = deployment_id_match.group(1)
                        logger.info(f"âœ… æå–åˆ°éƒ¨ç½²ID: {self.latest_deployment_id}")
                    else:
                        # å°è¯•å…¶ä»–å¯èƒ½çš„æ ¼å¼
                        deployment_id_match = re.search(r"Deployment ID: (\w+)", result.stdout)
                        if deployment_id_match:
                            self.latest_deployment_id = deployment_id_match.group(1)
                            logger.info(f"âœ… æå–åˆ°éƒ¨ç½²ID: {self.latest_deployment_id}")
                        else:
                            logger.warning("âš ï¸ æœªä»CLIè¾“å‡ºä¸­æå–åˆ°éƒ¨ç½²ID")
                            self.latest_deployment_id = None
                    
                    return True
                    
                except subprocess.CalledProcessError as e:
                    logger.error(f"âŒ EdgeOne CLI éƒ¨ç½²å¤±è´¥: {e}")
                    logger.error(f"é”™è¯¯è¾“å‡º: {e.stderr}")
                    return False
                except Exception as e:
                    logger.error(f"âŒ EdgeOne CLI éƒ¨ç½²å¼‚å¸¸: {e}")
                    return False
            
            # ä¸»éƒ¨ç½²æµç¨‹
            logger.info("ğŸ” æ£€æŸ¥EdgeOne CLI...")
            edgeone_path = check_edgeone_cli()
            
            if not edgeone_path:
                logger.error("âŒ EdgeOne CLI ä¸å¯ç”¨ï¼Œè¯·å…ˆå®‰è£…")
                return None
            
            logger.info("ğŸ” æ£€æŸ¥ç™»å½•çŠ¶æ€...")
            if not check_edgeone_login(edgeone_path):
                logger.error("âŒ EdgeOne CLI æœªç™»å½•ï¼Œè¯·å…ˆè¿è¡Œç™»å½•å‘½ä»¤")
                logger.info(f"ğŸ’¡ ç™»å½•å‘½ä»¤: {edgeone_path} login")
                return None
            
            logger.info("ğŸš€ å¼€å§‹CLIéƒ¨ç½²...")
            if execute_cli_deploy(edgeone_path):
                logger.info("âœ… EdgeOne CLI éƒ¨ç½²å®Œæˆï¼")
                
                # ç­‰å¾…CDNåŒæ­¥
                logger.info("â³ ç­‰å¾…CDNåŒæ­¥...")
                time.sleep(15)  # ç­‰å¾…15ç§’è®©CDNåŒæ­¥
                
                # æ„å»ºè®¿é—®URL - ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
                verified_url = self._verify_multiple_urls(filename)
                
                if verified_url:
                    logger.info(f"âœ… URLéªŒè¯æˆåŠŸ: {verified_url}")
                    return verified_url
                else:
                    # è¿”å›é»˜è®¤URL
                    default_url = f"https://{EDGEONE_DOMAIN}/{filename}"
                    logger.info(f"ğŸ’¡ è¿”å›é»˜è®¤URL: {default_url}")
                    return default_url
            else:
                logger.error("âŒ EdgeOne CLI éƒ¨ç½²å¤±è´¥")
                return None
                
        except Exception as e:
            logger.error(f"âŒ éƒ¨ç½²è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def _verify_url_accessibility(self, url: str) -> str:
        """éªŒè¯URLå¯è®¿é—®æ€§ï¼Œè¿”å›å¯è®¿é—®çš„URL"""
        logger.info(f"ğŸ” éªŒè¯URLå¯è®¿é—®æ€§: {url}")
        
        # å¿«é€ŸéªŒè¯ï¼Œå‡å°‘ç­‰å¾…æ—¶é—´
        for attempt in range(3):  # å‡å°‘åˆ°3æ¬¡å°è¯•
            try:
                # å‡å°‘ç­‰å¾…æ—¶é—´
                wait_time = 3 + (attempt * 2)  # 3, 5, 7ç§’
                logger.info(f"â³ ç¬¬{attempt+1}æ¬¡éªŒè¯ï¼Œç­‰å¾…{wait_time}ç§’...")
                time.sleep(wait_time)
                
                response = requests.head(url, timeout=10)  # å‡å°‘è¶…æ—¶æ—¶é—´
                
                if response.status_code == 200:
                    logger.info(f"âœ… URLéªŒè¯æˆåŠŸï¼ŒçŠ¶æ€ç : {response.status_code}")
                    return url
                elif response.status_code == 404:
                    logger.info(f"âš ï¸ ç¬¬{attempt+1}æ¬¡éªŒè¯å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨ (404)")
                else:
                    logger.info(f"âš ï¸ ç¬¬{attempt+1}æ¬¡éªŒè¯å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    
            except requests.exceptions.ConnectTimeout:
                logger.info(f"âš ï¸ ç¬¬{attempt+1}æ¬¡éªŒè¯è¿æ¥è¶…æ—¶")
            except requests.exceptions.Timeout:
                logger.info(f"âš ï¸ ç¬¬{attempt+1}æ¬¡éªŒè¯è¯·æ±‚è¶…æ—¶")
            except Exception as e:
                logger.info(f"âš ï¸ ç¬¬{attempt+1}æ¬¡éªŒè¯å¼‚å¸¸: {e}")
        
        logger.warning(f"âŒ URLéªŒè¯å¤±è´¥ï¼Œä½†éƒ¨ç½²å¯èƒ½æˆåŠŸ: {url}")
        return None
    
    def _verify_multiple_urls(self, filename: str) -> str:
        """éªŒè¯å¤šç§å¯èƒ½çš„URLæ ¼å¼ï¼Œæ™ºèƒ½å¿«é€ŸéªŒè¯ - ç®€åŒ–ç‰ˆ"""
        # æ„å»ºåŸºç¡€URL
        base_url = f"https://{EDGEONE_DOMAIN}/{filename}"
        
        # å¿«é€ŸéªŒè¯ä¸»URL - åªç­‰å¾…5ç§’
        try:
            response = requests.head(base_url, timeout=5)
            if response.status_code == 200:
                logger.info(f"âœ… URLéªŒè¯æˆåŠŸ: {base_url}")
                return base_url
        except:
            pass
        
        # å¦‚æœä¸»URLå¤±è´¥ï¼Œè¿”å›åŸºç¡€URLï¼ˆé€šå¸¸CDNä¼šå¾ˆå¿«åŒæ­¥ï¼‰
        logger.info(f"ğŸ’¡ è¿”å›åŸºç¡€URLï¼ˆCDNæ­£åœ¨åŒæ­¥ï¼‰: {base_url}")
        return base_url
    
    def send_wechat_message(self, summary: str, edgeone_url: str = None) -> bool:
        """å‘é€ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯ - ä½¿ç”¨WecomChanæœåŠ¡å™¨ï¼Œé…ç½®ä¼ä¸šå¾®ä¿¡å‡­è¯"""
        try:
            # ä½¿ç”¨WecomChanæœåŠ¡å™¨ç›´æ¥å‘é€ï¼Œé…ç½®ä¼ä¸šå¾®ä¿¡å‡­è¯
            url = "http://212.64.57.87:5001/send"
            token = "wecomchan_token"
            
            # é…ç½®ä¼ä¸šå¾®ä¿¡å‡­è¯ï¼ˆç›´æ¥ä½¿ç”¨æä¾›çš„å‡­è¯ï¼‰
            corp_id = "ww5396d87e63595849"
            agent_id = "1000011"
            secret = "HakXD1he7FuOdgTUQonX562Xy7T1tRdB4-sdZ8F57II"
            
            # æ„å»ºæ¶ˆæ¯å†…å®¹
            content = summary
            if edgeone_url:
                content += f"\n\nğŸŒ åœ¨çº¿æŠ¥å‘Š: {edgeone_url}"
            
            # åˆ†æ®µå‘é€é•¿æ¶ˆæ¯
            max_length = 1000
            messages = []
            
            if len(content) <= max_length:
                messages = [content]
            else:
                # æŒ‰æ®µè½åˆ†å‰²
                paragraphs = content.split('\n\n')
                current_msg = ""
                
                for para in paragraphs:
                    if len(current_msg + para + '\n\n') <= max_length:
                        current_msg += para + '\n\n'
                    else:
                        if current_msg:
                            messages.append(current_msg.strip())
                        current_msg = para + '\n\n'
                
                if current_msg:
                    messages.append(current_msg.strip())
            
            # å‘é€æ‰€æœ‰åˆ†æ®µ
            success_count = 0
            for i, msg in enumerate(messages):
                data = {
                    "msg": msg,
                    "token": token,
                    "to_user": "weicungang",
                    "cid": corp_id,
                    "aid": agent_id,
                    "secret": secret
                }
                
                max_retries = 5
                retry_delay = 3
                
                for attempt in range(max_retries):
                    try:
                        logger.info(f"ğŸ“¤ æ­£åœ¨å‘é€æ¶ˆæ¯åˆ†æ®µ {i+1}/{len(messages)} (å°è¯• {attempt+1}/{max_retries})")
                        response = requests.post(url, json=data, timeout=30)
                        
                        # æ£€æŸ¥å“åº”å†…å®¹
                        response_text = response.text.lower()
                        if "errcode" in response_text and "0" in response_text:
                            logger.info(f"âœ… æ¶ˆæ¯åˆ†æ®µ {i+1}/{len(messages)} å‘é€æˆåŠŸ")
                            success_count += 1
                            break
                        elif "500" in response_text or "error" in response_text:
                            logger.warning(f"âš ï¸ æ¶ˆæ¯åˆ†æ®µ {i+1}/{len(messages)} å‘é€å¤±è´¥ (å°è¯• {attempt+1}/{max_retries}): {response.text}")
                            if attempt < max_retries - 1:
                                time.sleep(retry_delay)
                                retry_delay *= 1.5
                                continue
                        else:
                            logger.warning(f"âš ï¸ æ¶ˆæ¯åˆ†æ®µ {i+1}/{len(messages)} å“åº”å¼‚å¸¸ (å°è¯• {attempt+1}/{max_retries}): {response.text}")
                            if attempt < max_retries - 1:
                                time.sleep(retry_delay)
                                retry_delay *= 1.5
                                continue
                    except requests.exceptions.ConnectTimeout:
                        logger.warning(f"âš ï¸ æ¶ˆæ¯åˆ†æ®µ {i+1}/{len(messages)} è¿æ¥è¶…æ—¶ (å°è¯• {attempt+1}/{max_retries})")
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                            retry_delay *= 1.5
                            continue
                        else:
                            logger.error(f"âŒ æ¶ˆæ¯åˆ†æ®µ {i+1}/{len(messages)} è¿æ¥è¶…æ—¶ï¼Œå‘é€å¤±è´¥")
                    except requests.exceptions.Timeout:
                        logger.warning(f"âš ï¸ æ¶ˆæ¯åˆ†æ®µ {i+1}/{len(messages)} è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt+1}/{max_retries})")
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                            retry_delay *= 1.5
                            continue
                        else:
                            logger.error(f"âŒ æ¶ˆæ¯åˆ†æ®µ {i+1}/{len(messages)} è¯·æ±‚è¶…æ—¶ï¼Œå‘é€å¤±è´¥")
                    except Exception as e:
                        logger.warning(f"âš ï¸ æ¶ˆæ¯åˆ†æ®µ {i+1}/{len(messages)} å‘é€å¼‚å¸¸ (å°è¯• {attempt+1}/{max_retries}): {e}")
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                            retry_delay *= 1.5
                            continue
                        else:
                            logger.error(f"âŒ æ¶ˆæ¯åˆ†æ®µ {i+1}/{len(messages)} å‘é€å¼‚å¸¸: {e}")
                
                # åˆ†æ®µä¹‹é—´ç¨ä½œé—´éš”
                if i < len(messages) - 1:
                    time.sleep(1)
            
            if success_count == len(messages):
                logger.info(f"âœ… ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯å‘é€æˆåŠŸï¼Œå…± {len(messages)} ä¸ªåˆ†æ®µå…¨éƒ¨å‘é€æˆåŠŸ")
                return True
            elif success_count > 0:
                logger.warning(f"âš ï¸ ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯éƒ¨åˆ†å‘é€æˆåŠŸï¼Œ{success_count}/{len(messages)} ä¸ªåˆ†æ®µå‘é€æˆåŠŸ")
                return True
            else:
                logger.error(f"âŒ ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯å‘é€å¤±è´¥ï¼Œæ‰€æœ‰åˆ†æ®µå‡å‘é€å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"âŒ å‘é€ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯å¼‚å¸¸: {e}")
            return False
    
    def generate_summary(self, df: pd.DataFrame) -> str:
        """ç”Ÿæˆæ‘˜è¦ä¿¡æ¯"""
        if df.empty:
            return "ğŸ“¦ åº“å­˜åˆ†ææŠ¥å‘Š\n\nâŒ æš‚æ— åº“å­˜æ•°æ®"
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_items = len(df)
        total_quantity = df['åˆ°ä»“ä½æ•°é‡'].sum()
        unique_products = df['è§„æ ¼åç§°'].nunique()
        
        # æŒ‰ä»“åº“ç±»å‹ç»Ÿè®¡
        location_stats = df.groupby('ä»“åº“ç±»å‹')['åˆ°ä»“ä½æ•°é‡'].sum()
        
        summary = f"""ğŸ“¦ åº“å­˜åˆ†ææŠ¥å‘Š

ğŸ“Š æ€»ä½“æ¦‚å†µ:
â€¢ æ€»è®°å½•æ•°: {total_items:,}
â€¢ æ€»åº“å­˜æ•°é‡: {total_quantity:,.0f}
â€¢ äº§å“ç§ç±»: {unique_products:,}

ğŸª å„ä»“åº“ç±»å‹åº“å­˜åˆ†å¸ƒ:"""
        
        for location, quantity in location_stats.items():
            summary += f"\nâ€¢ {location}: {quantity:,.0f}"
        
        summary += f"\n\nğŸ“… æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        
        return summary
    
    def run(self):
        """ä¸»è¿è¡Œå‡½æ•°"""
        logger.info("å¼€å§‹æ‰§è¡Œåº“å­˜åˆ†æ")
        
        try:
            # è¿æ¥æ•°æ®åº“
            if not self.connect_databases():
                return False
            
            # èšåˆæ‰€æœ‰åº“å­˜æ•°æ®
            inventory_df = self.aggregate_inventory_data()
            if inventory_df.empty:
                logger.warning("æœªè·å–åˆ°åº“å­˜æ•°æ®")
                return False
            
            # ç”ŸæˆæŠ¥å‘Š
            html_report = self.generate_report(inventory_df)
            html_filename = f"inventory_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            
            # éƒ¨ç½²åˆ°EdgeOne Pages
            edgeone_url = self.deploy_to_edgeone(html_report, html_filename)
            
            # ç”Ÿæˆæ‘˜è¦
            summary = self.generate_summary(inventory_df)
            
            # å‘é€ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯
            self.send_wechat_message(summary, edgeone_url)
            
            logger.info("åº“å­˜åˆ†æå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"åº“å­˜åˆ†æå¼‚å¸¸: {e}")
            return False
        finally:
            self.close_databases()

def main():
    """ä¸»å‡½æ•°"""
    analyzer = InventoryAnalyzer()
    analyzer.run()

if __name__ == "__main__":
    main()