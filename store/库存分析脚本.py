#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åº“å­˜åˆ†æè„šæœ¬
åŠŸèƒ½ï¼šä»å¤šä¸ªæ•°æ®åº“è¡¨æ ¼è·å–åº“å­˜æ•°æ®ï¼ŒæŒ‰ä»“åº“ç±»å‹èšåˆï¼Œç”ŸæˆæŠ¥å‘Šå¹¶æ¨é€åˆ°ä¼ä¸šå¾®ä¿¡
"""

import pymysql
import pandas as pd
import json
import requests
import logging
from datetime import datetime, timedelta
import os
from typing import Dict, List, Tuple
import numpy as np
import time
import subprocess
import sys

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('åº“å­˜åˆ†æ.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# æ•°æ®åº“é…ç½®
DB_CONFIG_WDT = {
    'host': '212.64.57.87',
    'user': 'root',
    'password': 'c973ee9b500cc638',
    'database': 'wdt',
    'charset': 'utf8mb4'
}

DB_CONFIG_DATE = {
    'host': '212.64.57.87',
    'user': 'root',
    'password': 'c973ee9b500cc638',
    'database': 'Date',
    'charset': 'utf8mb4'
}

# ä¼ä¸šå¾®ä¿¡é…ç½®
WECOM_CONFIG = {
    'corpid': os.getenv('WECOM_CID', ''),
    'corpsecret': os.getenv('WECOM_SECRET', ''),
    'agentid': os.getenv('WECOM_AID', ''),
    'touser': os.getenv('WECOM_TOUID', 'weicungang')
}

# EdgeOneéƒ¨ç½²é…ç½®
EDGEONE_CONFIG = {
    'cli_path': "/Users/weixiaogang/.npm-global/bin/edgeone",
    'token': "YxsKLIORJJqehzWS0UlrPKr4qgMJjikkqdJwTQ/SOYc=",
    'project_name': "sales-report",
    'domain': "edge.haierht.cn"
}

class InventoryAnalyzer:
    """åº“å­˜åˆ†æå™¨"""
    
    def __init__(self):
        self.wdt_connection = None
        self.date_connection = None
        
    def connect_databases(self) -> bool:
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.wdt_connection = pymysql.connect(**DB_CONFIG_WDT)
            self.date_connection = pymysql.connect(**DB_CONFIG_DATE)
            logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False
    
    def close_databases(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.wdt_connection:
            self.wdt_connection.close()
        if self.date_connection:
            self.date_connection.close()
        logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    def get_wdt_stock_data(self, spec_mapping: Dict[str, Dict[str, str]]) -> pd.DataFrame:
        """è·å–wdtæ•°æ®åº“çš„stockè¡¨æ ¼æ•°æ®ï¼Œæ ¹æ®è§„æ ¼åç§°æ˜ å°„æŸ¥è¯¢"""
        if not self.wdt_connection:
            logger.error("wdtæ•°æ®åº“æœªè¿æ¥")
            return pd.DataFrame()
        
        if not spec_mapping:
            logger.warning("æ²¡æœ‰è§„æ ¼åç§°æ˜ å°„ï¼Œæ— æ³•æŸ¥è¯¢wdtæ•°æ®")
            return pd.DataFrame()
        
        try:
            # è·å–æ‰€æœ‰æœ‰æ•ˆçš„è§„æ ¼åç§°
            spec_names = list(spec_mapping.keys())
            
            if not spec_names:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„è§„æ ¼åç§°")
                return pd.DataFrame()
            
            # æ„å»ºæ‰¹é‡æŸ¥è¯¢ - ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æ¥è€Œä¸æ˜¯å‚æ•°åŒ–æŸ¥è¯¢
            spec_names_str = "','".join(spec_names)
            query = f"""
            SELECT 
                spec_name as è§„æ ¼åç§°,
                stock_num as æ•°é‡,
                CASE 
                    WHEN warehouse_name = 'å¸¸è§„ä»“' THEN 'å¸¸è§„ä»“'
                    WHEN warehouse_name LIKE '%é¡ºä¸°%' THEN 'é¡ºä¸°ä»“'
                    ELSE 'å¿½ç•¥'
                END as ä»“åº“ç±»å‹
            FROM stock 
            WHERE spec_name IN ('{spec_names_str}')
            AND (warehouse_name = 'å¸¸è§„ä»“' OR warehouse_name LIKE '%é¡ºä¸°%')
            AND stock_num > 0
            """
            
            df = pd.read_sql(query, self.wdt_connection)
            
            if not df.empty:
                logger.info(f"ä»wdt.stockè·å–æ•°æ®æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•")
                return df
            else:
                logger.warning("æœªä»wdt.stockè·å–åˆ°ä»»ä½•æ•°æ®")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"è·å–wdtæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_jinrongstore_data(self, spec_mapping: Dict[str, Dict[str, str]]) -> pd.DataFrame:
        """è·å–jinrongstoreæ•°æ®ï¼šæ ¹æ®è§„æ ¼åç§°æ˜ å°„æŸ¥è¯¢"""
        if not self.date_connection:
            logger.error("dateæ•°æ®åº“æœªè¿æ¥")
            return pd.DataFrame()
        
        if not spec_mapping:
            logger.warning("æ²¡æœ‰è§„æ ¼åç§°æ˜ å°„ï¼Œæ— æ³•æŸ¥è¯¢jinrongstoreæ•°æ®")
            return pd.DataFrame()
        
        try:
            # è·å–æ‰€æœ‰è¡¨æ ¼
            cursor = self.date_connection.cursor()
            cursor.execute("SHOW TABLES LIKE '%jinrongstore%'")
            tables = cursor.fetchall()
            
            if not tables:
                logger.warning("æœªæ‰¾åˆ°jinrongstoreç›¸å…³è¡¨æ ¼")
                return pd.DataFrame()
            
            table_name = tables[0][0]
            logger.info(f"æ‰¾åˆ°jinrongstoreè¡¨æ ¼: {table_name}")
            
            # è·å–è¡¨ç»“æ„
            cursor.execute(f"DESCRIBE `{table_name}`")
            columns = [col[0] for col in cursor.fetchall()]
            logger.info(f"jinrongstoreè¡¨æ ¼åˆ—: {columns}")
            
            # ç²¾ç¡®æŸ¥æ‰¾åˆ—å
            model_col = 'å‹å·'
            quantity_col = 'æ•°é‡'
            redeemed_col = 'å·²èµè´§'
            
            # éªŒè¯åˆ—æ˜¯å¦å­˜åœ¨
            if model_col not in columns or quantity_col not in columns or redeemed_col not in columns:
                logger.warning("jinrongstoreè¡¨æ ¼ä¸­ç¼ºå°‘å¿…è¦åˆ—")
                return pd.DataFrame()
            
            # è·å–æ‰€æœ‰jinrongstoreå¯¹åº”çš„åç§°
            jinrong_names = []
            spec_name_mapping = {}
            
            for spec_name, warehouse_names in spec_mapping.items():
                if 'jinrongstore' in warehouse_names:
                    jinrong_name = warehouse_names['jinrongstore']
                    jinrong_names.append(jinrong_name)
                    spec_name_mapping[jinrong_name] = spec_name
            
            if not jinrong_names:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°jinrongstoreå¯¹åº”çš„åç§°")
                return pd.DataFrame()
            
            # æ„å»ºæ‰¹é‡æŸ¥è¯¢
            jinrong_names_str = "','".join(jinrong_names)
            query = f"""
            SELECT 
                `{model_col}` as å¯¹åº”åç§°,
                (`{quantity_col}` - `{redeemed_col}`) as æ•°é‡
            FROM `{table_name}`
            WHERE `{model_col}` IN ('{jinrong_names_str}')
            AND (`{quantity_col}` - `{redeemed_col}`) > 0
            """
            
            df = pd.read_sql(query, self.date_connection)
            
            if not df.empty:
                # æ·»åŠ è§„æ ¼åç§°å’Œä»“åº“ç±»å‹
                df['è§„æ ¼åç§°'] = df['å¯¹åº”åç§°'].map(spec_name_mapping)
                df['ä»“åº“ç±»å‹'] = 'é‡‘èä»“'
                df = df.drop('å¯¹åº”åç§°', axis=1)
                
                logger.info(f"ä»{table_name}è·å–æ•°æ®æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•")
                return df
            else:
                logger.warning("æœªä»jinrongstoreè·å–åˆ°ä»»ä½•æ•°æ®")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"è·å–jinrongstoreæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_rrsstore_data(self, spec_mapping: Dict[str, Dict[str, str]]) -> pd.DataFrame:
        """è·å–rrsstoreæ•°æ®ï¼šæ ¹æ®è§„æ ¼åç§°æ˜ å°„æŸ¥è¯¢"""
        if not self.date_connection:
            logger.error("dateæ•°æ®åº“æœªè¿æ¥")
            return pd.DataFrame()
        
        if not spec_mapping:
            logger.warning("æ²¡æœ‰è§„æ ¼åç§°æ˜ å°„ï¼Œæ— æ³•æŸ¥è¯¢rrsstoreæ•°æ®")
            return pd.DataFrame()
        
        try:
            # è·å–æ‰€æœ‰è¡¨æ ¼
            cursor = self.date_connection.cursor()
            cursor.execute("SHOW TABLES LIKE '%rrsstore%'")
            tables = cursor.fetchall()
            
            if not tables:
                logger.warning("æœªæ‰¾åˆ°rrsstoreç›¸å…³è¡¨æ ¼")
                return pd.DataFrame()
            
            table_name = tables[0][0]
            logger.info(f"æ‰¾åˆ°rrsstoreè¡¨æ ¼: {table_name}")
            
            # ç²¾ç¡®ä½¿ç”¨æŒ‡å®šçš„åˆ—å
            model_col = 'å•†å“ç¼–ç '
            quantity_col = 'å¯ç”¨åº“å­˜æ•°é‡'
            
            # è·å–è¡¨ç»“æ„éªŒè¯
            cursor.execute(f"DESCRIBE `{table_name}`")
            columns = [col[0] for col in cursor.fetchall()]
            logger.info(f"rrsstoreè¡¨æ ¼åˆ—: {columns}")
            
            # å¦‚æœæŒ‡å®šåˆ—ä¸å­˜åœ¨ï¼Œä½¿ç”¨å®é™…å­˜åœ¨çš„åˆ—
            if model_col not in columns:
                model_col = 'ç¤¾ä¼šåŒ–ç‰©æ–™ç¼–ç '  # å¤‡é€‰
            if quantity_col not in columns:
                quantity_col = 'å¯ç”¨åº“å­˜'  # å¤‡é€‰
            
            if model_col not in columns or quantity_col not in columns:
                logger.warning("rrsstoreè¡¨æ ¼ä¸­ç¼ºå°‘å¿…è¦åˆ—")
                return pd.DataFrame()
            
            # è·å–æ‰€æœ‰rrsstoreå¯¹åº”çš„åç§°
            rrs_names = []
            spec_name_mapping = {}
            
            for spec_name, warehouse_names in spec_mapping.items():
                if 'rrsstore' in warehouse_names:
                    rrs_name = warehouse_names['rrsstore']
                    rrs_names.append(rrs_name)
                    spec_name_mapping[rrs_name] = spec_name
            
            if not rrs_names:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°rrsstoreå¯¹åº”çš„åç§°")
                return pd.DataFrame()
            
            # æ„å»ºæ‰¹é‡æŸ¥è¯¢
            rrs_names_str = "','".join(rrs_names)
            query = f"""
            SELECT 
                `{model_col}` as å¯¹åº”åç§°,
                CAST(`{quantity_col}` AS SIGNED) as æ•°é‡
            FROM `{table_name}`
            WHERE `{model_col}` IN ('{rrs_names_str}')
            AND CAST(`{quantity_col}` AS SIGNED) > 0
            """
            
            df = pd.read_sql(query, self.date_connection)
            
            if not df.empty:
                # æ·»åŠ è§„æ ¼åç§°å’Œä»“åº“ç±»å‹
                df['è§„æ ¼åç§°'] = df['å¯¹åº”åç§°'].map(spec_name_mapping)
                df['ä»“åº“ç±»å‹'] = 'äº‘ä»“'
                df = df.drop('å¯¹åº”åç§°', axis=1)
                
                logger.info(f"ä»{table_name}è·å–æ•°æ®æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•")
                return df
            else:
                logger.warning("æœªä»rrsstoreè·å–åˆ°ä»»ä½•æ•°æ®")
                return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"è·å–rrsstoreæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_tongstore_data(self, spec_mapping: Dict[str, Dict[str, str]]) -> pd.DataFrame:
        """è·å–tongstoreæ•°æ®ï¼šæ ¹æ®è§„æ ¼åç§°æ˜ å°„æŸ¥è¯¢"""
        if not self.date_connection:
            logger.error("dateæ•°æ®åº“æœªè¿æ¥")
            return pd.DataFrame()
        
        if not spec_mapping:
            logger.warning("æ²¡æœ‰è§„æ ¼åç§°æ˜ å°„ï¼Œæ— æ³•æŸ¥è¯¢tongstoreæ•°æ®")
            return pd.DataFrame()
        
        try:
            # è·å–æ‰€æœ‰è¡¨æ ¼
            cursor = self.date_connection.cursor()
            cursor.execute("SHOW TABLES LIKE '%tongstore%'")
            tables = cursor.fetchall()
            
            if not tables:
                logger.warning("æœªæ‰¾åˆ°tongstoreç›¸å…³è¡¨æ ¼")
                return pd.DataFrame()
            
            table_name = tables[0][0]
            logger.info(f"æ‰¾åˆ°tongstoreè¡¨æ ¼: {table_name}")
            
            # è·å–å‰10è¡Œæ•°æ®æ¥åˆ†æç»“æ„
            query_sample = f"SELECT * FROM `{table_name}` LIMIT 10"
            df_sample = pd.read_sql(query_sample, self.date_connection)
            
            logger.info(f"tongstoreæ•°æ®é¢„è§ˆ: \n{df_sample.to_string()}")
            
            # æ ¹æ®å®é™…æ•°æ®ç»“æ„ç¡®å®šåˆ—å
            columns = df_sample.columns.tolist()
            logger.info(f"tongstoreæ‰€æœ‰åˆ—: {columns}")
            
            # æ ¹æ®æ•°æ®é¢„è§ˆï¼Œç¡®å®šæ­£ç¡®çš„åˆ—å
            # ä»é¢„è§ˆæ•°æ®çœ‹ï¼Œå•†å“åç§°åœ¨__EMPTY_1åˆ—ï¼Œæ•°é‡åœ¨__EMPTY_2åˆ—
            product_col_actual = '__EMPTY_1'  # å•†å“åç§°åˆ—
            quantity_col_actual = '__EMPTY_2'  # æ•°é‡åˆ—
            
            logger.info(f"ä½¿ç”¨åˆ—: {product_col_actual} ä½œä¸ºå•†å“åç§°, {quantity_col_actual} ä½œä¸ºæ•°é‡")
            
            # è·å–æ‰€æœ‰tongstoreå¯¹åº”çš„åç§°
            tong_names = []
            spec_name_mapping = {}
            
            for spec_name, warehouse_names in spec_mapping.items():
                if 'tongstore' in warehouse_names:
                    tong_name = warehouse_names['tongstore']
                    tong_names.append(tong_name)
                    spec_name_mapping[tong_name] = spec_name
            
            if not tong_names:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°tongstoreå¯¹åº”çš„åç§°")
                return pd.DataFrame()
            
            # æ„å»ºæ‰¹é‡æŸ¥è¯¢
            tong_names_str = "','".join(tong_names)
            query = f"""
            SELECT 
                `{product_col_actual}` as å¯¹åº”åç§°,
                CAST(`{quantity_col_actual}` AS SIGNED) as æ•°é‡
            FROM `{table_name}`
            WHERE `{product_col_actual}` IN ('{tong_names_str}')
            AND `{product_col_actual}` IS NOT NULL 
            AND `{product_col_actual}` != ''
            AND `{product_col_actual}` != '_EMPTY_7'
            AND `{quantity_col_actual}` IS NOT NULL
            AND CAST(`{quantity_col_actual}` AS SIGNED) > 0
            AND `{product_col_actual}` != 'å•†å“åç§°'  -- æ’é™¤æ ‡é¢˜è¡Œ
            """
            
            df = pd.read_sql(query, self.date_connection)
            
            if not df.empty:
                # æ·»åŠ è§„æ ¼åç§°å’Œä»“åº“ç±»å‹
                df['è§„æ ¼åç§°'] = df['å¯¹åº”åç§°'].map(spec_name_mapping)
                df['ä»“åº“ç±»å‹'] = 'ç»Ÿä»“'
                df = df.drop('å¯¹åº”åç§°', axis=1)
                
                logger.info(f"ä»{table_name}è·å–æ•°æ®æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•")
                return df
            else:
                logger.warning("æœªä»tongstoreè·å–åˆ°ä»»ä½•æ•°æ®")
                return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"è·å–tongstoreæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_jdstore_data(self, spec_mapping: Dict[str, Dict[str, str]]) -> pd.DataFrame:
        """è·å–jdstoreæ•°æ®ï¼šæ ¹æ®è§„æ ¼åç§°æ˜ å°„æŸ¥è¯¢"""
        if not self.date_connection:
            logger.error("dateæ•°æ®åº“æœªè¿æ¥")
            return pd.DataFrame()
        
        if not spec_mapping:
            logger.warning("æ²¡æœ‰è§„æ ¼åç§°æ˜ å°„ï¼Œæ— æ³•æŸ¥è¯¢jdstoreæ•°æ®")
            return pd.DataFrame()
        
        try:
            # è·å–æ‰€æœ‰è¡¨æ ¼
            cursor = self.date_connection.cursor()
            cursor.execute("SHOW TABLES LIKE '%jdstore%'")
            tables = cursor.fetchall()
            
            if not tables:
                logger.warning("æœªæ‰¾åˆ°jdstoreç›¸å…³è¡¨æ ¼")
                return pd.DataFrame()
            
            table_name = tables[0][0]
            logger.info(f"æ‰¾åˆ°jdstoreè¡¨æ ¼: {table_name}")
            
            # ç²¾ç¡®ä½¿ç”¨æŒ‡å®šçš„åˆ—å
            model_col = 'äº‹ä¸šéƒ¨å•†å“ç¼–ç '
            quantity_col = 'å¯ç”¨åº“å­˜'
            
            # è·å–è¡¨ç»“æ„éªŒè¯
            cursor.execute(f"DESCRIBE `{table_name}`")
            columns = [col[0] for col in cursor.fetchall()]
            logger.info(f"jdstoreè¡¨æ ¼åˆ—: {columns}")
            
            # éªŒè¯åˆ—æ˜¯å¦å­˜åœ¨
            if model_col not in columns or quantity_col not in columns:
                logger.warning("jdstoreè¡¨æ ¼ä¸­ç¼ºå°‘å¿…è¦åˆ—")
                return pd.DataFrame()
            
            # è·å–æ‰€æœ‰jdstoreå¯¹åº”çš„åç§°
            jd_names = []
            spec_name_mapping = {}
            
            for spec_name, warehouse_names in spec_mapping.items():
                if 'jdstore' in warehouse_names:
                    jd_name = warehouse_names['jdstore']
                    jd_names.append(jd_name)
                    spec_name_mapping[jd_name] = spec_name
            
            if not jd_names:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°jdstoreå¯¹åº”çš„åç§°")
                return pd.DataFrame()
            
            # æ„å»ºæ‰¹é‡æŸ¥è¯¢
            jd_names_str = "','".join(jd_names)
            query = f"""
            SELECT 
                `{model_col}` as å¯¹åº”åç§°,
                CAST(`{quantity_col}` AS SIGNED) as æ•°é‡
            FROM `{table_name}`
            WHERE `{model_col}` IN ('{jd_names_str}')
            AND CAST(`{quantity_col}` AS SIGNED) > 0
            """
            
            df = pd.read_sql(query, self.date_connection)
            
            if not df.empty:
                # æ·»åŠ è§„æ ¼åç§°å’Œä»“åº“ç±»å‹
                df['è§„æ ¼åç§°'] = df['å¯¹åº”åç§°'].map(spec_name_mapping)
                df['ä»“åº“ç±»å‹'] = 'äº¬ä»“'
                df = df.drop('å¯¹åº”åç§°', axis=1)
                
                logger.info(f"ä»{table_name}è·å–æ•°æ®æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•")
                return df
            else:
                logger.warning("æœªä»jdstoreè·å–åˆ°ä»»ä½•æ•°æ®")
                return pd.DataFrame()
            
        except Exception as e:
            logger.error(f"è·å–jdstoreæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_matchstore_mapping(self) -> Dict[str, Dict[str, str]]:
        """è·å–matchstoreæ˜ å°„å…³ç³»ï¼šè§„æ ¼åç§°ä½œä¸ºæœ€ç»ˆäº§å“åï¼Œè¿”å›æ¯ä¸ªè§„æ ¼åç§°åœ¨å„ä¸ªåº“ä½çš„å¯¹åº”åç§°"""
        if not self.date_connection:
            logger.error("dateæ•°æ®åº“æœªè¿æ¥")
            return {}
        
        try:
            # è·å–æ‰€æœ‰è¡¨æ ¼
            cursor = self.date_connection.cursor()
            cursor.execute("SHOW TABLES LIKE '%matchstore%'")
            tables = cursor.fetchall()
            
            if not tables:
                logger.warning("æœªæ‰¾åˆ°matchstoreç›¸å…³è¡¨æ ¼")
                return {}
            
            table_name = tables[0][0]
            logger.info(f"æ‰¾åˆ°matchstoreè¡¨æ ¼: {table_name}")
            
            # è·å–è¡¨ç»“æ„
            cursor.execute(f"DESCRIBE `{table_name}`")
            columns = [col[0] for col in cursor.fetchall()]
            logger.info(f"matchstoreè¡¨æ ¼åˆ—: {columns}")
            
            # ä½¿ç”¨è§„æ ¼åç§°ä½œä¸ºæœ€ç»ˆäº§å“åï¼Œå¹¶å»ºç«‹æ˜ å°„å…³ç³»
            mapping = {}
            
            # ç²¾ç¡®æŸ¥æ‰¾åˆ—å
            spec_col = 'è§„æ ¼åç§°'
            
            # éœ€è¦æ˜ å°„çš„åˆ— - ä½¿ç”¨å®é™…çš„åˆ—å
            mapping_columns = {
                'jinrongstore': 'jinrongstore',
                'tongstore': 'tongstore', 
                'jdstore': 'jdstore',
                'rrsstore': 'rrsstore'
            }
            
            # éªŒè¯åˆ—æ˜¯å¦å­˜åœ¨
            available_columns = [col for col in mapping_columns.keys() if col in columns]
            if spec_col not in columns or not available_columns:
                logger.warning("matchstoreè¡¨æ ¼ä¸­ç¼ºå°‘å¿…è¦åˆ—")
                return {}
            
            # æ„å»ºæŸ¥è¯¢ - åªè·å–æœ‰è§„æ ¼åç§°çš„è®°å½•
            select_cols = ', '.join([f'`{col}`' for col in available_columns])
            query = f"""
            SELECT `{spec_col}`, {select_cols}
            FROM `{table_name}`
            WHERE `{spec_col}` IS NOT NULL AND `{spec_col}` != '' AND `{spec_col}` != 'nan'
            AND `{spec_col}` != 'None' AND `{spec_col}` != 'è§„æ ¼åç§°'
            """
            
            df = pd.read_sql(query, self.date_connection)
            
            # å»ºç«‹æ˜ å°„ï¼šå¯¹äºæ¯ä¸ªè§„æ ¼åç§°ï¼Œè®°å½•å®ƒåœ¨å„ä¸ªåº“ä½çš„å¯¹åº”åç§°
            for _, row in df.iterrows():
                spec_name = str(row[spec_col]).strip()
                
                # åªæœ‰å½“è§„æ ¼åç§°æœ‰æ•ˆæ—¶æ‰å»ºç«‹æ˜ å°„
                if spec_name and spec_name != 'nan' and spec_name != 'None' and spec_name != 'è§„æ ¼åç§°':
                    # ä¸ºæ¯ä¸ªè§„æ ¼åç§°åˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œè®°å½•å®ƒåœ¨å„ä¸ªåº“ä½çš„å¯¹åº”åç§°
                    spec_mapping = {}
                    
                    for col in available_columns:
                        value = str(row[col]).strip() if pd.notna(row[col]) and str(row[col]).strip() != '' else None
                        if value and value != 'nan' and value != 'None' and value != col:
                            spec_mapping[col] = value
                    
                    # åªæœ‰å½“è‡³å°‘æœ‰ä¸€ä¸ªåº“ä½æœ‰å¯¹åº”åç§°æ—¶ï¼Œæ‰æ·»åŠ åˆ°æ˜ å°„ä¸­
                    if spec_mapping:
                        mapping[spec_name] = spec_mapping
            
            logger.info(f"è·å–matchstoreæ˜ å°„æˆåŠŸï¼Œå…± {len(mapping)} ä¸ªè§„æ ¼åç§°çš„æ˜ å°„å…³ç³»")
            return mapping
            
        except Exception as e:
            logger.error(f"è·å–matchstoreæ•°æ®å¤±è´¥: {e}")
            return {}
    
    def unify_product_names(self, df: pd.DataFrame, mapping: Dict[str, str]) -> pd.DataFrame:
        """ç»Ÿä¸€äº§å“åç§°ï¼šä½¿ç”¨è§„æ ¼åç§°ä½œä¸ºæœ€ç»ˆäº§å“åï¼Œåªä¿ç•™æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®"""
        if df.empty:
            return df
        
        # åªä¿ç•™æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®
        if mapping:
            # åˆ›å»ºæ˜ å°„åçš„æ•°æ®æ¡†
            mapped_data = []
            for _, row in df.iterrows():
                product_name = str(row['äº§å“åç§°']).strip()
                # ä¸¥æ ¼åŒ¹é…ï¼šåªæœ‰å®Œå…¨åŒ¹é…çš„æ•°æ®æ‰ä¿ç•™
                if product_name in mapping:
                    # åªä¿ç•™æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®
                    new_row = row.copy()
                    new_row['è§„æ ¼åç§°'] = mapping[product_name]
                    mapped_data.append(new_row)
            
            if mapped_data:
                result_df = pd.DataFrame(mapped_data)
                logger.info(f"ç»Ÿä¸€äº§å“åç§°å®Œæˆï¼Œä¿ç•™ {len(result_df)} æ¡æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®")
                return result_df
            else:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®")
                return pd.DataFrame()
        else:
            # å¦‚æœæ²¡æœ‰æ˜ å°„å…³ç³»ï¼Œè¿”å›ç©ºæ•°æ®æ¡†
            logger.warning("æ²¡æœ‰æ˜ å°„å…³ç³»ï¼Œè¿”å›ç©ºæ•°æ®")
            return pd.DataFrame()
    
    def aggregate_inventory_data(self) -> pd.DataFrame:
        """èšåˆæ‰€æœ‰åº“å­˜æ•°æ®ï¼šåªç»Ÿè®¡æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®"""
        logger.info("å¼€å§‹èšåˆåº“å­˜æ•°æ®")
        
        # è·å–æ˜ å°„å…³ç³»
        mapping = self.get_matchstore_mapping()
        
        if not mapping:
            logger.warning("æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆçš„æ˜ å°„å…³ç³»ï¼Œæ— æ³•è¿›è¡Œæ•°æ®èšåˆ")
            return pd.DataFrame()
        
        # è·å–å„ä»“åº“æ•°æ®
        all_data = []
        
        # wdtæ•°æ®
        wdt_data = self.get_wdt_stock_data(mapping)
        if not wdt_data.empty:
            all_data.append(wdt_data)
        
        # jinrongstoreæ•°æ®
        jinrong_data = self.get_jinrongstore_data(mapping)
        if not jinrong_data.empty:
            all_data.append(jinrong_data)
        
        # rrsstoreæ•°æ®
        rrs_data = self.get_rrsstore_data(mapping)
        if not rrs_data.empty:
            all_data.append(rrs_data)
        
        # tongstoreæ•°æ®
        tong_data = self.get_tongstore_data(mapping)
        if not tong_data.empty:
            all_data.append(tong_data)
        
        # jdstoreæ•°æ®
        jd_data = self.get_jdstore_data(mapping)
        if not jd_data.empty:
            all_data.append(jd_data)
        
        if not all_data:
            logger.warning("æœªè·å–åˆ°ä»»ä½•æœ‰æ•ˆçš„åº“å­˜æ•°æ®")
            return pd.DataFrame()
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        combined_df = pd.concat(all_data, ignore_index=True)
        
        # ç¡®ä¿æ•°é‡åˆ—æ˜¯æ•°å€¼ç±»å‹
        combined_df['æ•°é‡'] = pd.to_numeric(combined_df['æ•°é‡'], errors='coerce').fillna(0)
        
        # æŒ‰è§„æ ¼åç§°ã€ä»“åº“ç±»å‹èšåˆ
        result_df = combined_df.groupby(['è§„æ ¼åç§°', 'ä»“åº“ç±»å‹']).agg({
            'æ•°é‡': 'sum'
        }).reset_index()
        
        # è®¡ç®—åˆè®¡æ•°é‡ï¼ˆåªç»Ÿè®¡æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®ï¼‰
        total_df = result_df.groupby(['è§„æ ¼åç§°']).agg({
            'æ•°é‡': 'sum'
        }).reset_index()
        total_df = total_df.rename(columns={'æ•°é‡': 'åˆè®¡æ•°é‡'})
        
        # åˆå¹¶æ•°æ®
        final_df = result_df.merge(total_df, on=['è§„æ ¼åç§°'], how='left')
        
        # é‡å‘½åæ•°é‡åˆ—ä¸ºåˆ°ä»“ä½æ•°é‡
        final_df = final_df.rename(columns={'æ•°é‡': 'åˆ°ä»“ä½æ•°é‡'})
        
        # é‡æ–°æ’åºåˆ—
        final_df = final_df[['è§„æ ¼åç§°', 'ä»“åº“ç±»å‹', 'åˆè®¡æ•°é‡', 'åˆ°ä»“ä½æ•°é‡']]
        
        # ç¡®ä¿æ•°å€¼åˆ—æ˜¯æ•°å€¼ç±»å‹
        final_df['åˆè®¡æ•°é‡'] = pd.to_numeric(final_df['åˆè®¡æ•°é‡'], errors='coerce').fillna(0)
        final_df['åˆ°ä»“ä½æ•°é‡'] = pd.to_numeric(final_df['åˆ°ä»“ä½æ•°é‡'], errors='coerce').fillna(0)
        
        logger.info(f"èšåˆå®Œæˆï¼Œå…± {len(final_df)} æ¡è®°å½•ï¼ˆåªåŒ…å«æœ‰æ˜ å°„å…³ç³»çš„æ•°æ®ï¼‰")
        return final_df
    
    def get_category_mapping(self) -> Dict[str, str]:
        """è·å–å“ç±»æ˜ å°„å…³ç³»"""
        if not self.date_connection:
            logger.error("dateæ•°æ®åº“æœªè¿æ¥")
            return {}
        
        try:
            # è·å–matchstoreè¡¨æ ¼
            cursor = self.date_connection.cursor()
            cursor.execute("SHOW TABLES LIKE '%matchstore%'")
            tables = cursor.fetchall()
            
            if not tables:
                logger.warning("æœªæ‰¾åˆ°matchstoreç›¸å…³è¡¨æ ¼")
                return {}
            
            table_name = tables[0][0]
            
            # è·å–å“ç±»æ˜ å°„
            query = f"""
            SELECT è§„æ ¼åç§°, å“ç±»
            FROM `{table_name}`
            WHERE è§„æ ¼åç§° IS NOT NULL AND è§„æ ¼åç§° != ''
            AND å“ç±» IS NOT NULL AND å“ç±» != ''
            """
            
            df = pd.read_sql(query, self.date_connection)
            
            # å»ºç«‹æ˜ å°„
            category_mapping = {}
            for _, row in df.iterrows():
                spec_name = str(row['è§„æ ¼åç§°']).strip()
                category = str(row['å“ç±»']).strip()
                if spec_name and category and category != 'nan':
                    category_mapping[spec_name] = category
            
            logger.info(f"è·å–å“ç±»æ˜ å°„æˆåŠŸï¼Œå…± {len(category_mapping)} æ¡æ˜ å°„å…³ç³»")
            return category_mapping
            
        except Exception as e:
            logger.error(f"è·å–å“ç±»æ˜ å°„å¤±è´¥: {e}")
            return {}
    
    def create_summary_table(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºæ±‡æ€»è¡¨æ ¼ï¼šæŒ‰å“ç±»å’Œå‹å·æ±‡æ€»ï¼Œä»“åº“ç±»å‹ä½œä¸ºåˆ—"""
        if df.empty:
            return pd.DataFrame()
        
        # è·å–å“ç±»æ˜ å°„
        category_mapping = self.get_category_mapping()
        
        # æ·»åŠ å“ç±»ä¿¡æ¯
        df['å“ç±»'] = df['è§„æ ¼åç§°'].apply(lambda x: category_mapping.get(str(x).strip(), 'å…¶ä»–'))
        
        # å°†ä»“åº“ç±»å‹è½¬æ¢ä¸ºåˆ—
        pivot_df = df.pivot_table(
            index=['å“ç±»', 'è§„æ ¼åç§°'],
            columns='ä»“åº“ç±»å‹',
            values='åˆ°ä»“ä½æ•°é‡',
            aggfunc='sum',
            fill_value=0
        ).reset_index()
        
        # è®¡ç®—åˆè®¡åº“å­˜
        warehouse_columns = ['å¸¸è§„ä»“', 'é¡ºä¸°ä»“', 'äº¬ä»“', 'äº‘ä»“', 'ç»Ÿä»“', 'é‡‘èä»“']
        for col in warehouse_columns:
            if col not in pivot_df.columns:
                pivot_df[col] = 0
        
        pivot_df['åˆè®¡åº“å­˜'] = pivot_df[warehouse_columns].sum(axis=1)
        
        # é‡æ–°æ’åºåˆ—
        columns = ['å“ç±»', 'è§„æ ¼åç§°', 'åˆè®¡åº“å­˜'] + warehouse_columns
        pivot_df = pivot_df[columns]
        
        # é‡å‘½ååˆ— - ç»Ÿä¸€ä½¿ç”¨è§„æ ¼åç§°
        pivot_df = pivot_df.rename(columns={'è§„æ ¼åç§°': 'è§„æ ¼åç§°'})
        
        # æŒ‰åˆè®¡æ•°é‡æ’åºï¼šå…ˆæŒ‰å“ç±»åˆè®¡æ•°é‡æ’åºï¼Œå†æŒ‰å•å“åˆè®¡æ•°é‡æ’åº
        # è®¡ç®—æ¯ä¸ªå“ç±»çš„åˆè®¡æ•°é‡
        category_totals = pivot_df.groupby('å“ç±»')['åˆè®¡åº“å­˜'].sum().sort_values(ascending=False)
        
        # æŒ‰å“ç±»åˆè®¡æ•°é‡æ’åºï¼Œç„¶åæŒ‰å•å“åˆè®¡æ•°é‡æ’åº
        pivot_df['å“ç±»æ’åº'] = pivot_df['å“ç±»'].map(category_totals)
        pivot_df = pivot_df.sort_values(['å“ç±»æ’åº', 'åˆè®¡åº“å­˜'], ascending=[False, False])
        pivot_df = pivot_df.drop('å“ç±»æ’åº', axis=1)
        
        logger.info(f"æ±‡æ€»è¡¨æ ¼åˆ›å»ºå®Œæˆï¼Œå…± {len(pivot_df)} æ¡è®°å½•")
        return pivot_df
    
    def generate_report(self, df: pd.DataFrame) -> str:
        """ç”ŸæˆæŠ¥å‘Š"""
        if df.empty:
            return "æš‚æ— åº“å­˜æ•°æ®"
        
        # åˆ›å»ºæ±‡æ€»è¡¨æ ¼
        summary_df = self.create_summary_table(df)
        
        # è·å–æ‰€æœ‰å“ç±»
        categories = summary_df['å“ç±»'].unique().tolist()
        
        # ç”ŸæˆHTMLè¡¨æ ¼
        html_content = f"""
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>åº“å­˜åˆ†ææŠ¥å‘Š</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
                .container {{ max-width: 1400px; margin: 0 auto; background-color: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
                h1 {{ color: #333; text-align: center; }}
                .filters {{ margin: 20px 0; padding: 15px; background-color: #f8f9fa; border-radius: 5px; }}
                .filters label {{ margin-right: 15px; font-weight: bold; }}
                .filters select {{ padding: 5px; margin-right: 20px; border: 1px solid #ddd; border-radius: 3px; }}
                table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; font-size: 12px; }}
                th {{ background-color: #f2f2f2; font-weight: bold; position: sticky; top: 0; }}
                tr:nth-child(even) {{ background-color: #f9f9f9; }}
                .number {{ text-align: right; font-family: monospace; }}
                .timestamp {{ text-align: center; color: #666; margin-top: 20px; font-style: italic; }}
                .category-row {{ background-color: #e3f2fd !important; font-weight: bold; }}
                .product-row {{ display: table-row; }}
                .hidden {{ display: none; }}
            </style>
            <script>
                // å­˜å‚¨æ‰€æœ‰æ•°æ®
                let allData = {summary_df.to_dict('records')};
                
                function updateProductFilter() {{
                    const categoryFilter = document.getElementById('categoryFilter').value;
                    const productFilter = document.getElementById('productFilter');
                    
                    // æ¸…ç©ºäº§å“ç­›é€‰
                    productFilter.innerHTML = '<option value="">å…¨éƒ¨è§„æ ¼åç§°</option>';
                    
                    if (categoryFilter) {{
                        // è·å–è¯¥å“ç±»ä¸‹çš„æ‰€æœ‰äº§å“ï¼ŒæŒ‰æ•°é‡æ’åº
                        const categoryProducts = allData
                            .filter(item => item.å“ç±» === categoryFilter)
                            .sort((a, b) => b.åˆè®¡åº“å­˜ - a.åˆè®¡åº“å­˜);
                        
                        categoryProducts.forEach(item => {{
                            const option = document.createElement('option');
                            option.value = item.è§„æ ¼åç§°;
                            option.textContent = `${{item.è§„æ ¼åç§°}} (${{item.åˆè®¡åº“å­˜.toLocaleString()}})`;
                            productFilter.appendChild(option);
                        }});
                    }}
                    
                    filterTable();
                }}
                
                function filterTable() {{
                    const categoryFilter = document.getElementById('categoryFilter').value;
                    const productFilter = document.getElementById('productFilter').value;
                    const rows = document.querySelectorAll('tbody tr');
                    let visibleCount = 0;
                    
                    rows.forEach(row => {{
                        const categoryCell = row.cells[0];
                        const productCell = row.cells[1];
                        
                        if (!categoryCell || !productCell) return;
                        
                        const category = categoryCell.textContent.trim();
                        const product = productCell.textContent.trim();
                        
                        // æ£€æŸ¥æ˜¯å¦æ˜¯å“ç±»è¡Œï¼ˆåŒ…å«"å°è®¡"å­—æ ·ï¼‰
                        const isCategoryRow = category.includes('å°è®¡');
                        
                        if (isCategoryRow) {{
                            // å“ç±»è¡Œçš„å¤„ç†é€»è¾‘
                            const categoryName = category.replace(' (å°è®¡)', '');
                            const categoryMatch = categoryFilter === '' || categoryName === categoryFilter;
                            
                            if (categoryMatch) {{
                                row.style.display = '';
                                visibleCount++;
                            }} else {{
                                row.style.display = 'none';
                            }}
                        }} else {{
                            // äº§å“è¡Œçš„å¤„ç†é€»è¾‘
                            const categoryMatch = categoryFilter === '' || category === categoryFilter;
                            const productMatch = productFilter === '' || product === productFilter;
                            
                            if (categoryMatch && productMatch) {{
                                row.style.display = '';
                                visibleCount++;
                            }} else {{
                                row.style.display = 'none';
                            }}
                        }}
                    }});
                    
                    // æ›´æ–°æ˜¾ç¤ºä¿¡æ¯
                    document.getElementById('visibleCount').textContent = visibleCount;
                }}
                
                function resetFilters() {{
                    document.getElementById('categoryFilter').value = '';
                    document.getElementById('productFilter').innerHTML = '<option value="">å…¨éƒ¨è§„æ ¼åç§°</option>';
                    
                    // æ˜¾ç¤ºæ‰€æœ‰è¡Œ
                    const rows = document.querySelectorAll('tbody tr');
                    rows.forEach(row => {{
                        row.style.display = '';
                    }});
                    
                    filterTable();
                }}
                
                // é¡µé¢åŠ è½½æ—¶åˆå§‹åŒ–ç­›é€‰
                window.onload = function() {{
                    filterTable();
                }};
            </script>
        </head>
        <body>
            <div class="container">
                <h1>ğŸ“¦ åº“å­˜åˆ†ææŠ¥å‘Š</h1>
                
                <div class="filters">
                    <label>å“ç±»ç­›é€‰:</label>
                    <select id="categoryFilter" onchange="updateProductFilter()">
                        <option value="">å…¨éƒ¨å“ç±»</option>
                        {''.join([f'<option value="{cat}">{cat}</option>' for cat in categories])}
                    </select>
                    
                    <label>è§„æ ¼åç§°ç­›é€‰:</label>
                    <select id="productFilter" onchange="filterTable()">
                        <option value="">å…¨éƒ¨è§„æ ¼åç§°</option>
                    </select>
                    
                    <button onclick="resetFilters()" style="padding: 5px 10px; margin-left: 10px; background-color: #007bff; color: white; border: none; border-radius: 3px; cursor: pointer;">é‡ç½®ç­›é€‰</button>
                    
                    <span style="margin-left: 20px; color: #666;">æ˜¾ç¤ºè®°å½•æ•°: <span id="visibleCount">0</span></span>
                </div>
                
                <table>
                    <thead>
                        <tr>
                            <th>å“ç±»</th>
                            <th>è§„æ ¼åç§°</th>
                            <th>åˆè®¡åº“å­˜</th>
                            <th>å¸¸è§„ä»“</th>
                            <th>é¡ºä¸°ä»“</th>
                            <th>äº¬ä»“</th>
                            <th>äº‘ä»“</th>
                            <th>ç»Ÿä»“</th>
                            <th>é‡‘èä»“</th>
                        </tr>
                    </thead>
                    <tbody>
        """
        
        # æŒ‰å“ç±»åˆ†ç»„æ˜¾ç¤º
        for category in categories:
            category_data = summary_df[summary_df['å“ç±»'] == category]
            
            # æ·»åŠ å“ç±»å°è®¡è¡Œ
            category_total = category_data['åˆè®¡åº“å­˜'].sum()
            category_warehouse_totals = category_data[['å¸¸è§„ä»“', 'é¡ºä¸°ä»“', 'äº¬ä»“', 'äº‘ä»“', 'ç»Ÿä»“', 'é‡‘èä»“']].sum()
            
            html_content += f"""
                        <tr class="category-row">
                            <td>{category} (å°è®¡)</td>
                            <td></td>
                            <td class="number">{category_total:,.0f}</td>
                            <td class="number">{category_warehouse_totals['å¸¸è§„ä»“']:,.0f}</td>
                            <td class="number">{category_warehouse_totals['é¡ºä¸°ä»“']:,.0f}</td>
                            <td class="number">{category_warehouse_totals['äº¬ä»“']:,.0f}</td>
                            <td class="number">{category_warehouse_totals['äº‘ä»“']:,.0f}</td>
                            <td class="number">{category_warehouse_totals['ç»Ÿä»“']:,.0f}</td>
                            <td class="number">{category_warehouse_totals['é‡‘èä»“']:,.0f}</td>
                        </tr>
            """
            
            # æ·»åŠ è¯¥å“ç±»çš„æ‰€æœ‰è§„æ ¼åç§°
            for _, row in category_data.iterrows():
                html_content += f"""
                        <tr>
                            <td>{category}</td>
                            <td>{row['è§„æ ¼åç§°']}</td>
                            <td class="number">{row['åˆè®¡åº“å­˜']:,.0f}</td>
                            <td class="number">{row['å¸¸è§„ä»“']:,.0f}</td>
                            <td class="number">{row['é¡ºä¸°ä»“']:,.0f}</td>
                            <td class="number">{row['äº¬ä»“']:,.0f}</td>
                            <td class="number">{row['äº‘ä»“']:,.0f}</td>
                            <td class="number">{row['ç»Ÿä»“']:,.0f}</td>
                            <td class="number">{row['é‡‘èä»“']:,.0f}</td>
                        </tr>
                """
        
        # æ·»åŠ æ€»è®¡è¡Œ
        total_row = summary_df.sum(numeric_only=True)
        html_content += f"""
                        <tr style="background-color: #ffeb3b; font-weight: bold;">
                            <td colspan="2">æ€»è®¡</td>
                            <td class="number">{total_row['åˆè®¡åº“å­˜']:,.0f}</td>
                            <td class="number">{total_row['å¸¸è§„ä»“']:,.0f}</td>
                            <td class="number">{total_row['é¡ºä¸°ä»“']:,.0f}</td>
                            <td class="number">{total_row['äº¬ä»“']:,.0f}</td>
                            <td class="number">{total_row['äº‘ä»“']:,.0f}</td>
                            <td class="number">{total_row['ç»Ÿä»“']:,.0f}</td>
                            <td class="number">{total_row['é‡‘èä»“']:,.0f}</td>
                        </tr>
                    </tbody>
                </table>
                
                <div class="timestamp">
                    ğŸ“… æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
                </div>
            </div>
        </body>
        </html>
        """
        
        return html_content
    
    def save_to_csv(self, df: pd.DataFrame) -> str:
        """ä¿å­˜ä¸ºCSVæ–‡ä»¶"""
        filename = f"inventory_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        logger.info(f"æ•°æ®å·²ä¿å­˜åˆ° {filename}")
        return filename
    
    def _simple_verify_url(self, public_url: str) -> str:
        """ä¸¥æ ¼éªŒè¯URLæ˜¯å¦å¯è®¿é—®"""
        logger.info(f"ğŸ” æ­£åœ¨éªŒè¯URL: {public_url}")
        
        # ç­‰å¾…CDNåŒæ­¥ï¼Œæœ€å¤šé‡è¯•5æ¬¡
        for attempt in range(5):
            try:
                time.sleep(3)  # ç­‰å¾…CDNåŒæ­¥
                response = requests.head(public_url, timeout=15)
                
                if response.status_code == 200:
                    logger.info(f"âœ… URLéªŒè¯æˆåŠŸï¼Œæ–‡ä»¶å¯æ­£å¸¸è®¿é—®: {public_url}")
                    return public_url
                elif response.status_code == 404:
                    logger.info(f"âš ï¸ ç¬¬{attempt+1}æ¬¡éªŒè¯å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨ (404)ï¼Œç­‰å¾…CDNåŒæ­¥...")
                else:
                    logger.info(f"âš ï¸ ç¬¬{attempt+1}æ¬¡éªŒè¯å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    
            except Exception as verify_e:
                logger.info(f"âš ï¸ ç¬¬{attempt+1}æ¬¡éªŒè¯å¼‚å¸¸: {verify_e}")
        
        logger.error(f"âŒ URLéªŒè¯å¤±è´¥ï¼Œç»è¿‡5æ¬¡é‡è¯•ä»æ— æ³•è®¿é—®ï¼Œä¸è¿”å›URL")
        return None
    
    def deploy_to_edgeone(self, html_content: str, filename: str) -> str:
        """éƒ¨ç½²åˆ°EdgeOne Pages - ä½¿ç”¨æ•´ä½“æ—¥æŠ¥æ•°æ®.pyçš„éƒ¨ç½²æ–¹å¼"""
        try:
            logger.info("ğŸš€ å¼€å§‹éƒ¨ç½²åˆ°EdgeOne Pages...")
            
            # åˆ›å»ºreportsç›®å½•
            script_dir = os.path.dirname(os.path.abspath(__file__))
            reports_dir = os.path.join(script_dir, "reports")
            
            # ç¡®ä¿reportsç›®å½•å­˜åœ¨
            if not os.path.exists(reports_dir):
                os.makedirs(reports_dir, exist_ok=True)
                logger.info(f"ğŸ“ åˆ›å»ºreportsç›®å½•: {reports_dir}")
            else:
                logger.info(f"ğŸ“ ä½¿ç”¨ç°æœ‰reportsç›®å½•: {reports_dir}")
            
            # å°†HTMLå†…å®¹å†™å…¥åˆ°reportsç›®å½•
            file_path = os.path.join(reports_dir, filename)
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(html_content)
                logger.info(f"ğŸ’¾ HTMLæ–‡ä»¶å·²ä¿å­˜åˆ°: {file_path}")
                
                # éªŒè¯æ–‡ä»¶æ˜¯å¦æˆåŠŸå†™å…¥
                if os.path.exists(file_path):
                    file_size = os.path.getsize(file_path)
                    logger.info(f"âœ… æ–‡ä»¶å†™å…¥æˆåŠŸï¼Œå¤§å°: {file_size:,} å­—èŠ‚")
                else:
                    logger.error(f"âŒ æ–‡ä»¶å†™å…¥å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                    return None
                    
            except Exception as write_error:
                logger.error(f"âŒ æ–‡ä»¶å†™å…¥å¼‚å¸¸: {write_error}")
                return None
            
            # æ£€æŸ¥ç›®å½•ä¸­æ˜¯å¦æœ‰æ–‡ä»¶
            files = [f for f in os.listdir(reports_dir) if f.endswith('.html')]
            if not files:
                logger.error(f"âŒ éƒ¨ç½²ç›®å½•ä¸­æ²¡æœ‰HTMLæ–‡ä»¶: {reports_dir}")
                return None
            
            logger.info(f"ğŸ“„ æ‰¾åˆ° {len(files)} ä¸ªHTMLæ–‡ä»¶")
            
            # ä½¿ç”¨ç»å¯¹è·¯å¾„éƒ¨ç½²
            deploy_path = os.path.abspath(reports_dir)
            logger.info(f"ğŸ”§ ä½¿ç”¨ç»å¯¹è·¯å¾„éƒ¨ç½²: {deploy_path}")
            
            # ä½¿ç”¨EdgeOne CLIéƒ¨ç½²
            edgeone_cli_path = EDGEONE_CONFIG['cli_path']
            logger.info(f"ğŸ”§ ä½¿ç”¨EdgeOne CLIè·¯å¾„: {edgeone_cli_path}")
            
            # æ£€æŸ¥CLIæ˜¯å¦å­˜åœ¨
            if not os.path.exists(edgeone_cli_path):
                logger.warning(f"âŒ EdgeOne CLIä¸å­˜åœ¨: {edgeone_cli_path}")
                # å°è¯•ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„edgeone
                edgeone_cli_path = "edgeone"
                logger.info(f"ğŸ”§ å°è¯•ä½¿ç”¨ç¯å¢ƒå˜é‡: {edgeone_cli_path}")
            
            # æ„å»ºéƒ¨ç½²å‘½ä»¤
            project_name = EDGEONE_CONFIG['project_name']
            token = EDGEONE_CONFIG['token']
            
            # æ‰§è¡Œéƒ¨ç½²å‘½ä»¤
            cmd = [
                edgeone_cli_path,
                "pages",
                "deploy",
                deploy_path,  # ä½¿ç”¨ç›®å½•è·¯å¾„
                "-n", project_name,  # é¡¹ç›®åç§°
                "-t", token  # token
            ]
            
            logger.info(f"ğŸ”§ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            
            # æ‰§è¡Œéƒ¨ç½²å‘½ä»¤
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300,  # 5åˆ†é’Ÿè¶…æ—¶
                cwd=reports_dir
            )
            
            if result.returncode == 0:
                logger.info("âœ… EdgeOne Pages éƒ¨ç½²æˆåŠŸï¼")
                logger.info(f"ğŸ“¤ éƒ¨ç½²è¾“å‡º: {result.stdout}")
                
                # æ„å»ºURL
                domain = EDGEONE_CONFIG['domain']
                public_url = f"https://{domain}/{filename}"
                
                # éªŒè¯URL
                verified_url = self._simple_verify_url(public_url)
                if verified_url:
                    logger.info(f"âœ… éƒ¨ç½²æˆåŠŸï¼Œå¯è®¿é—®URL: {verified_url}")
                    return verified_url
                else:
                    logger.error("âŒ URLéªŒè¯å¤±è´¥ï¼Œä¸è¿”å›URL")
                    return None
            else:
                logger.error(f"âŒ éƒ¨ç½²å¤±è´¥: {result.stderr}")
                logger.error(f"ğŸ“¤ éƒ¨ç½²è¾“å‡º: {result.stdout}")
                return None
                
        except subprocess.TimeoutExpired:
            logger.error("âŒ éƒ¨ç½²è¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰")
            return None
        except Exception as e:
            logger.error(f"âŒ éƒ¨ç½²å¼‚å¸¸: {e}")
            return None
    
    def send_wechat_message(self, summary: str, edgeone_url: str = None) -> bool:
        """å‘é€ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯ - ä½¿ç”¨WecomChanæœåŠ¡å™¨ï¼Œé…ç½®ä¼ä¸šå¾®ä¿¡å‡­è¯"""
        try:
            # ä½¿ç”¨WecomChanæœåŠ¡å™¨ç›´æ¥å‘é€ï¼Œé…ç½®ä¼ä¸šå¾®ä¿¡å‡­è¯
            url = "http://212.64.57.87:5001/send"
            token = "wecomchan_token"
            
            # é…ç½®ä¼ä¸šå¾®ä¿¡å‡­è¯ï¼ˆç›´æ¥ä½¿ç”¨æä¾›çš„å‡­è¯ï¼‰
            corp_id = "ww5396d87e63595849"
            agent_id = "1000011"
            secret = "HakXD1he7FuOdgTUQonX562Xy7T1tRdB4-sdZ8F57II"
            
            # æ„å»ºæ¶ˆæ¯å†…å®¹
            content = summary
            if edgeone_url:
                content += f"\n\nğŸŒ åœ¨çº¿æŠ¥å‘Š: {edgeone_url}"
            
            # åˆ†æ®µå‘é€é•¿æ¶ˆæ¯
            max_length = 1000
            messages = []
            
            if len(content) <= max_length:
                messages = [content]
            else:
                # æŒ‰æ®µè½åˆ†å‰²
                paragraphs = content.split('\n\n')
                current_msg = ""
                
                for para in paragraphs:
                    if len(current_msg + para + '\n\n') <= max_length:
                        current_msg += para + '\n\n'
                    else:
                        if current_msg:
                            messages.append(current_msg.strip())
                        current_msg = para + '\n\n'
                
                if current_msg:
                    messages.append(current_msg.strip())
            
            # å‘é€æ‰€æœ‰åˆ†æ®µ
            for msg in messages:
                data = {
                    "msg": msg,
                    "token": token,
                    "to_user": "weicungang",
                    "cid": corp_id,
                    "aid": agent_id,
                    "secret": secret
                }
                
                max_retries = 5
                retry_delay = 3
                
                for attempt in range(max_retries):
                    try:
                        response = requests.post(url, json=data, timeout=30)
                        
                        if "errcode" in response.text and "0" in response.text:
                            logger.info(f"æ¶ˆæ¯å‘é€æˆåŠŸ (åˆ†æ®µ {messages.index(msg)+1}/{len(messages)})")
                            break
                        elif "500" in response.text or "error" in response.text.lower():
                            if attempt < max_retries - 1:
                                time.sleep(retry_delay)
                                retry_delay *= 1.5
                                continue
                        else:
                            if attempt < max_retries - 1:
                                time.sleep(retry_delay)
                                retry_delay *= 1.5
                                continue
                    except requests.exceptions.ConnectTimeout:
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                            retry_delay *= 1.5
                            continue
                        else:
                            logger.error("è¿æ¥è¶…æ—¶ï¼Œå‘é€å¤±è´¥")
                            return False
                    except requests.exceptions.Timeout:
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                            retry_delay *= 1.5
                            continue
                        else:
                            logger.error("è¯·æ±‚è¶…æ—¶ï¼Œå‘é€å¤±è´¥")
                            return False
                    except Exception as e:
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                            retry_delay *= 1.5
                            continue
                        else:
                            logger.error(f"å‘é€å¼‚å¸¸: {e}")
                            return False
                
                # åˆ†æ®µä¹‹é—´ç¨ä½œé—´éš”
                if len(messages) > 1:
                    time.sleep(1)
            
            logger.info("ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯å‘é€æˆåŠŸ")
            return True
                
        except Exception as e:
            logger.error(f"å‘é€ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯å¼‚å¸¸: {e}")
            return False
    
    def generate_summary(self, df: pd.DataFrame) -> str:
        """ç”Ÿæˆæ‘˜è¦ä¿¡æ¯"""
        if df.empty:
            return "ğŸ“¦ åº“å­˜åˆ†ææŠ¥å‘Š\n\nâŒ æš‚æ— åº“å­˜æ•°æ®"
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_items = len(df)
        total_quantity = df['åˆ°ä»“ä½æ•°é‡'].sum()
        unique_products = df['è§„æ ¼åç§°'].nunique()
        
        # æŒ‰ä»“åº“ç±»å‹ç»Ÿè®¡
        location_stats = df.groupby('ä»“åº“ç±»å‹')['åˆ°ä»“ä½æ•°é‡'].sum()
        
        summary = f"""ğŸ“¦ åº“å­˜åˆ†ææŠ¥å‘Š

ğŸ“Š æ€»ä½“æ¦‚å†µ:
â€¢ æ€»è®°å½•æ•°: {total_items:,}
â€¢ æ€»åº“å­˜æ•°é‡: {total_quantity:,.0f}
â€¢ äº§å“ç§ç±»: {unique_products:,}

ğŸª å„ä»“åº“ç±»å‹åº“å­˜åˆ†å¸ƒ:"""
        
        for location, quantity in location_stats.items():
            summary += f"\nâ€¢ {location}: {quantity:,.0f}"
        
        summary += f"\n\nğŸ“… æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        
        return summary
    
    def run(self):
        """ä¸»è¿è¡Œå‡½æ•°"""
        logger.info("å¼€å§‹æ‰§è¡Œåº“å­˜åˆ†æ")
        
        try:
            # è¿æ¥æ•°æ®åº“
            if not self.connect_databases():
                return False
            
            # èšåˆæ‰€æœ‰åº“å­˜æ•°æ®
            inventory_df = self.aggregate_inventory_data()
            if inventory_df.empty:
                logger.warning("æœªè·å–åˆ°åº“å­˜æ•°æ®")
                return False
            
            # ç”ŸæˆæŠ¥å‘Š
            html_report = self.generate_report(inventory_df)
            html_filename = f"inventory_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            
            # éƒ¨ç½²åˆ°EdgeOne Pages
            edgeone_url = self.deploy_to_edgeone(html_report, html_filename)
            
            # ç”Ÿæˆæ‘˜è¦
            summary = self.generate_summary(inventory_df)
            
            # å‘é€ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯
            self.send_wechat_message(summary, edgeone_url)
            
            logger.info("åº“å­˜åˆ†æå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"åº“å­˜åˆ†æå¼‚å¸¸: {e}")
            return False
        finally:
            self.close_databases()

def main():
    """ä¸»å‡½æ•°"""
    analyzer = InventoryAnalyzer()
    analyzer.run()

if __name__ == "__main__":
    main()