#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# è§£å†³ä¸­æ–‡ç¼–ç é—®é¢˜ - å¼ºåˆ¶UTF-8ç¯å¢ƒ
import os
import sys
import locale
import logging
from datetime import datetime, timedelta

# å¼ºåˆ¶è®¾ç½®UTF-8ç¯å¢ƒ
os.environ['PYTHONIOENCODING'] = 'utf-8'
os.environ['LC_ALL'] = 'en_US.UTF-8'

# é‡æ–°é…ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸ºUTF-8
try:
    import codecs
    import io
    # æ–¹æ³•1ï¼šä½¿ç”¨io.TextIOWrapperåŒ…è£…
    if hasattr(sys.stdout, 'buffer'):
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
except Exception as e:
    print(f"ç¼–ç è®¾ç½®è­¦å‘Š: {e}")

# è®¾ç½®localeä¸ºUTF-8æ”¯æŒçš„ç¯å¢ƒ
try:
    locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
except:
    try:
        locale.setlocale(locale.LC_ALL, 'C.UTF-8') 
    except:
        pass  # å¦‚æœéƒ½è®¾ç½®å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ

import pandas as pd
import glob
import requests
from datetime import datetime, timedelta
import traceback
import time
import json
from calendar import monthrange
import subprocess
import pymysql

# ========== æ—¥å¿—é…ç½® ==========
def setup_logging():
    """è®¾ç½®æ—¥å¿—è®°å½•"""
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    
    log_filename = f"logs/å¤šäº‹ä¸šéƒ¨æœˆæŠ¥æ•°æ®_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    return logging.getLogger(__name__)

logger = setup_logging()

# ========== é…ç½®åŒº ==========
# æ•°æ®åº“é…ç½®
DB_HOST = "212.64.57.87"
DB_PORT = 3306
DB_USER = "root"
DB_PASSWORD = "c973ee9b500cc638"
DB_NAME = "Date"
DB_CHARSET = "utf8mb4"

# å¾®ä¿¡é…ç½®
token = "wecomchan_token"
to_user = "weicungang"
url = "http://212.64.57.87:5001/send"

# äº‹ä¸šéƒ¨åˆ†ç»„é…ç½®
business_groups = {
    "ç©ºè°ƒäº‹ä¸šéƒ¨": {"keywords": ["å®¶ç”¨ç©ºè°ƒ", "å•†ç”¨ç©ºè°ƒ"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "åˆ¶å†·äº‹ä¸šéƒ¨": {"keywords": ["å†°ç®±", "å†·æŸœ"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "æ´—æŠ¤äº‹ä¸šéƒ¨": {"keywords": ["æ´—è¡£æœº", "æ™¾è¡£æœº", "å¹²è¡£æœº", "çƒ˜å¹²æœº"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "æ°´è”ç½‘äº‹ä¸šéƒ¨": {"keywords": ["çƒ­æ°´å™¨", "å‡€æ°´", "é‡‡æš–", "ç”µçƒ­æ°´å™¨", "ç‡ƒæ°”çƒ­æ°´å™¨", "å¤šèƒ½æºçƒ­æ°´å™¨"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "å¨ç”µæ´—ç¢—æœºäº‹ä¸šéƒ¨": {"keywords": ["å¨ç”µ", "æ´—ç¢—æœº"], "users": ["weicungang"]}  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
}

# æ¸ é“åˆ†ç»„é…ç½®
channel_groups = {
    "å¡è¨å¸æ¸ é“": {"keywords": ["å¡è¨å¸", "å°çº¢ä¹¦"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "å¤©çŒ«æ¸ é“": {"keywords": ["å¤©çŒ«", "æ·˜å®"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "äº¬ä¸œæ¸ é“": {"keywords": ["äº¬ä¸œ"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "æ‹¼å¤šå¤šæ¸ é“": {"keywords": ["æ‹¼å¤šå¤š"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "æŠ–éŸ³æ¸ é“": {"keywords": ["æŠ–éŸ³", "å¿«æ‰‹"], "users": ["weicungang"]}  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
}

# å›ºå®šæ”¶ä»¶äººï¼ˆalwayså‘é€ï¼‰
always_users = ["weicungang"]  # æµ‹è¯•æœŸé—´åªå‘é€ç»™ weicungang

# äº‹ä¸šéƒ¨é…ç½®ï¼ˆå®Œå…¨å‚è€ƒæ»é”€åº“å­˜æ¸…ç†è„šæœ¬çš„åˆ†ç»„é€»è¾‘ï¼‰
business_groups = {
    "ç©ºè°ƒäº‹ä¸šéƒ¨": {"keywords": ["ç©ºè°ƒ"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "åˆ¶å†·äº‹ä¸šéƒ¨": {"keywords": ["å†°ç®±","å†·æŸœ"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "æ´—æŠ¤äº‹ä¸šéƒ¨": {"keywords": ["æ´—è¡£æœº"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "æ°´è”ç½‘äº‹ä¸šéƒ¨": {"keywords": ["çƒ­æ°´å™¨", "å‡€æ°´", "é‡‡æš–", "ç”µçƒ­æ°´å™¨", "ç‡ƒæ°”çƒ­æ°´å™¨", "å¤šèƒ½æºçƒ­æ°´å™¨"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "å¨ç”µæ´—ç¢—æœºäº‹ä¸šéƒ¨": {"keywords": ["å¨ç”µ", "æ´—ç¢—æœº"], "users": ["weicungang"]}  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
}

# æ¸ é“åˆ†ç»„é…ç½®ï¼ˆæŒ‰åº—é“ºåç§°ä¸¥æ ¼ç­›é€‰ï¼‰
CHANNEL_GROUPS = {
    "å¡è¨å¸æ¸ é“": {"keywords": ["å¡è¨å¸", "å°çº¢ä¹¦"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "å¤©çŒ«æ¸ é“": {"keywords": ["å¤©çŒ«", "æ·˜å®"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "äº¬ä¸œæ¸ é“": {"keywords": ["äº¬ä¸œ"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "æ‹¼å¤šå¤šæ¸ é“": {"keywords": ["æ‹¼å¤šå¤š"], "users": ["weicungang"]},  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
    "æŠ–éŸ³æ¸ é“": {"keywords": ["æŠ–éŸ³", "å¿«æ‰‹"], "users": ["weicungang"]}  # æµ‹è¯•æœŸé—´ç»Ÿä¸€å‘é€ç»™ weicungang
}

# å›ºå®šåˆ—å
DATE_COL = 'äº¤æ˜“æ—¶é—´'
AMOUNT_COL = 'åˆ†æ‘Šåæ€»ä»·'
QTY_COL = 'å®å‘æ•°é‡'
SHOP_COL = 'åº—é“º'
CATEGORY_COL = 'è´§å“åç§°'
MODEL_COL = 'è§„æ ¼åç§°'

# æ‹¼éŸ³æ˜ å°„
pinyin_map = {
    "ç©ºè°ƒäº‹ä¸šéƒ¨": "kongtiao",
    "åˆ¶å†·äº‹ä¸šéƒ¨": "zhiling", 
    "æ´—æŠ¤äº‹ä¸šéƒ¨": "xihu",
    "æ°´è”ç½‘äº‹ä¸šéƒ¨": "shuilianwang",
    "å¨ç”µæ´—ç¢—æœºäº‹ä¸šéƒ¨": "chudianxiwangji",
    "å¡è¨å¸æ¸ é“": "kasadi",
    "å¤©çŒ«æ¸ é“": "tianmao",
    "äº¬ä¸œæ¸ é“": "jingdong",
    "æ‹¼å¤šå¤šæ¸ é“": "pinduoduo",
    "æŠ–éŸ³æ¸ é“": "douyin"
}

def get_target_users(group_name, group_type):
    """æ ¹æ®åˆ†ç»„åç§°å’Œç±»å‹è·å–ç›®æ ‡ç”¨æˆ·ï¼Œç¡®ä¿å»é‡"""
    users = set(always_users)  # å›ºå®šæ”¶ä»¶äºº
    
    if group_type == 'business':
        # äº‹ä¸šéƒ¨åˆ†ç»„ï¼Œæ ¹æ®å…³é”®è¯åŒ¹é…ç”¨æˆ·
        for dept, conf in business_groups.items():
            if dept == group_name:
                users.update(conf["users"])
                break
    else:
        # æ¸ é“åˆ†ç»„ï¼Œæ ¹æ®æ¸ é“åŒ¹é…ç”¨æˆ·
        for channel, conf in channel_groups.items():
            if channel == group_name:
                users.update(conf["users"])
                break
    
    # ç¡®ä¿ç”¨æˆ·åˆ—è¡¨å»é‡
    target_users = list(set(users))
    return target_users

# ========== å‡½æ•°å®šä¹‰ ==========
# æ–°å¢å‡½æ•°ï¼šä»æ•°æ®åº“è·å–åˆ†é”€æ•°æ®
def get_fenxiao_data(report_date):
    """ä»HT_fenxiaoè¡¨è·å–åˆ†é”€æ•°æ®"""
    try:
        conn = pymysql.connect(
            host=DB_HOST, port=DB_PORT, user=DB_USER, 
            password=DB_PASSWORD, database=DB_NAME, charset=DB_CHARSET,
            connect_timeout=10
        )
        
        # ä½¿ç”¨fenxiaochanpinè¡¨è¿›è¡Œå•†å“åŒ¹é…ï¼ˆå·²ç¡®è®¤å­˜åœ¨æ•°æ®ï¼‰
        cursor = conn.cursor()
        
        # è·å–HT_fenxiaoè¡¨ç»“æ„
        cursor.execute("DESCRIBE HT_fenxiao")
        columns = [row[0] for row in cursor.fetchall()]
        logger.info(f"ğŸ“Š HT_fenxiaoè¡¨å­—æ®µ: {columns}")
        
        # æŸ¥æ‰¾å¯èƒ½çš„å­—æ®µå
        amount_fields = [col for col in columns if 'é‡‘é¢' in col or 'å®ä»˜' in col or 'æ”¯ä»˜' in col]
        shop_fields = [col for col in columns if 'åº—é“º' in col or 'å•†åº—' in col]
        status_fields = [col for col in columns if 'çŠ¶æ€' in col or 'è®¢å•' in col]
        time_fields = [col for col in columns if 'æ—¶é—´' in col or 'æ”¯ä»˜' in col]
        product_fields = [col for col in columns if 'äº§å“' in col or 'åç§°' in col]
        qty_fields = [col for col in columns if 'æ•°é‡' in col or 'é‡‡è´­æ•°é‡' in col]
        
        # é€‰æ‹©æœ€åˆé€‚çš„å­—æ®µå
        amount_col = 'ç”¨æˆ·å®é™…æ”¯ä»˜æ€»é¢' if 'ç”¨æˆ·å®é™…æ”¯ä»˜æ€»é¢' in columns else (amount_fields[0] if amount_fields else 'ç”¨æˆ·å®é™…æ”¯ä»˜é‡‘é¢')
        shop_col = 'åˆ†é”€å•†åº—é“ºåç§°' if 'åˆ†é”€å•†åº—é“ºåç§°' in columns else (shop_fields[0] if shop_fields else 'åˆ†é”€å•†åº—é“ºåç§°')
        status_col = 'è®¢å•çŠ¶æ€' if 'è®¢å•çŠ¶æ€' in columns else (status_fields[0] if status_fields else 'è®¢å•çŠ¶æ€')
        time_col = 'é‡‡è´­å•æ”¯ä»˜æ—¶é—´' if 'é‡‡è´­å•æ”¯ä»˜æ—¶é—´' in columns else (time_fields[0] if time_fields else 'é‡‡è´­å•æ”¯ä»˜æ—¶é—´')
        product_col = 'äº§å“åç§°' if 'äº§å“åç§°' in columns else (product_fields[0] if product_fields else 'äº§å“åç§°')
        qty_col = 'é‡‡è´­æ•°é‡' if 'é‡‡è´­æ•°é‡' in columns else (qty_fields[0] if qty_fields else 'é‡‡è´­æ•°é‡')
        
        # æŸ¥è¯¢åˆ†é”€æ•°æ®ï¼Œä½¿ç”¨åŠ¨æ€å­—æ®µåï¼Œç¡®ä¿è®¢å•çŠ¶æ€è¿‡æ»¤ç”Ÿæ•ˆ
        # åªè¿‡æ»¤æ‰ï¼šæœªä»˜æ¬¾ã€å·²å–æ¶ˆã€å·²é€€è´§
        sql = f"""
        SELECT 
            {shop_col} as åº—é“º,
            {status_col} as è®¢å•çŠ¶æ€,
            {amount_col} as åˆ†æ‘Šåæ€»ä»·,
            {time_col} as äº¤æ˜“æ—¶é—´,
            {product_col} as è§„æ ¼åç§°,
            {product_col} as è´§å“åç§°,
            {qty_col} as å®å‘æ•°é‡,
            'åˆ†é”€' as æ•°æ®æ¥æº
        FROM HT_fenxiao 
        WHERE {time_col} LIKE '{report_date}%'
        AND {status_col} NOT IN ('å·²å–æ¶ˆ', 'æœªä»˜æ¬¾', 'å·²é€€è´§')
        """
        
        logger.info(f"ğŸ“Š æ‰§è¡ŒSQL: {sql}")
        
        df_fenxiao = pd.read_sql(sql, conn)
        
        if not df_fenxiao.empty:
            logger.info(f"ğŸ“Š åˆ†é”€æ•°æ®è·å–æˆåŠŸï¼Œå…±{len(df_fenxiao)}è¡Œï¼ˆå·²è¿‡æ»¤æ— æ•ˆè®¢å•çŠ¶æ€ï¼‰")
            
            # æ˜¾ç¤ºè®¢å•çŠ¶æ€åˆ†å¸ƒï¼Œç¡®è®¤è¿‡æ»¤ç”Ÿæ•ˆ
            status_counts = df_fenxiao['è®¢å•çŠ¶æ€'].value_counts()
            logger.info(f"ğŸ“Š è¿‡æ»¤åè®¢å•çŠ¶æ€åˆ†å¸ƒ:")
            for status, count in status_counts.items():
                logger.info(f"   {status}: {count}æ¡")
            
            # ä¼˜åŒ–äº§å“åŒ¹é…é€»è¾‘ï¼šæ‰¹é‡å¤„ç†é¿å…é‡å¤æŸ¥è¯¢
            logger.info("ğŸ”„ å°è¯•ä»fenxiaochanpinè¡¨åŒ¹é…è§„æ ¼åç§°å’Œè´§å“åç§°...")
            
            # è·å–æ‰€æœ‰å”¯ä¸€çš„äº§å“åç§°
            unique_products = df_fenxiao['è§„æ ¼åç§°'].dropna().unique()
            logger.info(f"ğŸ“Š éœ€è¦åŒ¹é…çš„å”¯ä¸€äº§å“æ•°é‡: {len(unique_products)}")
            
            # æ„å»ºæœ€ç»ˆçš„äº§å“æ˜ å°„ç¼“å­˜
            final_product_mapping = {}
            
            # æ‰¹é‡æŸ¥è¯¢fenxiaochanpinè¡¨
            if len(unique_products) > 0:
                placeholders = ','.join(['%s'] * len(unique_products))
                batch_sql = f"SELECT äº§å“åç§°, è§„æ ¼åç§°, è´§å“åç§° FROM fenxiaochanpin WHERE äº§å“åç§° IN ({placeholders})"
                cursor.execute(batch_sql, tuple(unique_products))
                fenxiao_results = cursor.fetchall()
                
                # æ„å»ºfenxiaochanpinæ˜ å°„
                fenxiao_mapping = {}
                for product_name, model_name, goods_name in fenxiao_results:
                    fenxiao_mapping[product_name] = (model_name, goods_name)
                
                logger.info(f"ğŸ“Š fenxiaochanpinè¡¨åŒ¹é…åˆ° {len(fenxiao_mapping)} ä¸ªäº§å“")
                
                # å¤„ç†æ¯ä¸ªå”¯ä¸€äº§å“
                for product_name in unique_products:
                    if not isinstance(product_name, str):
                        continue
                        
                    if product_name in fenxiao_mapping:
                        matched_model_name, matched_product_name = fenxiao_mapping[product_name]
                        
                        # å¦‚æœè´§å“åç§°ä¸ºç©ºï¼Œä»ERPæ•°æ®æŸ¥è¯¢
                        if matched_product_name is None or matched_product_name == '':
                            erp_sql = "SELECT è´§å“åç§° FROM Daysales WHERE è§„æ ¼åç§° = %s AND è´§å“åç§° IS NOT NULL AND è´§å“åç§° != '' LIMIT 1"
                            cursor.execute(erp_sql, (matched_model_name,))
                            erp_result = cursor.fetchone()
                            if erp_result:
                                matched_product_name = erp_result[0]
                                logger.info(f"   âœ… ä»ERPæ•°æ®åŒ¹é…è´§å“åç§°: {matched_model_name} -> {matched_product_name}")
                            else:
                                # å…³é”®è¯åŒ¹é…
                                import re
                                keywords = []
                                model_patterns = re.findall(r'[A-Z0-9]{3,}', product_name.upper())
                                keywords.extend(model_patterns)
                                chinese_words = re.findall(r'[\u4e00-\u9fff]+', product_name)
                                for word in chinese_words:
                                    if len(word) >= 2 and word not in ['å¤§å®¹é‡', 'å®¶ç”¨', 'ç‹¬ç«‹å¼', 'å˜é¢‘', 'è¶…ä¸€çº§', 'æ°´æ•ˆ', 'å‡çº§æ¬¾', 'å°±è¿‘ä»“', 'æ–°å“ä¸Šå¸‚', 'è¶…å¤§å®¹é‡']:
                                        keywords.append(word)
                                
                                matched_by_keyword = False
                                for keyword in keywords[:3]:
                                    keyword_sql = "SELECT è´§å“åç§° FROM Daysales WHERE è´§å“åç§° LIKE %s AND è´§å“åç§° IS NOT NULL AND è´§å“åç§° != '' LIMIT 1"
                                    cursor.execute(keyword_sql, (f'%{keyword}%',))
                                    keyword_result = cursor.fetchone()
                                    if keyword_result:
                                        matched_product_name = keyword_result[0]
                                        logger.info(f"   âœ… é€šè¿‡å…³é”®è¯'{keyword}'åŒ¹é…åˆ°è´§å“åç§°: {matched_product_name}")
                                        matched_by_keyword = True
                                        break
                                
                                if not matched_by_keyword:
                                    matched_product_name = force_categorize_product(product_name)
                                    logger.info(f"   âš ï¸ æ‰€æœ‰åŒ¹é…æ–¹å¼éƒ½å¤±è´¥ï¼Œå¼ºåˆ¶åŒ¹é…åˆ°å“ç±»: {product_name} -> {matched_product_name}")
                        
                        final_product_mapping[product_name] = {
                            'è§„æ ¼åç§°': matched_model_name,
                            'è´§å“åç§°': matched_product_name
                        }
                        logger.info(f"   âœ… åŒ¹é…æˆåŠŸ: {product_name} -> è§„æ ¼åç§°:{matched_model_name}, è´§å“åç§°:{matched_product_name}")
                    else:
                        logger.info(f"   âš ï¸ æœªåŒ¹é…åˆ°: {product_name}ï¼Œä½¿ç”¨åŸäº§å“åç§°")
                        final_product_mapping[product_name] = {
                            'è§„æ ¼åç§°': product_name,
                            'è´§å“åç§°': product_name
                        }
            
            # æ‰¹é‡åº”ç”¨æ˜ å°„ç»“æœ
            logger.info("ğŸ”„ æ‰¹é‡åº”ç”¨äº§å“æ˜ å°„ç»“æœ...")
            for index, row in df_fenxiao.iterrows():
                product_name = row['è§„æ ¼åç§°']
                if isinstance(product_name, str) and product_name in final_product_mapping:
                    mapping = final_product_mapping[product_name]
                    df_fenxiao.at[index, 'è§„æ ¼åç§°'] = mapping['è§„æ ¼åç§°']
                    df_fenxiao.at[index, 'è´§å“åç§°'] = mapping['è´§å“åç§°']
            
            # æ·»åŠ å“ç±»å­—æ®µ
            logger.info("ğŸ”„ æ·»åŠ å“ç±»å­—æ®µ...")
            df_fenxiao['å“ç±»'] = df_fenxiao['è´§å“åç§°'].apply(categorize_product)
            
            # ä¸ºæ‰€æœ‰ht_fenxiaoæ•°æ®ç»Ÿä¸€æ·»åŠ "äº¬ä¸œ-"å‰ç¼€
            def add_jingdong_prefix(shop_name):
                if not isinstance(shop_name, str):
                    return shop_name
                
                # å¦‚æœå·²ç»æœ‰"äº¬ä¸œ-"å‰ç¼€ï¼Œç›´æ¥è¿”å›
                if shop_name.startswith('äº¬ä¸œ-'):
                    return shop_name
                
                # ç»Ÿä¸€æ·»åŠ "äº¬ä¸œ-"å‰ç¼€
                return f"äº¬ä¸œ-{shop_name}"
            
            # æ·»åŠ äº¬ä¸œæ¸ é“å‰ç¼€
            df_fenxiao['åº—é“º'] = df_fenxiao['åº—é“º'].apply(add_jingdong_prefix)
            
            logger.info(f"ğŸ“Š åˆ†é”€æ•°æ®å­—æ®µ: {df_fenxiao.columns.tolist()}")
            logger.info(f"ğŸ“Š åˆ†é”€æ•°æ®å‰3è¡Œ:")
            for i, row in df_fenxiao.head(3).iterrows():
                logger.info(f"   è¡Œ{i+1}: {dict(row)}")
            
            conn.close()
            return df_fenxiao
        else:
            logger.info("ğŸ“Š æœªè·å–åˆ°åˆ†é”€æ•°æ®")
            conn.close()
            return pd.DataFrame()
            
    except Exception as e:
        logger.error(f"âŒ è·å–åˆ†é”€æ•°æ®å¤±è´¥: {e}")
        if 'conn' in locals():
            conn.close()
        return pd.DataFrame()

def get_product_category_from_db(product_name):
    """ä»fenxiaochanpinæ•°æ®åº“è¡¨ä¸­è·å–äº§å“å“ç±»ä¿¡æ¯"""
    if not isinstance(product_name, str):
        return None
    
    try:
        conn = pymysql.connect(
            host=DB_HOST, port=DB_PORT, user=DB_USER, 
            password=DB_PASSWORD, database=DB_NAME, charset=DB_CHARSET,
            connect_timeout=10
        )
        
        # é¦–å…ˆæ£€æŸ¥fenxiaochanpinè¡¨æ˜¯å¦å­˜åœ¨
        cursor = conn.cursor()
        cursor.execute("SHOW TABLES LIKE 'fenxiaochanpin'")
        if not cursor.fetchone():
            logger.warning("âš ï¸ fenxiaochanpinè¡¨ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨äº§å“åç§°è¯†åˆ«å“ç±»")
            conn.close()
            return None
        
        # æ£€æŸ¥è¡¨ç»“æ„ï¼ŒæŸ¥æ‰¾å“ç±»å­—æ®µ
        cursor.execute("DESCRIBE fenxiaochanpin")
        columns = [row[0] for row in cursor.fetchall()]
        logger.info(f"ğŸ“Š fenxiaochanpinè¡¨å­—æ®µ: {columns}")
        
        # æŸ¥æ‰¾äº§å“åç§°å’Œå“ç±»å­—æ®µ
        product_cols = [col for col in columns if 'äº§å“' in col or 'åç§°' in col or 'è§„æ ¼' in col]
        category_cols = [col for col in columns if 'å“ç±»' in col or 'åˆ†ç±»' in col or 'category' in col.lower()]
        
        if not product_cols or not category_cols:
            logger.warning("âš ï¸ fenxiaochanpinè¡¨ä¸­æœªæ‰¾åˆ°äº§å“åç§°æˆ–å“ç±»å­—æ®µ")
            conn.close()
            return None
        
        product_col = product_cols[0]
        category_col = category_cols[0]
        
        logger.info(f"ğŸ” ä½¿ç”¨å­—æ®µ: äº§å“åç§°={product_col}, å“ç±»={category_col}")
        
        # æŸ¥è¯¢äº§å“å“ç±»
        sql = f"SELECT {category_col} FROM fenxiaochanpin WHERE {product_col} = %s LIMIT 1"
        cursor.execute(sql, (product_name,))
        result = cursor.fetchone()
        
        if result and result[0]:
            category = result[0]
            logger.info(f"âœ… æ•°æ®åº“åŒ¹é…æˆåŠŸ: {product_name} -> {category}")
            conn.close()
            return category
        else:
            logger.info(f"âš ï¸ æ•°æ®åº“æœªåŒ¹é…åˆ°: {product_name}")
            conn.close()
            return None
            
    except Exception as e:
        logger.error(f"âŒ ä»fenxiaochanpinè¡¨è·å–å“ç±»å¤±è´¥: {e}")
        return None

def categorize_product(product_name):
    """ä»äº§å“åç§°ä¸­è¯†åˆ«å“ç±»ï¼Œä¼˜å…ˆä½¿ç”¨æ•°æ®åº“åŒ¹é…"""
    if not isinstance(product_name, str):
        return "å…¶ä»–"
    
    # é¦–å…ˆå°è¯•ä»æ•°æ®åº“è·å–å“ç±»
    db_category = get_product_category_from_db(product_name)
    if db_category:
        return db_category
    
    # å¦‚æœæ•°æ®åº“åŒ¹é…å¤±è´¥ï¼Œä½¿ç”¨å…³é”®è¯è¯†åˆ«
    product_name_lower = product_name.lower()
    
    # å“ç±»å…³é”®è¯æ˜ å°„
    category_keywords = {
        "å®¶ç”¨ç©ºè°ƒ": ["ç©ºè°ƒ", "æŒ‚æœº", "æŸœæœº", "ä¸­å¤®ç©ºè°ƒ", "åˆ†ä½“å¼"],
        "å•†ç”¨ç©ºè°ƒ": ["å•†ç”¨", "å•†ç”¨ç©ºè°ƒ", "å¤šè”æœº", "é£ç®¡æœº"],
        "å†°ç®±": ["å†°ç®±", "å†·æŸœ", "å†°æŸœ", "å†·è—", "å†·å†»"],
        "æ´—è¡£æœº": ["æ´—è¡£æœº", "æ´—çƒ˜ä¸€ä½“", "æ»šç­’", "æ³¢è½®"],
        "æ´—ç¢—æœº": ["æ´—ç¢—æœº", "æ´—ç¢—", "æ´—ç¢Ÿæœº"],  # æ´—ç¢—æœºç‹¬ç«‹ä¸ºä¸€ä¸ªå“ç±»
        "çƒ­æ°´å™¨": ["çƒ­æ°´å™¨", "ç”µçƒ­æ°´å™¨", "ç‡ƒæ°”çƒ­æ°´å™¨", "å¤šèƒ½æºçƒ­æ°´å™¨"],
        "å‡€æ°´": ["å‡€æ°´", "å‡€æ°´å™¨", "å‡€æ°´æœº", "è¿‡æ»¤å™¨"],
        "é‡‡æš–": ["é‡‡æš–", "æš–æ°”", "åœ°æš–", "å£æŒ‚ç‚‰"],
        "å¨ç”µ": ["å¨ç”µ", "æ²¹çƒŸæœº", "ç‡ƒæ°”ç¶", "æ¶ˆæ¯’æŸœ", "è’¸ç®±", "çƒ¤ç®±"]  # ç§»é™¤æ´—ç¢—æœº
    }
    
    for category, keywords in category_keywords.items():
        if any(keyword in product_name_lower for keyword in keywords):
            logger.info(f"ğŸ” å…³é”®è¯åŒ¹é…: {product_name} -> {category}")
            return category
    
    logger.info(f"âš ï¸ æœªåŒ¹é…åˆ°å“ç±»: {product_name}ï¼Œå½’ç±»ä¸ºå…¶ä»–")
    return "å…¶ä»–"

def force_categorize_product(product_name):
    """å¼ºåˆ¶å°†äº§å“åç§°åŒ¹é…åˆ°å…«ä¸ªé¢„å®šä¹‰å“ç±»ä¹‹ä¸€"""
    if not isinstance(product_name, str):
        return "å†°ç®±"
    
    product_name_lower = product_name.lower()
    
    # å…«ä¸ªé¢„å®šä¹‰å“ç±»çš„å…³é”®è¯
    category_keywords = {
        "æ´—ç¢—æœº": ["æ´—ç¢—æœº", "æ´—ç¢—", "æ´—ç¢Ÿæœº", "æ´—ç¢Ÿ"],
        "å†°ç®±": ["å†°ç®±", "å†·è—", "å†·å†»", "ä¿é²œ"],
        "æ´—è¡£æœº": ["æ´—è¡£æœº", "æ´—çƒ˜ä¸€ä½“", "æ»šç­’", "æ³¢è½®", "æ´—è¡£"],
        "å†·æŸœ": ["å†·æŸœ", "å†°æŸœ", "å±•ç¤ºæŸœ", "å†·è—æŸœ", "å†·å†»æŸœ"],
        "å®¶ç”¨ç©ºè°ƒ": ["ç©ºè°ƒ", "æŒ‚æœº", "æŸœæœº", "åˆ†ä½“å¼", "å£æŒ‚", "ç«‹å¼"],
        "å•†ç©ºç©ºè°ƒ": ["å•†ç”¨", "å•†ç”¨ç©ºè°ƒ", "å¤šè”æœº", "é£ç®¡æœº", "ä¸­å¤®ç©ºè°ƒ", "å•†ç©º"],
        "å¨ç”µ": ["å¨ç”µ", "æ²¹çƒŸæœº", "ç‡ƒæ°”ç¶", "æ¶ˆæ¯’æŸœ", "è’¸ç®±", "çƒ¤ç®±", "ç¶å…·"],
        "çƒ­æ°´å™¨": ["çƒ­æ°´å™¨", "ç”µçƒ­æ°´å™¨", "ç‡ƒæ°”çƒ­æ°´å™¨", "å¤šèƒ½æºçƒ­æ°´å™¨", "çƒ­æ°´"]
    }
    
    # ä¼˜å…ˆåŒ¹é…
    for category, keywords in category_keywords.items():
        if any(keyword in product_name_lower for keyword in keywords):
            return category
    
    # æ™ºèƒ½åˆ¤æ–­é€»è¾‘
    if any(word in product_name_lower for word in ["æµ·å°”", "ç¾çš„", "æ ¼åŠ›", "tcl", "å®¹å£°"]):
        if any(word in product_name_lower for word in ["å‡", "l", "å®¹é‡"]):
            return "å†°ç®±"
        elif any(word in product_name_lower for word in ["kg", "å…¬æ–¤", "æ´—"]):
            return "æ´—è¡£æœº"
        elif any(word in product_name_lower for word in ["åŒ¹", "p", "åˆ¶å†·", "åˆ¶çƒ­"]):
            return "å®¶ç”¨ç©ºè°ƒ"
    
    # é»˜è®¤å…œåº•
    return "å†°ç®±"

def identify_tianmao_fenxiao(df):
    """ä»ERPæ•°æ®ä¸­è¯†åˆ«å¤©çŒ«åˆ†é”€æ•°æ®ï¼ˆä»“åº“å­—æ®µåŒ…å«'èœé¸Ÿä»“è‡ªæµè½¬'ï¼‰"""
    try:
        logger.info("ğŸ” å¼€å§‹è¯†åˆ«å¤©çŒ«åˆ†é”€æ•°æ®...")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»“åº“å­—æ®µ
        warehouse_col = 'ä»“åº“'
        if warehouse_col not in df.columns:
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ä»“åº“å­—æ®µ: {warehouse_col}")
            return None
        
        # æ˜¾ç¤ºä»“åº“å­—æ®µçš„å”¯ä¸€å€¼ï¼Œç”¨äºè°ƒè¯•
        unique_warehouses = df[warehouse_col].dropna().unique()
        logger.info(f"ğŸ“Š ä»“åº“å­—æ®µå”¯ä¸€å€¼: {unique_warehouses[:10]}")  # åªæ˜¾ç¤ºå‰10ä¸ª
        
        # ç­›é€‰å¤©çŒ«æ¸ é“ä¸”ä»“åº“åŒ…å«"èœé¸Ÿä»“è‡ªæµè½¬"çš„æ•°æ®
        tianmao_mask = df[SHOP_COL].astype(str).str.contains('å¤©çŒ«|æ·˜å®', na=False)
        warehouse_mask = df[warehouse_col].astype(str).str.contains('èœé¸Ÿä»“è‡ªæµè½¬', na=False)
        
        logger.info(f"ğŸ“Š å¤©çŒ«æ¸ é“æ•°æ®: {tianmao_mask.sum()}è¡Œ")
        logger.info(f"ğŸ“Š èœé¸Ÿä»“è‡ªæµè½¬æ•°æ®: {warehouse_mask.sum()}è¡Œ")
        
        tianmao_fenxiao = df[tianmao_mask & warehouse_mask].copy()
        
        if not tianmao_fenxiao.empty:
            # æ·»åŠ åˆ†é”€æ ‡è¯†
            tianmao_fenxiao['æ•°æ®æ¥æº'] = 'åˆ†é”€'
            # ä½¿ç”¨è´§å“åç§°è¿›è¡Œå“ç±»åŒ¹é…
            tianmao_fenxiao['å“ç±»'] = tianmao_fenxiao[CATEGORY_COL].apply(categorize_product)
            logger.info(f"ğŸ“Š è¯†åˆ«åˆ°å¤©çŒ«åˆ†é”€æ•°æ®: {len(tianmao_fenxiao)}è¡Œ")
            logger.info(f"ğŸ“Š å¤©çŒ«åˆ†é”€æ•°æ®ç¤ºä¾‹:")
            for i, row in tianmao_fenxiao.head(3).iterrows():
                logger.info(f"   åº—é“º: {row[SHOP_COL]}, ä»“åº“: {row[warehouse_col]}, é‡‘é¢: {row[AMOUNT_COL]}, å“ç±»: {row.get('å“ç±»', 'N/A')}")
            return tianmao_fenxiao
        else:
            logger.info("ğŸ“Š æœªè¯†åˆ«åˆ°å¤©çŒ«åˆ†é”€æ•°æ®")
            return None
            
    except Exception as e:
        logger.error(f"âŒ è¯†åˆ«å¤©çŒ«åˆ†é”€æ•°æ®å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return None

def clean_paragraphs(text):
    """æ¸…ç†æ–‡æœ¬æ®µè½ï¼Œå»é™¤å¤šä½™ç©ºè¡Œå’Œæ ¼å¼åŒ–æ–‡æœ¬"""
    if not text:
        return ""
    
    # åˆ†å‰²æˆè¡Œ
    lines = text.split('\n')
    cleaned_lines = []
    
    for line in lines:
        # å»é™¤è¡Œé¦–è¡Œå°¾ç©ºç™½
        cleaned_line = line.strip()
        cleaned_lines.append(cleaned_line)
    
    # åˆå¹¶è¿ç»­çš„ç©ºè¡Œä¸ºå•ä¸ªç©ºè¡Œ
    result_lines = []
    prev_empty = False
    
    for line in cleaned_lines:
        if line == "":
            if not prev_empty:
                result_lines.append(line)
            prev_empty = True
        else:
            result_lines.append(line)
            prev_empty = False
    
    # å»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºè¡Œ
    while result_lines and result_lines[0] == "":
        result_lines.pop(0)
    while result_lines and result_lines[-1] == "":
        result_lines.pop()
    
    return '\n'.join(result_lines)

def clean_html_tags(text):
    """æ¸…ç†HTMLæ ‡ç­¾ï¼Œç”¨äºå¾®ä¿¡æ¨é€"""
    import re
    if not text:
        return ""
    
    # ç§»é™¤HTMLæ ‡ç­¾ä½†ä¿ç•™å†…å®¹
    text = re.sub(r'<span[^>]*>', '', text)
    text = re.sub(r'', '', text)
    text = re.sub(r'<[^>]+>', '', text)
    
    return text

def check_and_fix_column_names(df):
    """æ£€æŸ¥å’Œä¿®æ­£åˆ—å"""
    print(f"ğŸ” æ£€æŸ¥åˆ—åï¼Œå½“å‰åˆ—: {list(df.columns)}")
    
    # å®šä¹‰å¯èƒ½çš„åˆ—åæ˜ å°„ï¼ˆæ‰©å±•ç‰ˆï¼‰
    column_mappings = {
        'åˆ†æ‘Šåæ€»ä»·': ['åˆ†æ‘Šåæ€»ä»·', 'æ€»ä»·', 'é‡‘é¢', 'é”€å”®é‡‘é¢', 'è®¢å•é‡‘é¢', 'å®ä»˜é‡‘é¢', 'æ”¯ä»˜é‡‘é¢', 'é€€æ¬¾å‰æ”¯ä»˜é‡‘é¢', 'åˆ†æ‘Šé‡‘é¢', 'åˆ†æ‘Šæ€»ä»·'],
        'å®å‘æ•°é‡': ['å®å‘æ•°é‡', 'æ•°é‡', 'é”€å”®æ•°é‡', 'è®¢å•æ•°é‡', 'å•†å“æ•°é‡', 'å‘è´§æ•°é‡', 'å®é™…æ•°é‡'],
        'åº—é“º': ['åº—é“º', 'åº—é“ºåç§°', 'åº—é“ºå', 'é”€å”®åº—é“º', 'æ¸ é“åº—é“º', 'é—¨åº—', 'å•†åº—'],
        'è´§å“åç§°': ['è´§å“åç§°', 'å•†å“åç§°', 'äº§å“åç§°', 'å“ç±»', 'å•†å“å“ç±»', 'äº§å“å“ç±»', 'å•†å“', 'äº§å“'],
        'è§„æ ¼åç§°': ['è§„æ ¼åç§°', 'å‹å·', 'å•†å“å‹å·', 'äº§å“å‹å·', 'è§„æ ¼', 'äº§å“è§„æ ¼', 'å•†å“è§„æ ¼'],
        'äº¤æ˜“æ—¶é—´': ['äº¤æ˜“æ—¶é—´', 'ä¸‹å•æ—¶é—´', 'è®¢å•æ—¶é—´', 'åˆ›å»ºæ—¶é—´', 'æ—¶é—´', 'æ—¥æœŸ', 'äº¤æ˜“æ—¥æœŸ', 'è®¢å•æ—¥æœŸ']
    }
    
    # æ£€æŸ¥å¹¶ä¿®æ­£åˆ—å
    fixed_columns = {}
    for target_col, possible_names in column_mappings.items():
        if target_col not in df.columns:
            found = False
            for possible_name in possible_names:
                if possible_name in df.columns:
                    print(f"   âœ… æ‰¾åˆ°åˆ—åæ˜ å°„: {possible_name} -> {target_col}")
                    fixed_columns[possible_name] = target_col
                    found = True
                    break
            if not found:
                print(f"   âŒ æœªæ‰¾åˆ°åˆ—å: {target_col}")
                print(f"      å¯èƒ½çš„åˆ—å: {possible_names}")
                print(f"      å®é™…åˆ—å: {list(df.columns)}")
        else:
            print(f"   âœ… åˆ—åå·²å­˜åœ¨: {target_col}")
    
    # æ‰§è¡Œåˆ—åé‡å‘½å
    if fixed_columns:
        df = df.rename(columns=fixed_columns)
        print(f"   ğŸ”„ å·²é‡å‘½ååˆ—: {fixed_columns}")
    
    return df

def check_required_columns(df):
    """æ£€æŸ¥å¿…éœ€çš„åˆ—æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨ç›´æ¥æŠ¥é”™é€€å‡º"""
    required_cols = [DATE_COL, AMOUNT_COL, QTY_COL, SHOP_COL, CATEGORY_COL, MODEL_COL]
    missing_cols = [col for col in required_cols if col not in df.columns]
    
    if missing_cols:
        error_msg = f"âŒ ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing_cols)}"
        print(error_msg)
        print(f"ğŸ“‹ å½“å‰æ–‡ä»¶åˆ—å: {list(df.columns)}")
        sys.exit(1)
    
    print(f"âœ… æ‰€æœ‰å¿…éœ€åˆ—å­˜åœ¨: {', '.join(required_cols)}")
    return True

def to_number(val):
    if pd.isnull(val):
        return 0
    val = str(val).replace('ï¼Œ', '').replace(',', '').replace(' ', '').replace('\u3000', '')
    try:
        return int(float(val))  # ç›´æ¥è¿”å›æ•´æ•°ï¼Œé¿å…å°æ•°ä½
    except:
        return 0

def is_online_shop(shop_name):
    """åˆ¤æ–­æ˜¯å¦ä¸ºçº¿ä¸Šåº—é“º"""
    if pd.isna(shop_name):
        return False
    
    shop_str = str(shop_name).lower()
    offline_keywords = [
        'çº¿ä¸‹', 'å®ä½“åº—', 'ä¸“æŸœ', 'é—¨åº—', 'å–åœº', 'å•†åœº', 'è¶…å¸‚', 
        'å›½ç¾', 'è‹å®', 'äº”æ˜Ÿ', 'å¤§ä¸­', 'æ°¸ä¹', 'è¿ªä¿¡é€š',
        'ä¸–çºªè”å', 'åæ¶¦ä¸‡å®¶', 'æ²ƒå°”ç›', 'å®¶ä¹ç¦', 'å¤§æ¶¦å‘',
        'çº¢æ˜Ÿç¾å‡¯é¾™', 'å±…ç„¶ä¹‹å®¶', 'æ¬§äºšè¾¾', 'é‡‘æµ·é©¬', 'æœˆæ˜Ÿ',
        'å·¥å‚åº—', 'åº“å­˜å¤„ç†', 'æ¸…ä»“', 'æ ·æœº', 'å±•ç¤ºæœº'
    ]
    
    return not any(keyword in shop_str for keyword in offline_keywords)

def check_server_availability():
    """æ£€æŸ¥WebæœåŠ¡å™¨æ˜¯å¦å¯ç”¨"""
    try:
        response = requests.get("http://127.0.0.1:5002/", timeout=5)
        return response.status_code == 200
    except:
        return False

def _send_single_message(message, target_user=None):
    """å‘é€å•æ¡æ¶ˆæ¯ï¼Œæ”¯æŒ5æ¬¡é‡è¯•å’Œå¤±è´¥webhooké€šçŸ¥"""
    url = "http://212.64.57.87:5001/send"
    token = "wecomchan_token"
    to_user = target_user if target_user else "weicungang"
    data = {
        "msg": message,
        "token": token,
        "to_user": to_user
    }
    
    max_retries = 5
    retry_delay = 3
    
    for attempt in range(max_retries):
        try:
            logger.info(f"ğŸ“¤ å°è¯•å‘é€æ¶ˆæ¯ç»™ç”¨æˆ· {to_user} (ç¬¬{attempt + 1}/{max_retries}æ¬¡)")
            response = requests.post(url, json=data, timeout=30)
            logger.info(f"ğŸ“¤ å‘é€ç»“æœ: {response.text[:100]}...")
            
            if "errcode" in response.text and "0" in response.text:
                logger.info(f"âœ… å‘é€æˆåŠŸ (å°è¯• {attempt + 1}/{max_retries})")
                return True
            elif "500" in response.text or "error" in response.text.lower():
                logger.warning(f"âš ï¸ æœåŠ¡å™¨é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries})")
                if attempt < max_retries - 1:
                    logger.info(f"â³ {retry_delay}ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
                    retry_delay *= 1.5
                    # å°è¯•ç¼©çŸ­å†…å®¹é‡è¯•
                    shorter_msg = message[:500]
                    data["msg"] = shorter_msg
                else:
                    logger.error(f"âŒ å‘é€å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡")
                    # å‘é€å¤±è´¥é€šçŸ¥åˆ°webhook
                    send_failure_webhook_notification(to_user, message, f"æœåŠ¡å™¨é”™è¯¯: {response.text}")
                    return False
            else:
                logger.warning(f"âš ï¸ å‘é€è¿”å›å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {response.text}")
                if attempt < max_retries - 1:
                    logger.info(f"â³ {retry_delay}ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
                    retry_delay *= 1.5
                else:
                    logger.error(f"âŒ å‘é€å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡")
                    # å‘é€å¤±è´¥é€šçŸ¥åˆ°webhook
                    send_failure_webhook_notification(to_user, message, f"å‘é€å¼‚å¸¸: {response.text}")
                    return False
        except requests.exceptions.ConnectTimeout:
            logger.error(f"âŒ è¿æ¥è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries})")
            if attempt < max_retries - 1:
                logger.info(f"â³ {retry_delay}ç§’åé‡è¯•...")
                time.sleep(retry_delay)
                retry_delay *= 1.5
            else:
                logger.error(f"âŒ å‘é€å¤±è´¥: è¿æ¥è¶…æ—¶ï¼Œå·²é‡è¯•{max_retries}æ¬¡")
                # å‘é€å¤±è´¥é€šçŸ¥åˆ°webhook
                send_failure_webhook_notification(to_user, message, "è¿æ¥è¶…æ—¶")
                return False
        except requests.exceptions.Timeout:
            logger.error(f"âŒ è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries})")
            if attempt < max_retries - 1:
                logger.info(f"â³ {retry_delay}ç§’åé‡è¯•...")
                time.sleep(retry_delay)
                retry_delay *= 1.5
            else:
                logger.error(f"âŒ å‘é€å¤±è´¥: è¯·æ±‚è¶…æ—¶ï¼Œå·²é‡è¯•{max_retries}æ¬¡")
                # å‘é€å¤±è´¥é€šçŸ¥åˆ°webhook
                send_failure_webhook_notification(to_user, message, "è¯·æ±‚è¶…æ—¶")
                return False
        except Exception as e:
            logger.error(f"âŒ å‘é€å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                logger.info(f"â³ {retry_delay}ç§’åé‡è¯•...")
                time.sleep(retry_delay)
                retry_delay *= 1.5
            else:
                logger.error(f"âŒ å‘é€å¤±è´¥: {e}ï¼Œå·²é‡è¯•{max_retries}æ¬¡")
                # å‘é€å¤±è´¥é€šçŸ¥åˆ°webhook
                send_failure_webhook_notification(to_user, message, f"å‘é€å¼‚å¸¸: {str(e)}")
                return False
    return False

def send_failure_webhook_notification(target_user, message_content, error_details):
    """å‘é€å¤±è´¥é€šçŸ¥åˆ°webhook"""
    webhook_url = "https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=02d1441f-aa5b-44cb-aeab-b934fe78f8cb"
    
    failure_msg = f"""ğŸš¨ å¤šäº‹ä¸šéƒ¨æœˆæŠ¥æ•°æ®å‘é€å¤±è´¥é€šçŸ¥

ğŸ“‹ å¤±è´¥è¯¦æƒ…:
â€¢ ç›®æ ‡ç”¨æˆ·: {target_user}
â€¢ å¤±è´¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
â€¢ é”™è¯¯åŸå› : {error_details}
â€¢ æ¶ˆæ¯é•¿åº¦: {len(message_content)} å­—ç¬¦

ğŸ“ æ¶ˆæ¯å†…å®¹é¢„è§ˆ:
{message_content[:200]}{'...' if len(message_content) > 200 else ''}

è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒæœåŠ¡å™¨çŠ¶æ€ã€‚"""
    
    try:
        webhook_data = {
            "msgtype": "text",
            "text": {
                "content": failure_msg
            }
        }
        
        logger.info(f"ğŸ“¤ å‘é€å¤±è´¥é€šçŸ¥åˆ°webhook: {webhook_url}")
        response = requests.post(webhook_url, json=webhook_data, timeout=10)
        
        if response.status_code == 200:
            result = response.json()
            if result.get('errcode') == 0:
                logger.info("âœ… å¤±è´¥é€šçŸ¥å‘é€æˆåŠŸ")
            else:
                logger.error(f"âŒ å¤±è´¥é€šçŸ¥å‘é€å¤±è´¥: {result}")
        else:
            logger.error(f"âŒ å¤±è´¥é€šçŸ¥HTTPé”™è¯¯: {response.status_code}")
            
    except Exception as e:
        logger.error(f"âŒ å‘é€å¤±è´¥é€šçŸ¥å¼‚å¸¸: {e}")

def send_wecomchan_segment(content, target_users=None):
    """åˆ†æ®µå‘é€ï¼Œç¡®ä¿é“¾æ¥ä¼˜å…ˆå‘é€ï¼Œæ”¯æŒå¤šç”¨æˆ·å‘é€å’Œå»é‡"""
    max_chars = 1500  # ä¿®æ­£å­—ç¬¦é™åˆ¶ä¸º1500
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šç›®æ ‡ç”¨æˆ·ï¼Œä½¿ç”¨é»˜è®¤ç”¨æˆ·
    if target_users is None:
        target_users = [to_user]
    
    # ç¡®ä¿ç”¨æˆ·åˆ—è¡¨å»é‡
    target_users = list(set(target_users))
    
    logger.info(f"ğŸ“¤ å‡†å¤‡å‘é€ç»™ {len(target_users)} ä¸ªç”¨æˆ·: {', '.join(target_users)}")
    
    # ä¸ºæ¯ä¸ªç”¨æˆ·å‘é€æ¶ˆæ¯
    success_count = 0
    for user in target_users:
        logger.info(f"ğŸ“¤ æ­£åœ¨å‘é€ç»™ç”¨æˆ·: {user}")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é“¾æ¥
        link_pattern = r'ğŸŒ æŸ¥çœ‹å®Œæ•´Webé¡µé¢: (https://[^\s]+)'
        import re
        link_match = re.search(link_pattern, content)
        
        if link_match:
            link = link_match.group(1)
            link_text = f"ğŸŒ æŸ¥çœ‹å®Œæ•´Webé¡µé¢: {link}"
            content_without_link = content.replace(link_text, "").strip()
            
            # å¦‚æœå†…å®¹é•¿åº¦è¶…è¿‡é™åˆ¶ï¼Œä¼˜å…ˆä¿è¯é“¾æ¥å‘é€
            if len(content_without_link) + len(link_text) > max_chars:
                # æˆªæ–­ä¸»å†…å®¹ï¼Œä¿ç•™é“¾æ¥
                available_chars = max_chars - len(link_text) - 10  # ç•™ä¸€äº›ç¼“å†²
                truncated_content = content_without_link[:available_chars].rstrip('\n')
                final_content = truncated_content + f"\n{link_text}"
                logger.warning(f"âš ï¸ å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­è‡³ {len(final_content)} å­—ç¬¦")
            else:
                final_content = content
        else:
            # æ²¡æœ‰é“¾æ¥ï¼Œç›´æ¥æˆªæ–­
            if len(content) > max_chars:
                final_content = content[:max_chars].rstrip('\n')
                logger.warning(f"âš ï¸ å†…å®¹è¿‡é•¿ä¸”æ— é“¾æ¥ï¼Œå·²æˆªæ–­è‡³ {len(final_content)} å­—ç¬¦")
            else:
                final_content = content
        
        # å‘é€æ¶ˆæ¯
        success = _send_single_message(final_content, user)
        if success:
            success_count += 1
            logger.info(f"âœ… å‘é€æˆåŠŸç»™ç”¨æˆ·: {user}")
        else:
            logger.error(f"âŒ å‘é€å¤±è´¥ç»™ç”¨æˆ·: {user}")
        
        # ç”¨æˆ·é—´å‘é€é—´éš”
        time.sleep(1)
    
    logger.info(f"ğŸ“Š å‘é€å®Œæˆ: {success_count}/{len(target_users)} æˆåŠŸ")
    return success_count == len(target_users)

def to_pinyin(s):
    mapping = {
        'ç©ºè°ƒäº‹ä¸šéƒ¨': 'kongtiaoshiyebu',
        'åˆ¶å†·äº‹ä¸šéƒ¨': 'zhilingshiyebu',
        'æ´—æŠ¤äº‹ä¸šéƒ¨': 'xihushiyebu',
        'æ°´è”ç½‘äº‹ä¸šéƒ¨': 'shuilianwangshiyebu',
        'å¨ç”µæ´—ç¢—æœºäº‹ä¸šéƒ¨': 'chudianxiwangjishiyebu',
        'å¡è¨å¸æ¸ é“': 'kasadiqudao',
        'å¤©çŒ«æ¸ é“': 'tianmaoqudao',
        'äº¬ä¸œæ¸ é“': 'jingdongqudao',
        'æ‹¼å¤šå¤šæ¸ é“': 'pinduoduoqudao',
        'æŠ–éŸ³æ¸ é“': 'douyinqudao'
    }
    if s in mapping:
        return mapping[s]
    import unicodedata
    import re
    s_ascii = unicodedata.normalize('NFKD', s).encode('ascii', 'ignore').decode('ascii')
    s_ascii = re.sub(r'[^a-zA-Z0-9_]', '', s_ascii)
    return s_ascii.lower() or 'report'

def generate_html_content(title_cn, content_text):
    """ç»Ÿä¸€çš„HTMLç”Ÿæˆå‡½æ•°ï¼Œç¡®ä¿æ‰€æœ‰æŠ¥å‘Šä½¿ç”¨ç›¸åŒçš„æ ¼å¼"""
    html_content = f'''<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
    <title>{title_cn}</title>
    <style>
        body {{ font-family: 'Microsoft YaHei', 'å¾®è½¯é›…é»‘', Arial, sans-serif; background: #f8f9fa; color: #222; margin: 0; padding: 0.5em; max-width: 900px; margin-left:auto; margin-right:auto; text-align: left; font-size: 10.5pt; }}
        h1, h2, h3 {{ color: #0056b3; text-align: left; font-family: 'Microsoft YaHei', 'å¾®è½¯é›…é»‘', Arial, sans-serif; font-size: 14pt; font-weight: bold; margin: 0.3em 0; }}
        pre, code {{ background: #f3f3f3; padding: 0.5em; border-radius: 4px; white-space: pre-wrap; word-break: break-all; text-align: left; font-family: 'Microsoft YaHei', 'å¾®è½¯é›…é»‘', Arial, sans-serif; margin: 0.3em 0; }}
        .growth-positive {{ background-color: #e6f4ea !important; }}
        .growth-negative {{ background-color: #fbeaea !important; }}
        .section {{ margin-bottom: 2em; text-align: left; }}
        .highlight {{ color: #d63384; font-weight: bold; }}
        .emoji {{ font-size: 1.2em; }}
        @media (max-width: 600px) {{
            body {{ padding: 0.5em; font-size: 10.5pt; }}
            h1 {{ font-size: 14pt; }}
        }}
        .left-align {{ text-align: left !important; }}
    </style>
</head>
<body>
    <h1>{title_cn}</h1>
    <div class="section left-align">
        <pre>
{content_text}
        </pre>
    </div>
    <footer style="margin-top:2em;color:#888;font-size:0.9em;">è‡ªåŠ¨ç”Ÿæˆ | Powered by EdgeOne Pages & ä¼ä¸šå¾®ä¿¡æœºå™¨äºº</footer>
</body>
</html>'''
    return html_content

def classify_channel(shop_name):
    """æ¸ é“å½’ç±»å‡½æ•° - æ·˜å®åˆå¹¶åˆ°å¤©çŒ«æ¸ é“"""
    if not isinstance(shop_name, str):
        return "å…¶ä»–"
    
    shop_name_lower = shop_name.lower()
    
    # å¡è¨å¸ä¼˜å…ˆ
    if 'å¡è¨å¸' in shop_name_lower or 'å°çº¢ä¹¦' in shop_name_lower:
        return "å¡è¨å¸æ¸ é“"
    if 'äº¬ä¸œ' in shop_name_lower:
        return "äº¬ä¸œæ¸ é“"
    if 'å¤©çŒ«' in shop_name_lower or 'æ·˜å®' in shop_name_lower:  # æ·˜å®åˆå¹¶åˆ°å¤©çŒ«
        return "å¤©çŒ«æ¸ é“"
    if 'æ‹¼å¤šå¤š' in shop_name_lower:
        return "æ‹¼å¤šå¤šæ¸ é“"
    if 'æŠ–éŸ³' in shop_name_lower or 'å¿«æ‰‹' in shop_name_lower:
        return "æŠ–éŸ³æ¸ é“"
    return "å…¶ä»–"


# ========== WebæŠ¥å‘Šä¿å­˜å‡½æ•°ï¼Œå‚è€ƒæ—¥æŠ¥é€»è¾‘ ==========
def save_report_to_local(content, report_id_prefix):
    os.makedirs("reports", exist_ok=True)
    filename = f"reports/{report_id_prefix}_{report_date}.html"
    # ç›´æ¥ä¿å­˜å†…å®¹ï¼Œä¸å†æ·»åŠ é¢å¤–çš„HTMLåŒ…è£…
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"âœ… æŠ¥è¡¨å·²ä¿å­˜: {filename}")
    return os.path.basename(filename)

def _simple_verify_url(public_url):
    """ä¸¥æ ¼éªŒè¯URLæ˜¯å¦å¯è®¿é—®"""
    print(f"ğŸ” æ­£åœ¨éªŒè¯URL: {public_url}")
    
    # ç­‰å¾…CDNåŒæ­¥ï¼Œæœ€å¤šé‡è¯•5æ¬¡
    for attempt in range(5):
        try:
            time.sleep(3)  # ç­‰å¾…CDNåŒæ­¥
            response = requests.head(public_url, timeout=15)
            
            if response.status_code == 200:
                print(f"âœ… URLéªŒè¯æˆåŠŸï¼Œæ–‡ä»¶å¯æ­£å¸¸è®¿é—®: {public_url}")
                return public_url
            elif response.status_code == 404:
                print(f"âš ï¸ ç¬¬{attempt+1}æ¬¡éªŒè¯å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨ (404)ï¼Œç­‰å¾…CDNåŒæ­¥...")
            else:
                print(f"âš ï¸ ç¬¬{attempt+1}æ¬¡éªŒè¯å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                
        except Exception as verify_e:
            print(f"âš ï¸ ç¬¬{attempt+1}æ¬¡éªŒè¯å¼‚å¸¸: {verify_e}")
    
    print(f"âŒ URLéªŒè¯å¤±è´¥ï¼Œç»è¿‡5æ¬¡é‡è¯•ä»æ— æ³•è®¿é—®ï¼Œä¸è¿”å›URL")
    return None
