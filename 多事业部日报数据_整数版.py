#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šäº‹ä¸šéƒ¨æ—¥æŠ¥è‡ªåŠ¨åŒ–ä¸»æµç¨‹ - æ•´æ•°æ•°æ®ç‰ˆæœ¬
- äº”å¤§äº‹ä¸šéƒ¨ã€äº”å¤§æ¸ é“ç‹¬ç«‹åˆ†ç»„
- æ•°æ®è¿‡æ»¤ï¼ˆåˆ·å•ã€è®¢å•çŠ¶æ€ã€çº¿ä¸Šåº—é“ºã€äº”å¤§æ¸ é“ï¼‰
- æŠ¥è¡¨ç”Ÿæˆã€webå‘å¸ƒã€å¾®ä¿¡æ¨é€
- æ‰€æœ‰æ•°æ®ä¿æŒæ•´æ•°ï¼Œæ— å°æ•°ç‚¹
"""

import os
import sys
import glob
import pandas as pd
import requests
from datetime import datetime, timedelta
import time
import traceback
import re
import unicodedata
import subprocess
import pymysql
import logging
import platform

# ========== æ—¥å¿—é…ç½® ==========
def setup_logging():
    """è®¾ç½®æ—¥å¿—è®°å½•"""
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    
    log_filename = f"logs/å¤šäº‹ä¸šéƒ¨æ—¥æŠ¥æ•°æ®_æ•´æ•°ç‰ˆ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    return logging.getLogger(__name__)

logger = setup_logging()

# ========== é…ç½®åŒº ==========
# æ•°æ®åº“é…ç½®
DB_HOST = "212.64.57.87"
DB_PORT = 3306
DB_USER = "root"
DB_PASSWORD = "c973ee9b500cc638"
DB_NAME = "Date"
DB_CHARSET = "utf8mb4"

WECHAT_API = "http://212.64.57.87:5001/send"
WECHAT_TOKEN = "wecomchan_token"
WECHAT_USER = "weicungang"
REPORTS_DIR = "reports"

# å›ºå®šæ”¶ä»¶äºº
always_users = ["weicungang"]

# äº‹ä¸šéƒ¨é…ç½®
business_groups = {
    "ç©ºè°ƒäº‹ä¸šéƒ¨": {"keywords": ["ç©ºè°ƒ"], "users": ["weicungang"]},
    "åˆ¶å†·äº‹ä¸šéƒ¨": {"keywords": ["å†°ç®±","å†·æŸœ"], "users": ["weicungang"]},
    "æ´—æŠ¤äº‹ä¸šéƒ¨": {"keywords": ["æ´—è¡£æœº"], "users": ["weicungang"]},
    "æ°´è”ç½‘äº‹ä¸šéƒ¨": {"keywords": ["çƒ­æ°´å™¨", "å‡€æ°´", "é‡‡æš–", "ç”µçƒ­æ°´å™¨", "ç‡ƒæ°”çƒ­æ°´å™¨", "å¤šèƒ½æºçƒ­æ°´å™¨"], "users": ["weicungang"]},
    "å¨ç”µæ´—ç¢—æœºäº‹ä¸šéƒ¨": {"keywords": ["å¨ç”µ", "æ´—ç¢—æœº"], "users": ["weicungang"]}
}

# æ¸ é“åˆ†ç»„é…ç½®
CHANNEL_GROUPS = {
    "å¡è¨å¸æ¸ é“": {"keywords": ["å¡è¨å¸", "å°çº¢ä¹¦"], "users": ["weicungang"]},
    "å¤©çŒ«æ¸ é“": {"keywords": ["å¤©çŒ«", "æ·˜å®"], "users": ["weicungang"]},
    "äº¬ä¸œæ¸ é“": {"keywords": ["äº¬ä¸œ"], "users": ["weicungang"]},
    "æ‹¼å¤šå¤šæ¸ é“": {"keywords": ["æ‹¼å¤šå¤š"], "users": ["weicungang"]},
    "æŠ–éŸ³æ¸ é“": {"keywords": ["æŠ–éŸ³", "å¿«æ‰‹"], "users": ["weicungang"]}
}

# å›ºå®šåˆ—å
DATE_COL = 'äº¤æ˜“æ—¶é—´'
AMOUNT_COL = 'åˆ†æ‘Šåæ€»ä»·'
QTY_COL = 'å®å‘æ•°é‡'
SHOP_COL = 'åº—é“º'
CATEGORY_COL = 'è´§å“åç§°'
MODEL_COL = 'è§„æ ¼åç§°'

# ========== å·¥å…·å‡½æ•° ==========
def check_required_columns(df):
    required_cols = [DATE_COL, AMOUNT_COL, QTY_COL, SHOP_COL, CATEGORY_COL, MODEL_COL]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        print(f"âŒ ç¼ºå°‘å¿…è¦çš„åˆ—: {missing}")
        print(f"å½“å‰åˆ—: {list(df.columns)}")
        sys.exit(1)

def to_integer(val):
    """ç¡®ä¿æ‰€æœ‰æ•°å€¼è½¬æ¢ä¸ºæ•´æ•°"""
    if pd.isnull(val):
        return 0
    val = str(val).replace('ï¼Œ', '').replace(',', '').replace(' ', '').replace('\u3000', '')
    try:
        return int(float(val))
    except:
        return 0

def calculate_ratio_int(current, previous):
    """è®¡ç®—ç¯æ¯”ï¼Œè¿”å›æ•´æ•°ç™¾åˆ†æ¯”"""
    if previous == 0:
        return "+100%" if current > 0 else "0%"
    ratio = int(((current - previous) / previous) * 100)
    if ratio > 0:
        return f"+{ratio}%"
    elif ratio < 0:
        return f"{ratio}%"
    else:
        return "0%"

def is_online_shop(shop_name):
    if not isinstance(shop_name, str):
        return False
    online_keywords = ['äº¬ä¸œ','å¤©çŒ«','æ‹¼å¤šå¤š','æŠ–éŸ³','å¡è¨å¸','å°çº¢ä¹¦','æ·˜å®','è‹å®','å›½ç¾']
    return any(kw in shop_name for kw in online_keywords)

def get_target_users(group_name, group_type):
    """æ ¹æ®åˆ†ç»„åç§°å’Œç±»å‹è·å–ç›®æ ‡ç”¨æˆ·"""
    users = set(always_users)
    
    if group_type == 'business':
        for dept, conf in business_groups.items():
            if dept == group_name:
                users.update(conf["users"])
                break
    else:
        for channel, conf in CHANNEL_GROUPS.items():
            if channel == group_name:
                users.update(conf["users"])
                break
    
    return list(set(users))

def _send_single_message(msg, target_user=None):
    """å‘é€å•æ¡æ¶ˆæ¯"""
    to_user = target_user if target_user else WECHAT_USER
    data = {"msg": msg, "token": WECHAT_TOKEN, "to_user": to_user}
    
    max_retries = 3
    retry_delay = 2
    
    for attempt in range(max_retries):
        try:
            resp = requests.post(WECHAT_API, json=data, timeout=15)
            if "errcode" in resp.text and "0" in resp.text:
                return True
            else:
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
        except:
            if attempt < max_retries - 1:
                time.sleep(retry_delay)
    return False

def send_wecomchan_segment(content, target_users=None):
    """åˆ†æ®µå‘é€æ¶ˆæ¯"""
    max_chars = 1500
    
    if target_users is None:
        target_users = [WECHAT_USER]
    
    target_users = list(set(target_users))
    
    for user in target_users:
        link_pattern = r'ğŸŒ æŸ¥çœ‹å®Œæ•´Webé¡µé¢: (https://[^\s]+)'
        link_match = re.search(link_pattern, content)
        
        if link_match:
            link = link_match.group(1)
            link_text = f"ğŸŒ æŸ¥çœ‹å®Œæ•´Webé¡µé¢: {link}"
            content_without_link = content.replace(link_text, "").strip()
            
            if len(content_without_link) + len(link_text) > max_chars:
                available_chars = max_chars - len(link_text) - 10
                truncated_content = content_without_link[:available_chars].rstrip('\n')
                final_content = truncated_content + f"\n{link_text}"
            else:
                final_content = content
        else:
            if len(content) > max_chars:
                final_content = content[:max_chars].rstrip('\n')
            else:
                final_content = content
        
        _send_single_message(final_content, user)
        time.sleep(1)

def to_pinyin(s):
    mapping = {
        'ç©ºè°ƒäº‹ä¸šéƒ¨': 'kongtiaoshiyebu',
        'åˆ¶å†·äº‹ä¸šéƒ¨': 'zhilingshiyebu',
        'æ´—æŠ¤äº‹ä¸šéƒ¨': 'xihushiyebu',
        'æ°´è”ç½‘äº‹ä¸šéƒ¨': 'shuilianwangshiyebu',
        'å¨ç”µæ´—ç¢—æœºäº‹ä¸šéƒ¨': 'chudianxiwangjishiyebu',
        'å¡è¨å¸æ¸ é“': 'kasadiqudao',
        'å¤©çŒ«æ¸ é“': 'tianmaoqudao',
        'äº¬ä¸œæ¸ é“': 'jingdongqudao',
        'æ‹¼å¤šå¤šæ¸ é“': 'pinduoduoqudao',
        'æŠ–éŸ³æ¸ é“': 'douyinqudao'
    }
    if s in mapping:
        return mapping[s]
    s_ascii = unicodedata.normalize('NFKD', s).encode('ascii', 'ignore').decode('ascii')
    s_ascii = re.sub(r'[^a-zA-Z0-9_]', '', s_ascii)
    return s_ascii.lower() or 'report'

def generate_html_content(title_cn, content_text):
    """ç»Ÿä¸€çš„HTMLç”Ÿæˆå‡½æ•°"""
    html_content = f'''<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
    <title>{title_cn}</title>
    <style>
        body {{ font-family: 'Microsoft YaHei', 'å¾®è½¯é›…é»‘', Arial, sans-serif; background: #f8f9fa; color: #222; margin: 0; padding: 0.5em; max-width: 900px; margin-left:auto; margin-right:auto; text-align: left; font-size: 10.5pt; }}
        h1, h2, h3 {{ color: #0056b3; text-align: left; font-family: 'Microsoft YaHei', 'å¾®è½¯é›…é»‘', Arial, sans-serif; font-size: 14pt; font-weight: bold; margin: 0.3em 0; }}
        pre, code {{ background: #f3f3f3; padding: 0.5em; border-radius: 4px; white-space: pre-wrap; word-break: break-all; text-align: left; font-family: 'Microsoft YaHei', 'å¾®è½¯é›…é»‘', Arial, sans-serif; margin: 0.3em 0; }}
        .growth-positive {{ background-color: #e6f4ea !important; }}
        .growth-negative {{ background-color: #fbeaea !important; }}
        .section {{ margin-bottom: 2em; text-align: left; }}
        .highlight {{ color: #d63384; font-weight: bold; }}
        .emoji {{ font-size: 1.2em; }}
        @media (max-width: 600px) {{
            body {{ padding: 0.5em; font-size: 10.5pt; }}
            h1 {{ font-size: 14pt; }}
        }}
        .left-align {{ text-align: left !important; }}
    </style>
</head>
<body>
    <h1>{title_cn}</h1>
    <div class="section left-align">
        <pre>
{content_text}
        </pre>
    </div>
    <footer style="margin-top:2em;color:#888;font-size:0.9em;">è‡ªåŠ¨ç”Ÿæˆ | Powered by EdgeOne Pages & ä¼ä¸šå¾®ä¿¡æœºå™¨äºº</footer>
</body>
</html>'''
    return html_content

# ========== æ•°æ®è·å– ==========
def get_erp_data(report_date):
    """ä»æ•°æ®åº“è·å–ERPæ•°æ®"""
    try:
        conn = pymysql.connect(
            host=DB_HOST, port=DB_PORT, user=DB_USER, 
            password=DB_PASSWORD, database=DB_NAME, charset=DB_CHARSET,
            connect_timeout=10
        )
        df = pd.read_sql(f"SELECT * FROM Daysales WHERE äº¤æ˜“æ—¶é—´ LIKE '{report_date}%'", conn)
        conn.close()
        return df
    except Exception as e:
        logger.error(f"âŒ ä»æ•°æ®åº“è·å–ERPæ•°æ®å¤±è´¥: {e}")
        return None

def get_prev_data(prev_date):
    """ä»æ•°æ®åº“è·å–åŒæœŸæ•°æ®"""
    try:
        conn = pymysql.connect(
            host=DB_HOST, port=DB_PORT, user=DB_USER, 
            password=DB_PASSWORD, database=DB_NAME, charset=DB_CHARSET,
            connect_timeout=10
        )
        df = pd.read_sql(f"SELECT * FROM Daysales WHERE äº¤æ˜“æ—¶é—´ LIKE '{prev_date}%'", conn)
        conn.close()
        return df
    except Exception as e:
        logger.error(f"âŒ ä»æ•°æ®åº“è·å–åŒæœŸæ•°æ®å¤±è´¥: {e}")
        return None

def get_fenxiao_data(report_date):
    """ä»HT_fenxiaoè¡¨è·å–åˆ†é”€æ•°æ®"""
    try:
        conn = pymysql.connect(
            host=DB_HOST, port=DB_PORT, user=DB_USER, 
            password=DB_PASSWORD, database=DB_NAME, charset=DB_CHARSET,
            connect_timeout=10
        )
        
        cursor = conn.cursor()
        cursor.execute("DESCRIBE HT_fenxiao")
        columns = [row[0] for row in cursor.fetchall()]
        
        amount_fields = [col for col in columns if 'é‡‘é¢' in col or 'å®ä»˜' in col or 'æ”¯ä»˜' in col]
        shop_fields = [col for col in columns if 'åº—é“º' in col or 'å•†åº—' in col]
        status_fields = [col for col in columns if 'çŠ¶æ€' in col or 'è®¢å•' in col]
        time_fields = [col for col in columns if 'æ—¶é—´' in col or 'æ”¯ä»˜' in col]
        product_fields = [col for col in columns if 'äº§å“' in col or 'åç§°' in col]
        qty_fields = [col for col in columns if 'æ•°é‡' in col or 'é‡‡è´­æ•°é‡' in col]
        
        amount_col = 'ç”¨æˆ·å®é™…æ”¯ä»˜æ€»é¢' if 'ç”¨æˆ·å®é™…æ”¯ä»˜æ€»é¢' in columns else (amount_fields[0] if amount_fields else 'ç”¨æˆ·å®é™…æ”¯ä»˜é‡‘é¢')
        shop_col = 'åˆ†é”€å•†åº—é“ºåç§°' if 'åˆ†é”€å•†åº—é“ºåç§°' in columns else (shop_fields[0] if shop_fields else 'åˆ†é”€å•†åº—é“ºåç§°')
        status_col = 'è®¢å•çŠ¶æ€' if 'è®¢å•çŠ¶æ€' in columns else (status_fields[0] if status_fields else 'è®¢å•çŠ¶æ€')
        time_col = 'é‡‡è´­å•æ”¯ä»˜æ—¶é—´' if 'é‡‡è´­å•æ”¯ä»˜æ—¶é—´' in columns else (time_fields[0] if time_fields else 'é‡‡è´­å•æ”¯ä»˜æ—¶é—´')
        product_col = 'äº§å“åç§°' if 'äº§å“åç§°' in columns else (product_fields[0] if product_fields else 'äº§å“åç§°')
        qty_col = 'é‡‡è´­æ•°é‡' if 'é‡‡è´­æ•°é‡' in columns else (qty_fields[0] if qty_fields else 'é‡‡è´­æ•°é‡')
        
        sql = f"""
        SELECT 
            {shop_col} as åº—é“º,
            {status_col} as è®¢å•çŠ¶æ€,
            {amount_col} as åˆ†æ‘Šåæ€»ä»·,
            {time_col} as äº¤æ˜“æ—¶é—´,
            {product_col} as è§„æ ¼åç§°,
            {product_col} as è´§å“åç§°,
            {qty_col} as å®å‘æ•°é‡,
            'åˆ†é”€' as æ•°æ®æ¥æº
        FROM HT_fenxiao 
        WHERE {time_col} LIKE '{report_date}%'
        AND {status_col} NOT IN ('å·²å–æ¶ˆ', 'æœªä»˜æ¬¾', 'å·²é€€è´§')
        """
        
        df_fenxiao = pd.read_sql(sql, conn)
        
        if not df_fenxiao.empty:
            # ä¼˜åŒ–äº§å“åŒ¹é…é€»è¾‘ï¼šæ‰¹é‡å¤„ç†é¿å…é‡å¤æŸ¥è¯¢
            logger.info("ğŸ”„ ä¼˜åŒ–äº§å“åŒ¹é…é€»è¾‘...")
            
            # è·å–æ‰€æœ‰å”¯ä¸€çš„äº§å“åç§°
            unique_products = df_fenxiao['è§„æ ¼åç§°'].dropna().unique()
            logger.info(f"ğŸ“Š éœ€è¦åŒ¹é…çš„å”¯ä¸€äº§å“æ•°é‡: {len(unique_products)}")
            
            # æ„å»ºæœ€ç»ˆçš„äº§å“æ˜ å°„ç¼“å­˜
            final_product_mapping = {}
            
            # æ‰¹é‡æŸ¥è¯¢fenxiaochanpinè¡¨
            if len(unique_products) > 0:
                placeholders = ','.join(['%s'] * len(unique_products))
                batch_sql = f"SELECT äº§å“åç§°, è§„æ ¼åç§°, è´§å“åç§° FROM fenxiaochanpin WHERE äº§å“åç§° IN ({placeholders})"
                cursor.execute(batch_sql, tuple(unique_products))
                fenxiao_results = cursor.fetchall()
                
                # æ„å»ºfenxiaochanpinæ˜ å°„
                fenxiao_mapping = {}
                for product_name, model_name, goods_name in fenxiao_results:
                    fenxiao_mapping[product_name] = (model_name, goods_name)
                
                logger.info(f"ğŸ“Š fenxiaochanpinè¡¨åŒ¹é…åˆ° {len(fenxiao_mapping)} ä¸ªäº§å“")
                
                # å¤„ç†æ¯ä¸ªå”¯ä¸€äº§å“
                for product_name in unique_products:
                    if not isinstance(product_name, str):
                        continue
                        
                    if product_name in fenxiao_mapping:
                        matched_model_name, matched_product_name = fenxiao_mapping[product_name]
                        
                        # å¦‚æœè´§å“åç§°ä¸ºç©ºï¼Œä»ERPæ•°æ®æŸ¥è¯¢
                        if matched_product_name is None or matched_product_name == '':
                            erp_sql = "SELECT è´§å“åç§° FROM Daysales WHERE è§„æ ¼åç§° = %s AND è´§å“åç§° IS NOT NULL AND è´§å“åç§° != '' LIMIT 1"
                            cursor.execute(erp_sql, (matched_model_name,))
                            erp_result = cursor.fetchone()
                            if erp_result:
                                matched_product_name = erp_result[0]
                                logger.info(f"   âœ… ä»ERPæ•°æ®åŒ¹é…è´§å“åç§°: {matched_model_name} -> {matched_product_name}")
                            else:
                                # å…³é”®è¯åŒ¹é…
                                import re
                                keywords = []
                                model_patterns = re.findall(r'[A-Z0-9]{3,}', product_name.upper())
                                keywords.extend(model_patterns)
                                chinese_words = re.findall(r'[\u4e00-\u9fff]+', product_name)
                                for word in chinese_words:
                                    if len(word) >= 2 and word not in ['å¤§å®¹é‡', 'å®¶ç”¨', 'ç‹¬ç«‹å¼', 'å˜é¢‘', 'è¶…ä¸€çº§', 'æ°´æ•ˆ', 'å‡çº§æ¬¾', 'å°±è¿‘ä»“', 'æ–°å“ä¸Šå¸‚', 'è¶…å¤§å®¹é‡']:
                                        keywords.append(word)
                                
                                matched_by_keyword = False
                                for keyword in keywords[:3]:
                                    keyword_sql = "SELECT è´§å“åç§° FROM Daysales WHERE è´§å“åç§° LIKE %s AND è´§å“åç§° IS NOT NULL AND è´§å“åç§° != '' LIMIT 1"
                                    cursor.execute(keyword_sql, (f'%{keyword}%',))
                                    keyword_result = cursor.fetchone()
                                    if keyword_result:
                                        matched_product_name = keyword_result[0]
                                        logger.info(f"   âœ… é€šè¿‡å…³é”®è¯'{keyword}'åŒ¹é…åˆ°è´§å“åç§°: {matched_product_name}")
                                        matched_by_keyword = True
                                        break
                                
                                if not matched_by_keyword:
                                    matched_product_name = force_categorize_product(product_name)
                                    logger.info(f"   âš ï¸ æ‰€æœ‰åŒ¹é…æ–¹å¼éƒ½å¤±è´¥ï¼Œå¼ºåˆ¶åŒ¹é…åˆ°å“ç±»: {product_name} -> {matched_product_name}")
                        
                        final_product_mapping[product_name] = {
                            'è§„æ ¼åç§°': matched_model_name,
                            'è´§å“åç§°': matched_product_name
                        }
                        logger.info(f"   âœ… åŒ¹é…æˆåŠŸ: {product_name} -> è§„æ ¼åç§°:{matched_model_name}, è´§å“åç§°:{matched_product_name}")
                    else:
                        logger.info(f"   âš ï¸ æœªåŒ¹é…åˆ°: {product_name}ï¼Œä½¿ç”¨åŸäº§å“åç§°")
                        final_product_mapping[product_name] = {
                            'è§„æ ¼åç§°': product_name,
                            'è´§å“åç§°': product_name
                        }
            
            # æ‰¹é‡åº”ç”¨æ˜ å°„ç»“æœ
            logger.info("ğŸ”„ æ‰¹é‡åº”ç”¨äº§å“æ˜ å°„ç»“æœ...")
            for index, row in df_fenxiao.iterrows():
                product_name = row['è§„æ ¼åç§°']
                if isinstance(product_name, str) and product_name in final_product_mapping:
                    mapping = final_product_mapping[product_name]
                    df_fenxiao.at[index, 'è§„æ ¼åç§°'] = mapping['è§„æ ¼åç§°']
                    df_fenxiao.at[index, 'è´§å“åç§°'] = mapping['è´§å“åç§°']
            
            df_fenxiao['å“ç±»'] = df_fenxiao['è´§å“åç§°'].apply(lambda x: "å…¶ä»–" if not isinstance(x, str) else x)
            
            def add_jingdong_prefix(shop_name):
                if not isinstance(shop_name, str):
                    return shop_name
                # å¦‚æœå·²ç»æœ‰"äº¬ä¸œ-"å‰ç¼€ï¼Œç›´æ¥è¿”å›
                if shop_name.startswith('äº¬ä¸œ-'):
                    return shop_name
                # ç»Ÿä¸€æ·»åŠ "äº¬ä¸œ-"å‰ç¼€
                return f"äº¬ä¸œ-{shop_name}"
            
            df_fenxiao['åº—é“º'] = df_fenxiao['åº—é“º'].apply(add_jingdong_prefix)
            
        conn.close()
        return df_fenxiao
    except Exception as e:
        logger.error(f"âŒ è·å–åˆ†é”€æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

def categorize_product(product_name):
    """ä»äº§å“åç§°ä¸­è¯†åˆ«å“ç±»"""
    if not isinstance(product_name, str):
        return "å…¶ä»–"
    
    product_name_lower = product_name.lower()
    category_keywords = {
        "å®¶ç”¨ç©ºè°ƒ": ["ç©ºè°ƒ", "æŒ‚æœº", "æŸœæœº", "ä¸­å¤®ç©ºè°ƒ", "åˆ†ä½“å¼"],
        "å•†ç”¨ç©ºè°ƒ": ["å•†ç”¨", "å•†ç”¨ç©ºè°ƒ", "å¤šè”æœº", "é£ç®¡æœº"],
        "å†°ç®±": ["å†°ç®±", "å†·æŸœ", "å†°æŸœ", "å†·è—", "å†·å†»"],
        "æ´—è¡£æœº": ["æ´—è¡£æœº", "æ´—çƒ˜ä¸€ä½“", "æ»šç­’", "æ³¢è½®"],
        "æ´—ç¢—æœº": ["æ´—ç¢—æœº", "æ´—ç¢—", "æ´—ç¢Ÿæœº"],  # æ´—ç¢—æœºç‹¬ç«‹ä¸ºä¸€ä¸ªå“ç±»
        "çƒ­æ°´å™¨": ["çƒ­æ°´å™¨", "ç”µçƒ­æ°´å™¨", "ç‡ƒæ°”çƒ­æ°´å™¨", "å¤šèƒ½æºçƒ­æ°´å™¨"],
        "å‡€æ°´": ["å‡€æ°´", "å‡€æ°´å™¨", "å‡€æ°´æœº", "è¿‡æ»¤å™¨"],
        "é‡‡æš–": ["é‡‡æš–", "æš–æ°”", "åœ°æš–", "å£æŒ‚ç‚‰"],
        "å¨ç”µ": ["å¨ç”µ", "æ²¹çƒŸæœº", "ç‡ƒæ°”ç¶", "æ¶ˆæ¯’æŸœ", "è’¸ç®±", "çƒ¤ç®±"]  # ç§»é™¤æ´—ç¢—æœº
    }
    
    for category, keywords in category_keywords.items():
        if any(keyword in product_name_lower for keyword in keywords):
            return category
    
    return "å…¶ä»–"

def force_categorize_product(product_name):
    """å¼ºåˆ¶å°†äº§å“åç§°åŒ¹é…åˆ°å…«ä¸ªé¢„å®šä¹‰å“ç±»ä¹‹ä¸€"""
    if not isinstance(product_name, str):
        return "å†°ç®±"
    
    product_name_lower = product_name.lower()
    
    # å…«ä¸ªé¢„å®šä¹‰å“ç±»çš„å…³é”®è¯
    category_keywords = {
        "æ´—ç¢—æœº": ["æ´—ç¢—æœº", "æ´—ç¢—", "æ´—ç¢Ÿæœº", "æ´—ç¢Ÿ"],
        "å†°ç®±": ["å†°ç®±", "å†·è—", "å†·å†»", "ä¿é²œ"],
        "æ´—è¡£æœº": ["æ´—è¡£æœº", "æ´—çƒ˜ä¸€ä½“", "æ»šç­’", "æ³¢è½®", "æ´—è¡£"],
        "å†·æŸœ": ["å†·æŸœ", "å†°æŸœ", "å±•ç¤ºæŸœ", "å†·è—æŸœ", "å†·å†»æŸœ"],
        "å®¶ç”¨ç©ºè°ƒ": ["ç©ºè°ƒ", "æŒ‚æœº", "æŸœæœº", "åˆ†ä½“å¼", "å£æŒ‚", "ç«‹å¼"],
        "å•†ç©ºç©ºè°ƒ": ["å•†ç”¨", "å•†ç”¨ç©ºè°ƒ", "å¤šè”æœº", "é£ç®¡æœº", "ä¸­å¤®ç©ºè°ƒ", "å•†ç©º"],
        "å¨ç”µ": ["å¨ç”µ", "æ²¹çƒŸæœº", "ç‡ƒæ°”ç¶", "æ¶ˆæ¯’æŸœ", "è’¸ç®±", "çƒ¤ç®±", "ç¶å…·"],
        "çƒ­æ°´å™¨": ["çƒ­æ°´å™¨", "ç”µçƒ­æ°´å™¨", "ç‡ƒæ°”çƒ­æ°´å™¨", "å¤šèƒ½æºçƒ­æ°´å™¨", "çƒ­æ°´"]
    }
    
    # ä¼˜å…ˆåŒ¹é…
    for category, keywords in category_keywords.items():
        if any(keyword in product_name_lower for keyword in keywords):
            return category
    
    # æ™ºèƒ½åˆ¤æ–­é€»è¾‘
    if any(word in product_name_lower for word in ["æµ·å°”", "ç¾çš„", "æ ¼åŠ›", "tcl", "å®¹å£°"]):
        if any(word in product_name_lower for word in ["å‡", "l", "å®¹é‡"]):
            return "å†°ç®±"
        elif any(word in product_name_lower for word in ["kg", "å…¬æ–¤", "æ´—"]):
            return "æ´—è¡£æœº"
        elif any(word in product_name_lower for word in ["åŒ¹", "p", "åˆ¶å†·", "åˆ¶çƒ­"]):
            return "å®¶ç”¨ç©ºè°ƒ"
    
    # é»˜è®¤å…œåº•
    return "å†°ç®±"

# ========== æŠ¥è¡¨ç”Ÿæˆ ==========
def classify_channel(shop_name):
    """æ¸ é“å½’ç±»å‡½æ•°"""
    if not isinstance(shop_name, str):
        return "å…¶ä»–"
    
    if any(kw in shop_name for kw in CHANNEL_GROUPS['å¡è¨å¸æ¸ é“']['keywords']):
        return "å¡è¨å¸æ¸ é“"
    if any(kw in shop_name for kw in CHANNEL_GROUPS['äº¬ä¸œæ¸ é“']['keywords']):
        return "äº¬ä¸œæ¸ é“"
    if any(kw in shop_name for kw in CHANNEL_GROUPS['å¤©çŒ«æ¸ é“']['keywords']):
        return "å¤©çŒ«æ¸ é“"
    if any(kw in shop_name for kw in CHANNEL_GROUPS['æ‹¼å¤šå¤šæ¸ é“']['keywords']):
        return "æ‹¼å¤šå¤šæ¸ é“"
    if any(kw in shop_name for kw in CHANNEL_GROUPS['æŠ–éŸ³æ¸ é“']['keywords']):
        return "æŠ–éŸ³æ¸ é“"
    return "å…¶ä»–"

def generate_group_report(group_name, group_type, keywords, df, df_prev, report_date):
    if group_type == 'business':
        def business_filter(row):
            if 'æ•°æ®æ¥æº' in row and row['æ•°æ®æ¥æº'] == 'åˆ†é”€' and 'å“ç±»' in row:
                return any(kw in str(row['å“ç±»']) for kw in keywords)
            else:
                return any(kw in str(row[CATEGORY_COL]) for kw in keywords)
        
        group_df = df[df.apply(business_filter, axis=1)]
        prev_group_df = df_prev[df_prev.apply(business_filter, axis=1)] if df_prev is not None else None
    else:
        if group_name == 'å¡è¨å¸æ¸ é“':
            group_df = df[df[SHOP_COL].apply(lambda x: any(kw in str(x) for kw in CHANNEL_GROUPS['å¡è¨å¸æ¸ é“']['keywords']))]
            prev_group_df = df_prev[df_prev[SHOP_COL].apply(lambda x: any(kw in str(x) for kw in CHANNEL_GROUPS['å¡è¨å¸æ¸ é“']['keywords']))] if df_prev is not None else None
        elif group_name == 'å¤©çŒ«æ¸ é“':
            group_df = df[df[SHOP_COL].apply(lambda x: (any(kw in str(x) for kw in CHANNEL_GROUPS['å¤©çŒ«æ¸ é“']['keywords'])) and not any(kw in str(x) for kw in CHANNEL_GROUPS['å¡è¨å¸æ¸ é“']['keywords']))]
            prev_group_df = df_prev[df_prev[SHOP_COL].apply(lambda x: (any(kw in str(x) for kw in CHANNEL_GROUPS['å¤©çŒ«æ¸ é“']['keywords'])) and not any(kw in str(x) for kw in CHANNEL_GROUPS['å¡è¨å¸æ¸ é“']['keywords']))] if df_prev is not None else None
        else:
            group_df = df[df[SHOP_COL].apply(lambda x: any(kw in str(x) for kw in CHANNEL_GROUPS[group_name]['keywords']))]
            prev_group_df = df_prev[df_prev[SHOP_COL].apply(lambda x: any(kw in str(x) for kw in CHANNEL_GROUPS[group_name]['keywords']))] if df_prev is not None else None
    
    if group_df.empty:
        content = f"ğŸ¢ {group_name}æ—¥æŠ¥\nğŸ“… æ•°æ®æ—¥æœŸ: {report_date}\n\nâš ï¸ ä»Šæ—¥æš‚æ— é”€å”®æ•°æ®"
        title_cn = f"{group_name}æ—¥æŠ¥ï¼ˆ{report_date}ï¼‰"
        empty_content = f"""ğŸ¢ {group_name}æ—¥æŠ¥
ğŸ“… æ•°æ®æ—¥æœŸ: {report_date}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš ï¸ ä»Šæ—¥æš‚æ— é”€å”®æ•°æ®
è¯¥äº‹ä¸šéƒ¨/æ¸ é“ä»Šæ—¥æš‚æ— é”€å”®æ•°æ®ï¼Œè¯·æŸ¥çœ‹å…¶ä»–æ—¶é—´æ®µçš„æŠ¥å‘Šã€‚"""
        
        html_content = generate_html_content(title_cn, empty_content)
        file_prefix = to_pinyin(group_name)
        filename = f"{file_prefix}_{report_date}.html".replace('/', '-')
        script_dir = os.path.dirname(os.path.abspath(__file__))
        reports_dir = os.path.join(script_dir, "reports")
        os.makedirs(reports_dir, exist_ok=True)
        filepath = os.path.join(reports_dir, filename)
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(html_content)
        return content, filename
    
    # æ•°æ®ç±»å‹è½¬æ¢
    group_df[AMOUNT_COL] = group_df[AMOUNT_COL].apply(to_integer)
    group_df[QTY_COL] = group_df[QTY_COL].apply(to_integer)
    
    total_amount = group_df[AMOUNT_COL].sum()
    total_qty = group_df[QTY_COL].sum()
    avg_price = total_amount // total_qty if total_qty > 0 else 0
    
    prev_amount = 0
    prev_qty = 0
    if prev_group_df is not None and not prev_group_df.empty:
        prev_group_df[AMOUNT_COL] = prev_group_df[AMOUNT_COL].apply(to_integer)
        prev_group_df[QTY_COL] = prev_group_df[QTY_COL].apply(to_integer)
        prev_amount = prev_group_df[AMOUNT_COL].sum()
        prev_qty = prev_group_df[QTY_COL].sum()
    
    prev_avg_price = prev_amount // prev_qty if prev_qty > 0 else 0
    
    # åˆ†é”€æ•°æ®ç»Ÿè®¡
    fenxiao_amount = 0
    fenxiao_qty = 0
    if 'æ•°æ®æ¥æº' in group_df.columns:
        fenxiao_df = group_df[group_df['æ•°æ®æ¥æº'] == 'åˆ†é”€']
        if not fenxiao_df.empty:
            fenxiao_amount = fenxiao_df[AMOUNT_COL].sum()
            fenxiao_qty = fenxiao_df[QTY_COL].sum()
    
    # åŒæœŸåˆ†é”€æ•°æ®
    prev_fenxiao_amount = 0
    prev_fenxiao_qty = 0
    if prev_group_df is not None and 'æ•°æ®æ¥æº' in prev_group_df.columns:
        prev_fenxiao_df = prev_group_df[prev_group_df['æ•°æ®æ¥æº'] == 'åˆ†é”€']
        if not prev_fenxiao_df.empty:
            prev_fenxiao_amount = prev_fenxiao_df[AMOUNT_COL].sum()
            prev_fenxiao_qty = prev_fenxiao_df[QTY_COL].sum()
    
    # å“ç±»æ˜ç»†
    category_data = group_df.groupby(CATEGORY_COL).agg({AMOUNT_COL: 'sum', QTY_COL: 'sum'}).reset_index()
    category_data = category_data.sort_values(AMOUNT_COL, ascending=False)
    prev_category_data = None
    if prev_group_df is not None:
        prev_category_data = prev_group_df.groupby(CATEGORY_COL).agg({AMOUNT_COL: 'sum', QTY_COL: 'sum'}).reset_index()
    
    # æ¸ é“æ•°æ®
    channel_data = None
    prev_channel_data = None
    if group_type == 'business':
        group_df['æ¸ é“'] = group_df[SHOP_COL].apply(classify_channel)
        channel_data = group_df.groupby('æ¸ é“').agg({AMOUNT_COL: 'sum', QTY_COL: 'sum'}).reset_index()
        channel_data = channel_data[channel_data['æ¸ é“'].isin(CHANNEL_GROUPS.keys())]
        channel_data = channel_data.sort_values(AMOUNT_COL, ascending=False)
        if prev_group_df is not None:
            prev_group_df['æ¸ é“'] = prev_group_df[SHOP_COL].apply(classify_channel)
            prev_channel_data = prev_group_df.groupby('æ¸ é“').agg({AMOUNT_COL: 'sum', QTY_COL: 'sum'}).reset_index()
    
    # åº—é“ºæ•°æ®
    shop_data = group_df.groupby(SHOP_COL).agg({AMOUNT_COL: 'sum', QTY_COL: 'sum'}).reset_index()
    shop_data = shop_data.sort_values(AMOUNT_COL, ascending=False)
    prev_shop_data = None
    if prev_group_df is not None:
        prev_shop_data = prev_group_df.groupby(SHOP_COL).agg({AMOUNT_COL: 'sum', QTY_COL: 'sum'}).reset_index()
    
    # TOPå•å“
    product_data = group_df.groupby(MODEL_COL).agg({AMOUNT_COL: 'sum', QTY_COL: 'sum'}).reset_index()
    product_data = product_data[product_data[AMOUNT_COL] > 1000]
    product_data = product_data.sort_values(AMOUNT_COL, ascending=False)
    
    # ç”Ÿæˆå†…å®¹
    web_content = f"""ğŸ¢ {group_name}æ—¥æŠ¥
ğŸ“… æ•°æ®æ—¥æœŸ: {report_date}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š æ•´ä½“æ•°æ®
æ€»é”€å”®é¢: Â¥{total_amount:,}ï¼ˆç¯æ¯”:{calculate_ratio_int(total_amount, prev_amount)}ï¼‰
æ€»é”€é‡: {total_qty}ä»¶ï¼ˆç¯æ¯”:{calculate_ratio_int(total_qty, prev_qty)}ï¼‰
å¹³å‡å•ä»·: Â¥{avg_price:,}ï¼ˆç¯æ¯”:{calculate_ratio_int(avg_price, prev_avg_price)}ï¼‰"""

    if fenxiao_amount > 0:
        web_content += f"""
å…¶ä¸­åˆ†é”€é”€å”®: Â¥{fenxiao_amount:,}ï¼ˆç¯æ¯”:{calculate_ratio_int(fenxiao_amount, prev_fenxiao_amount)}ï¼‰ï¼Œ{fenxiao_qty}ä»¶"""

    web_content += "\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nğŸ“‹ å“ç±»æ˜ç»†"
    
    for _, row in category_data.iterrows():
        cat = row[CATEGORY_COL]
        amount = to_integer(row[AMOUNT_COL])
        qty = to_integer(row[QTY_COL])
        price = amount // qty if qty else 0
        prev_amount_cat = to_integer(prev_category_data.loc[prev_category_data[CATEGORY_COL] == cat, AMOUNT_COL].sum()) if prev_category_data is not None else 0
        web_content += f"\nâ€¢ {cat}: Â¥{amount:,}ï¼ˆç¯æ¯”:{calculate_ratio_int(amount, prev_amount_cat)}ï¼‰ï¼Œ{qty}ä»¶ | å•ä»·: Â¥{price:,}"

    if group_type == 'business' and channel_data is not None and not channel_data.empty:
        web_content += "\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nğŸª æ¸ é“æ•°æ®"
        for _, row in channel_data.iterrows():
            channel = row['æ¸ é“']
            amount = to_integer(row[AMOUNT_COL])
            qty = to_integer(row[QTY_COL])
            price = amount // qty if qty else 0
            prev_amount_channel = to_integer(prev_channel_data.loc[prev_channel_data['æ¸ é“'] == channel, AMOUNT_COL].sum()) if prev_channel_data is not None else 0
            web_content += f"\nâ€¢ {channel}: Â¥{amount:,}ï¼ˆç¯æ¯”:{calculate_ratio_int(amount, prev_amount_channel)}ï¼‰ï¼Œ{qty}ä»¶ | å•ä»·: Â¥{price:,}"

    if shop_data is not None and not shop_data.empty:
        web_content += "\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nğŸª åº—é“ºæ•°æ®"
        for _, row in shop_data.head(10).iterrows():
            shop = row[SHOP_COL]
            amount = to_integer(row[AMOUNT_COL])
            qty = to_integer(row[QTY_COL])
            prev_amount_shop = to_integer(prev_shop_data.loc[prev_shop_data[SHOP_COL] == shop, AMOUNT_COL].sum()) if prev_shop_data is not None else 0
            web_content += f"\nâ€¢ {shop}: Â¥{amount:,}ï¼ˆç¯æ¯”:{calculate_ratio_int(amount, prev_amount_shop)}ï¼‰ï¼Œ{qty}ä»¶"

    if product_data is not None and not product_data.empty:
        web_content += "\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nğŸ† TOP å•å“"
        for _, row in product_data.head(10).iterrows():
            model = row[MODEL_COL]
            amount = to_integer(row[AMOUNT_COL])
            qty = to_integer(row[QTY_COL])
            price = amount // qty if qty else 0
            prev_amount_product = 0
            if df_prev is not None:
                prev_product = df_prev[df_prev[MODEL_COL] == model]
                if not prev_product.empty:
                    prev_amount_product = prev_product[AMOUNT_COL].sum()
            web_content += f"\nâ€¢ {model}: Â¥{amount:,}ï¼Œ{qty}ä»¶ | å•ä»·: Â¥{price:,}"

    # ç”Ÿæˆç®€æ´å¾®ä¿¡å†…å®¹
    content = f"ğŸ¢ {group_name}æ—¥æŠ¥\nğŸ“… æ•°æ®æ—¥æœŸ: {report_date}\n\n"
    content += f"ğŸ“Š æ•´ä½“æ•°æ®\næ€»é”€å”®é¢: Â¥{total_amount:,}ï¼ˆç¯æ¯”:{calculate_ratio_int(total_amount, prev_amount)}ï¼‰\næ€»é”€é‡: {total_qty}ä»¶ï¼ˆç¯æ¯”:{calculate_ratio_int(total_qty, prev_qty)}ï¼‰\nå¹³å‡å•ä»·: Â¥{avg_price:,}"
    
    if fenxiao_amount > 0:
        content += f"\nå…¶ä¸­åˆ†é”€é‡‘é¢: Â¥{fenxiao_amount:,}ï¼ˆç¯æ¯”:{calculate_ratio_int(fenxiao_amount, prev_fenxiao_amount)}ï¼‰"
    
    content += "\n\nğŸ“‹ å“ç±»æ˜ç»†\n"
    for i, (_, row) in enumerate(category_data.iterrows()):
        if i >= 3:
            break
        cat = row[CATEGORY_COL]
        amount = to_integer(row[AMOUNT_COL])
        qty = to_integer(row[QTY_COL])
        prev_amount_cat = to_integer(prev_category_data.loc[prev_category_data[CATEGORY_COL] == cat, AMOUNT_COL].sum()) if prev_category_data is not None else 0
        content += f"â€¢ {cat}: Â¥{amount:,}ï¼ˆç¯æ¯”:{calculate_ratio_int(amount, prev_amount_cat)}ï¼‰ï¼Œ{qty}ä»¶\n"
    
    if group_type == 'business' and channel_data is not None and not channel_data.empty:
        content += "\nğŸª æ¸ é“æ•°æ®\n"
        for i, (_, row) in enumerate(channel_data.iterrows()):
            if i >= 3:
                break
            channel = row['æ¸ é“']
            amount = to_integer(row[AMOUNT_COL])
            qty = to_integer(row[QTY_COL])
            prev_amount_channel = to_integer(prev_channel_data.loc[prev_channel_data['æ¸ é“'] == channel, AMOUNT_COL].sum()) if prev_channel_data is not None else 0
            content += f"â€¢ {channel}: Â¥{amount:,}ï¼ˆç¯æ¯”:{calculate_ratio_int(amount, prev_amount_channel)}ï¼‰ï¼Œ{qty}ä»¶\n"
    
    if shop_data is not None and not shop_data.empty:
        content += "\nğŸª åº—é“ºæ•°æ®\n"
        for i, (_, row) in enumerate(shop_data.iterrows()):
            if i >= 3:
                break
            shop = row[SHOP_COL]
            amount = to_integer(row[AMOUNT_COL])
            qty = to_integer(row[QTY_COL])
            prev_amount_shop = to_integer(prev_shop_data.loc[prev_shop_data[SHOP_COL] == shop, AMOUNT_COL].sum()) if prev_shop_data is not None else 0
            content += f"â€¢ {shop}: Â¥{amount:,}ï¼ˆç¯æ¯”:{calculate_ratio_int(amount, prev_amount_shop)}ï¼‰ï¼Œ{qty}ä»¶\n"
    
    if product_data is not None and not product_data.empty:
        content += "\nğŸ† TOPå•å“\n"
        for i, (_, row) in enumerate(product_data.iterrows()):
            if i >= 3:
                break
            model = row[MODEL_COL]
            amount = to_integer(row[AMOUNT_COL])
            qty = to_integer(row[QTY_COL])
            content += f"â€¢ {model}: Â¥{amount:,}ï¼Œ{qty}ä»¶\n"
    
    title_cn = f"{group_name}æ—¥æŠ¥ï¼ˆ{report_date}ï¼‰"
    html_content = generate_html_content(title_cn, web_content)
    
    file_prefix = to_pinyin(group_name)
    filename = f"{file_prefix}_{report_date}.html".replace('/', '-')
    script_dir = os.path.dirname(os.path.abspath(__file__))
    reports_dir = os.path.join(script_dir, "reports")
    os.makedirs(reports_dir, exist_ok=True)
    filepath = os.path.join(reports_dir, filename)
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(html_content)
    
    return content, filename

# ========== ä¸»ç¨‹åº ==========
logger.info("ğŸš€ å¤šäº‹ä¸šéƒ¨æ—¥æŠ¥æ•°æ®åˆ†æç³»ç»Ÿå¯åŠ¨...")

yesterday = datetime.now() - timedelta(days=1)
yesterday_str = yesterday.strftime('%Y-%m-%d')
logger.info(f"ğŸ“… åˆ†ææ—¥æœŸ: {yesterday_str}")

logger.info("ğŸ“Š å¼€å§‹è·å–ERPæ•°æ®...")
df_erp = get_erp_data(yesterday_str)
logger.info(f"ğŸ“Š ERPæ•°æ®è·å–å®Œæˆ: {len(df_erp)} è¡Œ")

if df_erp is None or len(df_erp) == 0:
    logger.error("âŒ æ— æ³•è·å–ERPæ•°æ®ï¼Œç¨‹åºé€€å‡º")
    sys.exit(1)

logger.info("ğŸ“Š å¼€å§‹è·å–åŒæœŸæ•°æ®...")
prev_date = (datetime.now() - timedelta(days=2)).strftime('%Y-%m-%d')
df_prev = get_prev_data(prev_date)
logger.info(f"ğŸ“Š åŒæœŸæ•°æ®è·å–å®Œæˆ: {len(df_prev) if df_prev is not None else 0} è¡Œ")

logger.info("ğŸ“Š å¼€å§‹è·å–åˆ†é”€æ•°æ®...")
df_fenxiao = get_fenxiao_data(yesterday_str)
logger.info(f"ğŸ“Š åˆ†é”€æ•°æ®è·å–å®Œæˆ: {len(df_fenxiao) if df_fenxiao is not None else 0} è¡Œ")

# æ•°æ®é¢„å¤„ç†
logger.info("ğŸš€ å¼€å§‹æ•°æ®é¢„å¤„ç†...")
df_erp[AMOUNT_COL] = df_erp[AMOUNT_COL].apply(to_integer)
df_erp[QTY_COL] = df_erp[QTY_COL].apply(to_integer)
df_erp = df_erp[(df_erp[AMOUNT_COL] > 0) & (df_erp[QTY_COL] > 0)]
df_erp = df_erp[df_erp[SHOP_COL].apply(is_online_shop)]

def is_five_channel(shop):
    if not isinstance(shop, str):
        return False
    five_channels = ['äº¬ä¸œ', 'å¤©çŒ«', 'æ‹¼å¤šå¤š', 'æŠ–éŸ³', 'å¡è¨å¸']
    return any(channel in shop for channel in five_channels)

df_erp = df_erp[df_erp[SHOP_COL].apply(is_five_channel)]
df_erp['æ•°æ®æ¥æº'] = 'ERP'

if df_fenxiao is not None and len(df_fenxiao) > 0:
    df_fenxiao[AMOUNT_COL] = df_fenxiao[AMOUNT_COL].apply(to_integer)
    df_fenxiao[QTY_COL] = df_fenxiao[QTY_COL].apply(to_integer)
    df_fenxiao = df_fenxiao[(df_fenxiao[AMOUNT_COL] > 0) & (df_fenxiao[QTY_COL] > 0)]
    df_fenxiao['æ•°æ®æ¥æº'] = 'åˆ†é”€'
    df_erp = pd.concat([df_erp, df_fenxiao], ignore_index=True)

if df_prev is not None and len(df_prev) > 0:
    df_prev[AMOUNT_COL] = df_prev[AMOUNT_COL].apply(to_integer)
    df_prev[QTY_COL] = df_prev[QTY_COL].apply(to_integer)
    df_prev = df_prev[(df_prev[AMOUNT_COL] > 0) & (df_prev[QTY_COL] > 0)]
    df_prev = df_prev[df_prev[SHOP_COL].apply(is_online_shop)]
    df_prev = df_prev[df_prev[SHOP_COL].apply(is_five_channel)]
    df_prev['æ•°æ®æ¥æº'] = 'ERP'

logger.info(f"ğŸ“Š æ•°æ®é¢„å¤„ç†å®Œæˆ - å½“å‰æ•°æ®: {len(df_erp)} è¡Œ")
logger.info(f"ğŸ“Š æ•°æ®é¢„å¤„ç†å®Œæˆ - åŒæœŸæ•°æ®: {len(df_prev) if df_prev is not None else 0} è¡Œ")

os.makedirs('reports', exist_ok=True)

all_group_files = []
all_group_links = []

for dept, keywords in business_groups.items():
    try:
        logger.info(f"\nğŸ”„ æ­£åœ¨å¤„ç† {dept}...")
        target_users = get_target_users(dept, 'business')
        logger.info(f"ğŸ“¤ {dept} ç›®æ ‡ç”¨æˆ·: {', '.join(target_users)}")
        
        content, filename = generate_group_report(dept, 'business', keywords['keywords'], df_erp, df_prev, yesterday_str)
        if content and filename:
            all_group_files.append({
                'name': dept,
                'content': content,
                'filename': filename,
                'type': 'business',
                'target_users': target_users
            })
            logger.info(f"âœ… {dept} å¤„ç†å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ {dept} å¤„ç†å¼‚å¸¸: {e}")
        continue

for channel, keywords in CHANNEL_GROUPS.items():
    try:
        logger.info(f"\nğŸ”„ æ­£åœ¨å¤„ç† {channel}...")
        target_users = get_target_users(channel, 'channel')
        logger.info(f"ğŸ“¤ {channel} ç›®æ ‡ç”¨æˆ·: {', '.join(target_users)}")
        
        content, filename = generate_group_report(channel, 'channel', keywords['keywords'], df_erp, df_prev, yesterday_str)
        if content and filename:
            all_group_files.append({
                'name': channel,
                'content': content,
                'filename': filename,
                'type': 'channel',
                'target_users': target_users
            })
            logger.info(f"âœ… {channel} å¤„ç†å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ {channel} å¤„ç†å¼‚å¸¸: {e}")
        continue

logger.info("ğŸ“¤ å¼€å§‹å‘é€å¾®ä¿¡æ¶ˆæ¯...")
for group_info in all_group_files:
    group_name = group_info['name']
    content = group_info['content']
    filename = group_info['filename']
    target_users = group_info['target_users']
    
    try:
        public_url = f"https://edge.haierht.cn/{filename}"
        msg = content + f"\nğŸŒ æŸ¥çœ‹å®Œæ•´Webé¡µé¢: {public_url}"
        logger.info(f"ğŸ“¤ å‘é€ {group_name} æŠ¥å‘Šç»™ {len(target_users)} ä¸ªç”¨æˆ·")
        send_wecomchan_segment(msg, target_users)
        time.sleep(1)
        all_group_links.append(f"{group_name}: {public_url}")
    except Exception as e:
        logger.error(f"âŒ {group_name} å‘é€å¼‚å¸¸: {e}")
        continue

logger.info("ğŸ‰ å¤šäº‹ä¸šéƒ¨æ—¥æŠ¥æ•°æ®åˆ†æå®Œæˆï¼")