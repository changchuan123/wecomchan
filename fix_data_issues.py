#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤æ•°æ®è·å–é—®é¢˜
"""

import pymysql
import pandas as pd
from datetime import datetime, timedelta
import sys
import logging
import time

# æ•°æ®åº“é…ç½®
DB_HOST = "212.64.57.87"
DB_PORT = 3306
DB_USER = "root"
DB_PASSWORD = "c973ee9b500cc638"
DB_NAME = "Date"
DB_CHARSET = "utf8mb4"

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def normalize_date_format(date_str):
    """ç®€åŒ–çš„æ—¥æœŸæ ¼å¼å¤„ç†"""
    if pd.isna(date_str) or date_str is None:
        return None
    
    date_str = str(date_str).strip()
    if not date_str or date_str == '':
        return None
    
    try:
        # å°è¯•ç›´æ¥è§£æ
        parsed_date = pd.to_datetime(date_str)
        return parsed_date.strftime('%Y-%m-%d')
    except:
        return None

def get_fixed_fenxiao_data(start_date, end_date=None):
    """ä¿®å¤ç‰ˆçš„åˆ†é”€æ•°æ®è·å–å‡½æ•°"""
    max_retries = 3
    conn = None
    
    for attempt in range(max_retries):
        try:
            conn = pymysql.connect(
                host=DB_HOST, port=DB_PORT, user=DB_USER,
                password=DB_PASSWORD, database=DB_NAME, charset=DB_CHARSET,
                connect_timeout=30, read_timeout=30, write_timeout=30
            )
            logging.info(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ (å°è¯• {attempt+1}/{max_retries})")
            break
        except Exception as e:
            logging.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ (å°è¯• {attempt+1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                logging.info(f"â³ ç­‰å¾…5ç§’åé‡è¯•...")
                time.sleep(5)
            else:
                logging.error("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                return pd.DataFrame()
    
    if conn is None:
        return pd.DataFrame()
    
    try:
        cursor = conn.cursor()
        
        # è·å–HT_fenxiaoè¡¨ç»“æ„
        cursor.execute("DESCRIBE HT_fenxiao")
        columns = [row[0] for row in cursor.fetchall()]
        logging.info(f"ğŸ“Š HT_fenxiaoè¡¨å­—æ®µ: {columns}")
        
        # æŸ¥æ‰¾å­—æ®µå
        amount_fields = [col for col in columns if 'é‡‘é¢' in col or 'å®ä»˜' in col or 'æ”¯ä»˜' in col]
        shop_fields = [col for col in columns if 'åº—é“º' in col or 'å•†åº—' in col]
        status_fields = [col for col in columns if 'çŠ¶æ€' in col or 'è®¢å•' in col]
        time_fields = [col for col in columns if 'æ—¶é—´' in col or 'æ—¥æœŸ' in col or 'åˆ›å»º' in col]
        product_fields = [col for col in columns if 'äº§å“' in col or 'åç§°' in col]
        qty_fields = [col for col in columns if 'æ•°é‡' in col or 'é‡‡è´­æ•°é‡' in col]
        
        # é€‰æ‹©å­—æ®µå
        amount_col = 'ç”¨æˆ·å®é™…æ”¯ä»˜æ€»é¢' if 'ç”¨æˆ·å®é™…æ”¯ä»˜æ€»é¢' in columns else (amount_fields[0] if amount_fields else 'ç”¨æˆ·å®é™…æ”¯ä»˜é‡‘é¢')
        shop_col = 'åˆ†é”€å•†åº—é“ºåç§°' if 'åˆ†é”€å•†åº—é“ºåç§°' in columns else (shop_fields[0] if shop_fields else 'åˆ†é”€å•†åº—é“ºåç§°')
        status_col = 'è®¢å•çŠ¶æ€' if 'è®¢å•çŠ¶æ€' in columns else (status_fields[0] if status_fields else 'è®¢å•çŠ¶æ€')
        
        # ä¿®å¤ï¼šä½¿ç”¨è®¢å•åˆ›å»ºæ—¶é—´ï¼Œä½†å¢åŠ å¤‡ç”¨é€‰é¡¹
        if 'è®¢å•åˆ›å»ºæ—¶é—´' in columns:
            time_col = 'è®¢å•åˆ›å»ºæ—¶é—´'
            logging.info("ğŸ“Š ä½¿ç”¨è®¢å•åˆ›å»ºæ—¶é—´ä½œä¸ºæ—¶é—´å­—æ®µ")
        else:
            time_col = time_fields[0] if time_fields else 'è®¢å•åˆ›å»ºæ—¶é—´'
            logging.info(f"ğŸ“Š ä½¿ç”¨é»˜è®¤æ—¶é—´å­—æ®µ: {time_col}")
            
        product_col = 'äº§å“åç§°' if 'äº§å“åç§°' in columns else (product_fields[0] if product_fields else 'äº§å“åç§°')
        qty_col = 'é‡‡è´­æ•°é‡' if 'é‡‡è´­æ•°é‡' in columns else (qty_fields[0] if qty_fields else 'é‡‡è´­æ•°é‡')
        
        # ä¿®å¤ï¼šç®€åŒ–æ—¶é—´æ¡ä»¶ï¼Œé¿å…å¤æ‚çš„ORæ¡ä»¶
        if end_date:
            time_condition = f"{time_col} >= '{start_date}' AND {time_col} <= '{end_date} 23:59:59'"
        else:
            if 'è‡³' in start_date:
                start_dt, end_dt = start_date.split('è‡³')
                time_condition = f"{time_col} >= '{start_dt}' AND {time_col} <= '{end_dt} 23:59:59'"
            else:
                time_condition = f"DATE({time_col}) = '{start_date}'"
        
        # ä¿®å¤ï¼šç®€åŒ–SQLæŸ¥è¯¢ï¼Œå‡å°‘è¿‡æ»¤æ¡ä»¶
        sql = f"""
        SELECT 
            {shop_col} as åº—é“º,
            {status_col} as è®¢å•çŠ¶æ€,
            {amount_col} as åˆ†æ‘Šåæ€»ä»·,
            {time_col} as äº¤æ˜“æ—¶é—´,
            {product_col} as è§„æ ¼åç§°,
            {product_col} as è´§å“åç§°,
            {qty_col} as å®å‘æ•°é‡,
            'åˆ†é”€' as æ•°æ®æ¥æº
        FROM HT_fenxiao 
        WHERE {time_condition}
        """
        
        logging.info(f"ğŸ“Š æ‰§è¡Œä¿®å¤ç‰ˆåˆ†é”€æ•°æ®æŸ¥è¯¢: {sql}")
        
        df_fenxiao = pd.read_sql(sql, conn)
        
        if not df_fenxiao.empty:
            logging.info(f"ğŸ“Š åˆ†é”€æ•°æ®è·å–æˆåŠŸï¼Œå…±{len(df_fenxiao)}è¡Œ")
            
            # æ˜¾ç¤ºåŸå§‹æ—¥æœŸæ ¼å¼æ ·æœ¬
            sample_dates = df_fenxiao['äº¤æ˜“æ—¶é—´'].head(5).tolist()
            logging.info(f"ğŸ“Š åŸå§‹æ—¥æœŸæ ¼å¼æ ·æœ¬: {sample_dates}")
            
            # ç®€åŒ–çš„æ—¥æœŸæ ¼å¼å¤„ç†
            df_fenxiao['äº¤æ˜“æ—¶é—´'] = df_fenxiao['äº¤æ˜“æ—¶é—´'].apply(normalize_date_format)
            
            # ç»Ÿè®¡æ—¥æœŸå¤„ç†ç»“æœ
            valid_dates = df_fenxiao['äº¤æ˜“æ—¶é—´'].notna().sum()
            total_dates = len(df_fenxiao)
            logging.info(f"ğŸ“Š æ—¥æœŸæ ¼å¼å¤„ç†ç»“æœ: æœ‰æ•ˆæ—¥æœŸ {valid_dates}/{total_dates}")
            
            # ç§»é™¤æ— æ•ˆæ—¥æœŸçš„è¡Œ
            df_fenxiao = df_fenxiao.dropna(subset=['äº¤æ˜“æ—¶é—´'])
            logging.info(f"ğŸ“Š ç§»é™¤æ— æ•ˆæ—¥æœŸååˆ†é”€æ•°æ®è¡Œæ•°: {len(df_fenxiao)}")
            
            if not df_fenxiao.empty:
                # æ˜¾ç¤ºå¤„ç†åçš„æ—¥æœŸèŒƒå›´
                df_fenxiao['äº¤æ˜“æ—¶é—´'] = pd.to_datetime(df_fenxiao['äº¤æ˜“æ—¶é—´'])
                min_date = df_fenxiao['äº¤æ˜“æ—¶é—´'].min()
                max_date = df_fenxiao['äº¤æ˜“æ—¶é—´'].max()
                logging.info(f"ğŸ“Š åˆ†é”€æ•°æ®æ—¥æœŸèŒƒå›´: {min_date.strftime('%Y-%m-%d')} è‡³ {max_date.strftime('%Y-%m-%d')}")
                
                # æ˜¾ç¤ºè®¢å•çŠ¶æ€åˆ†å¸ƒ
                status_counts = df_fenxiao['è®¢å•çŠ¶æ€'].value_counts()
                logging.info(f"ğŸ“Š è®¢å•çŠ¶æ€åˆ†å¸ƒ:")
                for status, count in status_counts.items():
                    logging.info(f"   {status}: {count}æ¡")
            
            return df_fenxiao
        else:
            logging.warning("âš ï¸ åˆ†é”€æ•°æ®æŸ¥è¯¢ç»“æœä¸ºç©º")
            return pd.DataFrame()
            
    except Exception as e:
        logging.error(f"âŒ è·å–åˆ†é”€æ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()
    finally:
        if conn:
            conn.close()

def test_fixed_data_retrieval():
    """æµ‹è¯•ä¿®å¤åçš„æ•°æ®è·å–"""
    print("ğŸ” å¼€å§‹æµ‹è¯•ä¿®å¤åçš„æ•°æ®è·å–...")
    
    # æ¨¡æ‹ŸåŸè„šæœ¬çš„æ—¥æœŸè®¡ç®—
    today = datetime.now()
    yesterday = today - timedelta(days=1)
    target_month_start = yesterday.replace(day=1)
    if yesterday.month == 12:
        next_month = yesterday.replace(year=yesterday.year + 1, month=1, day=1)
    else:
        next_month = yesterday.replace(month=yesterday.month + 1, day=1)
    month_end = next_month - timedelta(days=1)
    
    this_month_start_str = target_month_start.strftime('%Y-%m-%d')
    month_end_str = month_end.strftime('%Y-%m-%d')
    
    print(f"ğŸ“… æµ‹è¯•æ—¥æœŸèŒƒå›´: {this_month_start_str} è‡³ {month_end_str}")
    
    # æµ‹è¯•ERPæ•°æ®è·å–
    try:
        conn = pymysql.connect(
            host=DB_HOST, port=DB_PORT, user=DB_USER,
            password=DB_PASSWORD, database=DB_NAME, charset=DB_CHARSET,
            connect_timeout=30, read_timeout=30, write_timeout=30
        )
        
        # è·å–ERPæ•°æ®
        erp_query = f"SELECT * FROM Daysales WHERE äº¤æ˜“æ—¶é—´ >= '{this_month_start_str}' AND äº¤æ˜“æ—¶é—´ < '{month_end_str} 23:59:59'"
        print(f"ğŸ“Š æ‰§è¡ŒERPæ•°æ®æŸ¥è¯¢: {erp_query}")
        
        df_erp = pd.read_sql(erp_query, conn)
        print(f"âœ… ERPæ•°æ®è·å–æˆåŠŸï¼Œå…±{len(df_erp)}è¡Œ")
        
        # è·å–åˆ†é”€æ•°æ®
        print("ğŸ“Š æ­£åœ¨è·å–åˆ†é”€æ•°æ®...")
        df_fenxiao = get_fixed_fenxiao_data(this_month_start_str, month_end_str)
        
        if not df_fenxiao.empty:
            print(f"âœ… åˆ†é”€æ•°æ®è·å–æˆåŠŸï¼Œå…±{len(df_fenxiao)}è¡Œ")
            
            # åˆå¹¶æ•°æ®
            print("ğŸ”„ åˆå¹¶ERPæ•°æ®å’Œåˆ†é”€æ•°æ®...")
            df_combined = pd.concat([df_erp, df_fenxiao], ignore_index=True)
            print(f"ğŸ“Š åˆå¹¶åæ€»æ•°æ®é‡: {len(df_combined)}è¡Œ")
            
            # æ˜¾ç¤ºæ•°æ®åˆ†å¸ƒ
            print("\nğŸ“Š æ•°æ®æ¥æºåˆ†å¸ƒ:")
            if 'æ•°æ®æ¥æº' in df_combined.columns:
                source_counts = df_combined['æ•°æ®æ¥æº'].value_counts()
                for source, count in source_counts.items():
                    print(f"  {source}: {count}æ¡")
            
            # æ˜¾ç¤ºæ—¥æœŸåˆ†å¸ƒ
            print("\nğŸ“Š æ—¥æœŸåˆ†å¸ƒ:")
            df_combined['äº¤æ˜“æ—¶é—´'] = pd.to_datetime(df_combined['äº¤æ˜“æ—¶é—´'])
            daily_counts = df_combined.groupby(df_combined['äº¤æ˜“æ—¶é—´'].dt.date).size()
            for date, count in daily_counts.items():
                print(f"  {date}: {count}æ¡")
                
        else:
            print("âš ï¸ åˆ†é”€æ•°æ®è·å–å¤±è´¥ï¼Œä»…ä½¿ç”¨ERPæ•°æ®")
            df_combined = df_erp
        
        conn.close()
        print("\nâœ… ä¿®å¤åçš„æ•°æ®è·å–æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•ä¿®å¤åçš„æ•°æ®è·å–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_fixed_data_retrieval() 